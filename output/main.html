<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>El libro Azul de la Inteligencia Artificial</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      word-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
  </style>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">El libro Azul de la Inteligencia Artificial</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#parte-uno"><span class="toc-section-number">1</span> Parte uno</a>
<ul>
<li><a href="#prólogo-y-agradecimientos"><span class="toc-section-number">1.1</span> Prólogo y agradecimientos</a></li>
</ul></li>
<li><a href="#parte-dos-fundamentos"><span class="toc-section-number">2</span> Parte dos: Fundamentos</a>
<ul>
<li><a href="#historia-de-la-inteligencia-artificial"><span class="toc-section-number">2.1</span> Historia de la inteligencia artificial</a></li>
<li><a href="#fundamentos-de-la-ia"><span class="toc-section-number">2.2</span> Fundamentos de la IA</a></li>
</ul></li>
<li><a href="#parte-tres-técnicas-clásicas"><span class="toc-section-number">3</span> Parte tres: Técnicas clásicas</a>
<ul>
<li><a href="#búsquedas-inteligentes"><span class="toc-section-number">3.1</span> Búsquedas inteligentes</a></li>
<li><a href="#algoritmos-evolutivos"><span class="toc-section-number">3.2</span> Algoritmos evolutivos</a></li>
<li><a href="#inteligencia-artificial-simbólica"><span class="toc-section-number">3.3</span> Inteligencia Artificial Simbólica</a></li>
</ul></li>
<li><a href="#parte-cuatro-machine-learning"><span class="toc-section-number">4</span> Parte cuatro: Machine Learning</a>
<ul>
<li><a href="#introducción-al-capítulo"><span class="toc-section-number">4.1</span> Introducción al capítulo</a></li>
<li><a href="#aprendizaje-supervisado"><span class="toc-section-number">4.2</span> Aprendizaje supervisado</a></li>
<li><a href="#aprendizaje-no-supervisado"><span class="toc-section-number">4.3</span> Aprendizaje no supervisado</a></li>
<li><a href="#bibliography">Bibliography</a></li>
</ul></li>
</ul>
</nav>
<p> </p>
<p>Copyright © 2020 Alejandro Medina Reyes<br />
<span class="smallcaps"></span><br />
<span class="smallcaps"></span><br />
Licensed under the Creative Commons Attribution-NonCommercial 3.0 Unported License (the “License”). You may not use this file except in compliance with the License. You may obtain a copy of the License at <a href="http://creativecommons.org/licenses/by-nc/3.0">http://creativecommons.org/licenses/by-nc/3.0</a>. Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an <span class="smallcaps">“as is” basis, without warranties or conditions of any kind</span>, either express or implied. See the License for the specific language governing permissions and limitations under the License.<br />
<em></em></p>
<h1 data-number="1" id="parte-uno"><span class="header-section-number">1</span> Parte uno</h1>
<h2 data-number="1.1" id="prólogo-y-agradecimientos"><span class="header-section-number">1.1</span> Prólogo y agradecimientos</h2>
<strong>Prólogo</strong>
<p>He decidido escribir este libro debido a que considero que es una rama de la computación muy interesante, además estos últimos años se ha incrementado el interés por la inteligencia artificial, debido principalmente a dos factores, la gran cantidad de información disponible que combinada con técnicas de deep learning nos permite hacer predicciones o generalizaciones muy exactas y el avance que hemos tenido tecnológicamente, siendo más preciso el desarrollo de potentes unidades de procesamiento gráfico, esto último es relevante ya que son capaces de trabajar eficazmente con operaciones de matrices que son ampliamente utilizadas por las redes neuronales.</p>
<p>A pesar de ser un campo con muchos años de investigación pienso que no hay mejor momento para descubrir todo el potencial que ésta área nos ofrece y explorar cómo puede repercutir en el mundo que nos rodea.</p>
<p>Este libro busca explorar diversos temas del campo de la inteligencia artificial con el fin de introducir diferentes paradigmas con los cuales se trabaja, revisando la parte conceptual y matemática, así como los usos de las diferentes técnicas.</p>
<strong>Agradecimientos</strong>
<p>Primero quiero agradecer a mis padres ya que me han apoyado en todo mi desarrollo personal y académico, mis logros son un reflejo del gran ejemplo que me han dado y de lo mucho que han hecho por mi. Igualmente es importante reconocer el apoyo de mi hermana en las distintas actividades que he desempeñado y en los proyectos que me he propuesto.</p>
<p>También quiero agradecer a mis maestros que me han enseñado mucho a lo largo de mi carrera profesional, agradezco principalmente a aquellos que me han motivado a crecer y a perseguir mis sueños además de brindarme los conocimientos y herramientas del curso correspondiente. Entre mis maestros quiero darle las gracias especialmente a tres de ellos: José Jesús Sánchez Farías, José Guillermo Fierro Mendoza y Patricia Galvan Morales ya que sin su apoyo no creo que me hubiera decidido a hacer este libro.</p>
<p>Finalmente quiero darle gracias a mi amada esposa que me ha motivado a desarrollarme como persona y que siempre ha estado a mi lado dándome el impulso necesario para llevar a cabo este tipo de proyectos.</p>
<h1 data-number="2" id="parte-dos-fundamentos"><span class="header-section-number">2</span> Parte dos: Fundamentos</h1>
<h2 data-number="2.1" id="historia-de-la-inteligencia-artificial"><span class="header-section-number">2.1</span> Historia de la inteligencia artificial</h2>
<strong>Introducción</strong>
<p>Considero interesante revisar primero un poco de la historia de la Inteligencia Artificial, ya que nos permite ponernos en contexto acerca del estado actual de esta ciencia y cómo llegamos a este punto. También siendo una ciencia con muchas vertientes podemos analizar cuales fueron los aciertos y fallas del pasado para considerarlos en los desarrollos actuales.</p>
<strong>Ideas sobre inteligencia artificial</strong>
<p>El deseo del ser humano por entender la inteligencia y ser capaces de replicarla se remonta a la antigüedad, un ejemplo es la existencia de Talos en la mitología griega, un gigante de bronce que protegía a la Creta minoica de posibles invasores, la versión más dominante de su origen dice que Talos era un autómata creado por Hefesto (Dios del fuego y la forja).</p>
<p>Existen otros ejemplos de autómatas antropomorfos como el robot de Leonardo da Vinci con la apariencia externa de una armadura, capaz de mover piernas y brazos o el autómata creado por Pierre Jacques-Droz en 1774, su creación podía escribir una carta compuesta por 50 caracteres determinados por el usuario.</p>
<strong>Orígenes de la inteligencia artificial</strong>
<p>Si bien muchos consideran que el trabajo de Alan Turing “Computing Machinery and Intelligence” <span class="citation" data-cites="turing_compmach"></span> dio inicio al campo de la inteligencia artificial creo relevante mencionar primero el trabajo realizado por Warren McCulloch and Walter Pitts en 1943, ese año publicaron "A logical calculus of the ideas immanent in nervous activity", aquí describieron un modelo de neurona que sentó las bases de lo que serían en un futuro las redes neuronales (Técnicas ampliamente usadas en la actualidad).</p>
<p>Posteriormente en 1950 Turing publico el trabajo mencionado anteriormente donde habló acerca del Test que lleva su nombre, mediante el cual en lugar de determinar si una máquina está “pensando”, tratamos de averiguar si es capaz de ganar en “el juego de la imitación” (Haciendo pensar a un ser humano que está hablando con otro humano), este trabajo fue de gran relevancia para el campo de la IA. Además del Test de Turing se cuestiono acerca de si una máquina puede realmente pensar y escribío algunas ideas sobre el desarrollo de máquinas capaces de aprender, este articulo es una lectura que yo personalmente considero de suma importancia para aquellos interesados en esta área.</p>
<strong>Nacimiento de la inteligencia artificial como ciencia</strong>
<p>La conferencia de Dartmouth (“Dartmouth Summer Research Project on Artificial Intelligence”), realizada en 1956 y que duró 2 meses, es considerada como el evento que dio como resultado el nacimiento de la Inteligencia artificial como ciencia.</p>
<p>En 1955 fue John McCarthy quien decidió organizar un grupo para estudiar la siguiente conjetura: cada aspecto del aprendizaje o característica de la inteligencia puede en principio ser descrito de manera tan precisa que una máquina pueda simularlo. A continuación muestro la propuesta de la conferencia <span class="citation" data-cites="DARTHMOUTH"></span>:</p>
<p>“We propose that a 2-month, 10-man study of artificial intelligence be carried out during the summer of 1956 at Dartmouth College in Hanover, New Hampshire. The study is to proceed on the basis of the conjecture that every aspect of learning or any other feature of intelligence can in principle be so precisely described that a machine can be made to simulate it. An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves. We think that a significant advance can be made in one or more of these problems if a carefully selected group of scientists work on it together for a summer.”</p>
<p>Es aquí donde de forma oficial se introduce el término Inteligencia Artificial. (Si bien es un término que ya se había utilizado fue aquí donde se popularizó y se convirtió en el término dominante). Entre aquellos que asistieron se encuentran el Dr. Marvin Minsky, Herbert A. Simon, Allen Newell, Ray Solomonoff, John Henry Holland, entre otros. En este evento se discutieron diferentes acercamientos para crear soluciones de Inteligencia Artificial, los asistentes mencionados terminaron teniendo un alto impacto en esta ciencia.</p>
<strong>La edad de oro 1956-1974</strong>
<p>A la conferencia de Dartmouth le siguió un gran entusiasmo en el campo de la inteligencia artificial, incluso se estimaba que en 20 años se tendrían máquinas completamente inteligentes, a pesar de que era demasiado optimista si hubo avances durante este periodo de tiempo.</p>
<p>Entre los trabajos más relevantes se encuentran algoritmos que usan el paradigma “Reasoning as search”, en los cuales se aproximaba a la solución de problemas paso a paso como si de un laberinto se tratará, retrocediendo al llegar callejón sin salida, Allen Newell y Herbert A. Simon trataron de capturar una versión general de este algoritmo. También se dieron avances en el reconocimiento del lenguaje general, ELIZA desarrollado en el MIT permitía conversar mediante frases preprogramadas. A finales de 1960 Marvin Minsky y Seymour Papert propusieron que el estudio de la inteligencia artificial debía dirigirse a solucionar problemas en situaciones simples un enfoque denominado como micro-mundos, Minsky y Papert desarrollaron un robot que era capaz de apilar cubos. También se desarrolló el Perceptrón un tipo de red neuronal artificial que veremos más adelante en este libro.</p>
<strong>El primer invierno de la inteligencia artificial 1974-1980</strong>
<p>Debido a las altas expectativas desarrolladas previamente hubo una gran decepción al ver que las promesas de la Inteligencia Artificial no se cumplían. Hubo un gran recorte en los presupuestos de investigación y el campo de las redes neuronales fue mayormente ignorado debido a las fuertes críticas de Minsky sobre las limitaciones del perceptrón.</p>
<strong>El boom de la inteligencia artificial 1980–1987</strong>
<p>La llegada de sistemas expertos (capaces de tomar decisiones como si fuese un experto humano mediante el uso de reglas lógicas) permitieron un nuevo boom en la Inteligencia Artificial gracias a su utilidad en las empresas.</p>
<p>Otro punto importante es el resurgimiento de las redes neuronales, gracias a las redes de Hopfield y el desarrollo del algoritmo de retropropagación.</p>
<strong>El segundo invierno de la inteligencia artificial 1987-1993</strong>
<p>Durante este tiempo se dio otra reducción en las inversiones hacia el campo de la IA, sin embargo hubo avances principalmente en el campo de la robótica. Personalmente considero que una de las razones por las cuales tuvo lugar este segundo invierno de la IA son las desventajas o limitaciones de los sistemas expertos:</p>
<ul>
<li><p>Existen tareas demasiado complejas, la necesidad de diseñar estas reglas de manera manual es una limitante.</p></li>
<li><p>Existe conocimiento en constante cambio, muchos sistemas expertos requieren que las reglas sean actualizadas manualmente lo cual puede llegar a ser un problema.</p></li>
<li><p>Estos sistemas suelen contener conocimiento de un área específica pero carecen de sentido común.</p></li>
</ul>
<strong>Siglo XXI</strong>
<p>Como mencione en el prólogo gracias a el aumento de potencia computacional y el acceso a grandes cantidades de información la Inteligencia Artificial ha visto grandes avances, entre los avances más notorios se encuentran las investigaciones y algoritmos de machine learning y deep learning.</p>
<h2 data-number="2.2" id="fundamentos-de-la-ia"><span class="header-section-number">2.2</span> Fundamentos de la IA</h2>
<strong>Definición</strong>
<p>Existen diferentes definiciones del término inteligencia artificial, de acuerdo a las ciencias de la computación la inteligencia artificial es el estudio de agentes inteligentes <span class="citation" data-cites="logical_approach"></span>.</p>
<p>Un agente inteligente es capaz de percibir su entorno y actuar sobre él tratando de optimizar algún objetivo, un agente es inteligente debido a que presenta características como el razonamiento o el aprendizaje.</p>
<figure>
<img src="pandocConversionMedia/ia/Agente.png" id="fig:agente" style="width:7.5cm" alt="Representación de un agente" /><figcaption aria-hidden="true">Representación de un agente</figcaption>
</figure>
<p>Otra definición determina que la inteligencia artificial es el desarrollo de sistemas capaces de interpretar correctamente información externa, aprender de esta información para cumplir con ciertos objetivos o tareas adaptándose de manera flexible <span class="citation" data-cites="KAPLAN201915"></span>.</p>
<p>Dependiendo de la definición diversos tipos de desarrollos pueden considerarse inteligentes o no, por ello yo prefiero una definición más abierta como la siguiente: la inteligencia artificial es la simulación de comportamientos inteligentes por parte de un sistema informático.</p>
<p><strong>Ciencias relacionadas con la IA</strong> La inteligencia artificial se relaciona con diversas ciencias que sirven de base para el desarrollo de esta ciencia, algunos ejemplos son los siguientes:</p>
<ul>
<li><p>Filosofía</p></li>
<li><p>Lógica/matemática</p></li>
<li><p>Ciencias computacionales</p></li>
<li><p>Psicología</p></li>
<li><p>Biología</p></li>
<li><p>Neurociencia</p></li>
</ul>
<p>Es evidente como estas ciencias han ayudado al desarrollo de la inteligencia artificial, gracias a la teoría de la evolución se lograron generar algoritmos evolutivos, el estudio del cerebro nos dio ideas sobre la manera de tratar problemas como el reconocimiento de imágenes, la lógica nos permitió modelar la manera en la cual razonamos y gracias a la matemática somos capaces de formalizar los modelos para poder implementarlos en los sistemas desarrollados.</p>
<strong>Paradigmas de la inteligencia artificial</strong>
<p>De acuerdo a Palma y Marín <span class="citation" data-cites="marin2008inteligencia"></span> existen 4 paradigmas principales:</p>
<ol>
<li><p>Simbólico o representacional: El conocimiento se representa por medio de descripciones declarativas y en lenguaje natural, éstos son los hechos, otro conjunto de conocimientos son las reglas de inferencia que describen las relaciones sobre los hechos, al aplicar dichas reglas sobre un conjunto de conceptos de entrada se razona y se obtiene una inferencia. Un ejemplo de este tipo de desarrollos son los sistemas expertos, este paradigma fue dominante desde 1956 a 1986.</p></li>
<li><p>Situado o reactivo: Toda conducta es resultado de una percepción, por lo cual éstas se tienen una conexión directa, condicionada o secuencial.</p></li>
<li><p>Conexionista: Describe que los problemas pueden ser resueltos por unidades pequeñas interconectadas entre sí. Las unidades pueden ser neuronas, genes, agentes inteligentes, etc. Este paradigma corresponde a las redes neuronales artificiales (RNA) se definen modelos con entradas y salidas en los cuales se ajustan parámetros de la red mediante diferentes algoritmos de aprendizaje. Dentro de este paradigma también entran los algoritmos evolutivos y sistemas multiagentes.</p></li>
<li><p>Híbrido: Para resolver diversos problemas existe la necesidad de integrar soluciones que corresponden a distintos paradigmas, por ello los sistemas híbridos son de gran utilidad para problemas reales.</p></li>
</ol>
<p>Una ventaja del paradigma simbólico es que es fácil interpretar lo que sucede dentro del sistema, en cambio en sistemas conexionistas suele ser complicado determinar las razones detrás de una decisión, sin embargo, actualmente se han desarrollado técnicas como Grad-CAM <span class="citation" data-cites="gradcam"></span> que permiten reducir esta incertidumbre en el campo de clasificación de imágenes.</p>
<p>En la siguiente figura se muestran distintas categorías de técnicas de inteligencia artificial.</p>
<figure>
<img src="pandocConversionMedia/ia/ai_taxonomy.png" id="fig:ai_taxonomy" style="width:13cm" alt="Clasificación de técnicas de inteligencia artificial" /><figcaption aria-hidden="true">Clasificación de técnicas de inteligencia artificial</figcaption>
</figure>
<h1 data-number="3" id="parte-tres-técnicas-clásicas"><span class="header-section-number">3</span> Parte tres: Técnicas clásicas</h1>
<h2 data-number="3.1" id="búsquedas-inteligentes"><span class="header-section-number">3.1</span> Búsquedas inteligentes</h2>
<strong>Introducción al capítulo</strong>
<p>Antes de empezar a hablar directamente sobre estos temas relacionados principalmente con los grafos quiero hacer mención de un fenómeno descrito por John McCarthy “As soon as it works, no one calls it AI any more”; ésta frase me parece particularmente interesante debido a que la delimitación de los temas que comprenden la inteligencia artificial como ciencia no están perfectamente definidos, habrá autores que consideren estos temas como una rama de las estructuras de datos y no como parte de esta ciencia.</p>
<p>En los inicios de la inteligencia artificial era sorprendente cuando una máquina lograba algo remotamente inteligente y el asombro llevaba a generar altas expectativas del alcance de esta ciencia. Hoy en día quizá no se vea como algo tan sorprendente pero debido a que algunos de estos algoritmos nacieron siendo parte de la inteligencia artificial he decidido dedicarle una pequeña sección.</p>
<p>En este capítulo no profundizaré en las diversas técnicas de búsquedas inteligentes, en cambio revisaremos un ejemplo fuertemente ligado a la historia de la inteligencia artificial; sin embargo a continuación proporcionaré un link a el libro inteligencia artificial: introducción y tareas de búsqueda de Roberto J. de la Fuente López. (<a href="http://www.aconute.es/iartificial/documentos/ia_intro_busqueda.pdf ">http://www.aconute.es/iartificial/documentos/ia_intro_busqueda.pdf </a>) para aquellos que deseen abordar de una manera más amplia el tema.</p>
<strong>¿Qué es una búsqueda inteligente?</strong>
<p>Una búsqueda inteligente es aquel algoritmo que nos permita recorrer una estructura de datos de manera eficiente para obtener una solución potencialmente óptima.</p>
<strong>La IA que venció al campeón del mundo</strong>
<p>Son famosos los juegos entre Garry Kasparov y Deep blue, antes de ver el funcionamiento de esta computadora veremos un poco de la historia de estos encuentros.</p>
<p>Es poco mencionado el hecho de que Kasparov ganó la primera partida en 1996, se dieron seis juegos de los cuales 3 fueron ganados por Kasparov y uno por Deep Blue, los otros terminaron en empate. (Link de la victoria de Kasparov sobre Deep Blue: <a href="http://hemeroteca.abc.es/nav/Navigate.exe/hemeroteca/madrid/abc/1996/02/19/084.html ">http://hemeroteca.abc.es/nav/Navigate.exe/hemeroteca/madrid/abc/1996/02/19/084.html </a>)</p>
<p>En la partida de 1997 Deep Blue derrotó a Kasparov, este último ganó un solo juego y Deep Blue ganó 2, los otros 3 quedaron en empate. Algo interesante es el hecho de que Kasparov acusó de hacer trampa a IBM <span class="citation" data-cites="hsu2004behind"></span> después del segundo juego ya que mostraba signos de inteligencia o creatividad, IBM negó esto y dijo que solo se había dado intervención humana entre los juegos (lo cual estaba permitido en las reglas acordadas).</p>
<strong>¿Cómo funcionaba Deep Blue?</strong>
<p>El algoritmo detrás de Deep Blue no es tan inteligente como hace parecer, incluso uno de sus programadores (Joe Hoane) menciona en una entrevista que no es un proyecto de inteligencia artificial cuando se le preguntó cuánto de su trabajo era dedicado específicamente a la inteligencia artificial en emular el pensamiento humano <span class="citation" data-cites="DBFORBES"></span>.</p>
<p>Las principales características de Deep Blue eran las siguientes <span class="citation" data-cites="CAMPBELL200257"></span>:</p>
<ul>
<li><p>Libro de jugadas iniciales: Esto le permitía a la computadora realizar buenos movimientos iniciales</p></li>
<li><p>Hardware especializado: Deep Blue contaba con chips especializados que permitían evaluar tableros de ajedrez con una gran rapidez, la función de evaluación contaba con más de 8000 características y cada chip tenía una velocidad de búsqueda de 2 a 2.5 posiciones por segundo.</p></li>
<li><p>Paralelización de búsqueda: Deep Blue era un sistema con alta paralelización contando con más de 500 procesadores disponibles para realizar el árbol de búsqueda.</p></li>
</ul>
<p>El algoritmo de búsqueda que utilizó Deep Blue está basado en el algoritmo alpha-beta que se detallará más adelante en este capítulo.</p>
<p>Si se quiere profundizar a detalle en el funcionamiento del sistema de esta computadora recomiendo leer el siguiente articulo (<a href="https://doi.org/10.1016/S0004-3702(01)00129-1">https://doi.org/10.1016/S0004-3702(01)00129-1</a>).</p>
<strong>El algoritmo Minimax</strong>
<p>El algoritmo de minimax nos permite elegir el mejor movimiento en un juego con adversario considerando que éste último siempre escogerá el peor movimiento para nosotros (el mejor para él).</p>
<p>En el juego existen dos jugadores:</p>
<ol>
<li><p>Maximizador (MAX): trata de obtener la puntuación más alta.</p></li>
<li><p>Minimizador (MIN): trata de obtener la puntuación más baja.</p></li>
</ol>
<p>Algoritmo de minimax con movimientos alternativos:</p>
<ol>
<li><p>Generación del árbol de juego. Se generarán todos los nodos hasta llegar a un estado terminal (o a alguna condición determinada).</p></li>
<li><p>Uso de función de evaluación sobre los nodos terminales.</p></li>
<li><p>Calcular el valor de los nodos superiores a partir del valor de los inferiores, dependiendo de si el nivel corresponde a MAX o MIN se escogerá el valor más alto o más bajo.</p></li>
<li><p>Elegir la jugada valorando los valores que han llegado al nivel superior. Para ilustrar el funcionamiento de este algoritmo a continuación mostraré en imágenes los diferentes pasos con el ejemplo del juego de gato (Si X gana el estado vale 1, Si O pierde el estado vale -1, Si se empata el valor es 0):</p></li>
</ol>
<figure>
<img src="pandocConversionMedia/ia/generación_edos.png" id="fig:gen_edos_minimax" style="width:9.5cm" alt="Generación de estados" /><figcaption aria-hidden="true">Generación de estados</figcaption>
</figure>
<figure>
<img src="pandocConversionMedia/ia/evaluacion_edos_finales.png" id="fig:ev_edos_minimax" style="width:11.5cm" alt="Evaluación de estados finales" /><figcaption aria-hidden="true">Evaluación de estados finales</figcaption>
</figure>
<figure>
<img src="pandocConversionMedia/ia/propagación_edos.png" id="fig:prop_edos_minimax" style="width:11.5cm" alt="Cálculo de los valores en los nodos superiores" /><figcaption aria-hidden="true">Cálculo de los valores en los nodos superiores</figcaption>
</figure>
<figure>
<img src="pandocConversionMedia/ia/eleccion_edo.png" id="fig:elec_edos_minimax" style="width:13.5cm" alt="Elección de estado o jugada" /><figcaption aria-hidden="true">Elección de estado o jugada</figcaption>
</figure>
<p>El algoritmo MINIMAX es un procedimiento recursivo, a continuación se presenta el pseudocódigo correspondiente, se recomienda al lector analizar como el siguiente pseudocódigo hace lo mismo que se describió con anterioridad.</p>
<div class="algorithm">

</div>
<p>Es importante notar que dependiendo del “juego” sobre el cuál se esté aplicando este algoritmo varía la función de evaluación y la función sucesor, encargada de generar los nuevos estados.</p>
<p>En el pseudocódigo descrito con anterioridad se generan todos los estados finales posibles, en el juego de gato esto no es un gran problema ya que el número de estados posibles es relativamente pequeño (alrededor de 362,800), sin embargo en otros juegos como el ajedrez este número es mucho más alto por lo cual se puede verificar a qué nivel de profundidad pertenece el nodo y si se ha llegado a ese límite establecido previamente evaluar el nodo aunque no sea un estado final, esto implica además el tener que generar funciones de evaluación más complejas ya que en ese punto no se puede saber con certeza si el jugador ganará o perderá.</p>
<p>Otra nota importante es que en este pseudocódigo es en los nodos donde se almacena el resultado de la evaluación, esto también podría hacerse implementando una tupla (nodo, valor) y devolviendo esta estructura en la función MINIMAX.</p>
<div class="center">
<p>(1,0)<span>420</span></p>
</div>
<p><strong>Ejercicio de programación:</strong></p>
<p>Yo recomiendo realizar el siguiente ejercicio para fortalecer los conocimientos adquiridos: En cualquier lenguaje de programación programar una inteligencia artificial capaz de jugar gato utilizando el algoritmo Minimax. A continuación se presenta un enlace, se debe hacer una copia del notebook y seguir las instrucciones.</p>
<p>(Ejercicio para completar: <a href="https://colab.research.google.com/drive/1xX4vcx6G0Dj_9XW5cml_lOnZnLIPb65T?usp=sharing">https://colab.research.google.com/drive/1xX4vcx6G0Dj_9XW5cml_lOnZnLIPb65T?usp=sharing</a>)</p>
<p>(Ejemplo minimax web: <a href="https://github.com/amr205/TicTacToe-AI---Minimax">https://github.com/amr205/TicTacToe-AI---Minimax</a>)</p>
<p><img src="pandocConversionMedia/Pictures/github/minimax.png" style="width:5cm" alt="image" /></p>
<strong>El algoritmo Alpha-beta pruning</strong>
<p>El algoritmo Alpha-beta pruning tiene el objetivo de realizar la misma tarea que el algoritmo Minimax sin embargo poda las ramas que no necesitan ser revisadas, sigue regresando el mismo resultado que el algoritmo minimax pero reduce el nivel de nodos que visita.</p>
<p>En este caso incluiré primero el pseudocódigo y posteriormente procederé a explicar el funcionamiento de este algoritmo.</p>
<div class="algorithm">

</div>
<p>Se puede observar que el funcionamiento es muy similar al algoritmo Minimax pero se utilizan dos variables, alpha y beta. Se puede observar que alpha guardaría el mejor estado posible que el maximizador tiene, y beta el mejor estado posible para el minimizador, por la manera en la que se visitan los nodos cuando beta es menor o igual no tiene mucho sentido continuar revisando la rama ya que el jugador contrario ya tiene una mejor opción en un nivel superior.</p>
<p>Un ejemplo de cómo funciona puede ser muy útil para entender el funcionamiento de este algoritmo, en lo personal considero que el siguiente video de Sebastian Lague muestra un ejemplo muy completo y descrito paso por paso (<a href="https://youtu.be/l-hh51ncgDI?t=546">https://youtu.be/l-hh51ncgDI?t=546</a>).</p>
<div class="center">
<p>(1,0)<span>420</span></p>
</div>
<p><strong>Ejercicio de programación:</strong></p>
<p>Yo recomiendo realizar el siguiente ejercicio para fortalecer los conocimientos adquiridos:</p>
<p>En cualquier lenguaje de programación programar una inteligencia artificial capaz de jugar ajedrez utilizando el algoritmo Alpha-beta pruning.</p>
<p>(Ejemplo: <a href="https://github.com/amr205/Chess-AI-using-Alpha-Beta-pruning">https://github.com/amr205/Chess-AI-using-Alpha-Beta-pruning</a>)</p>
<p><img src="pandocConversionMedia/Pictures/github/alphabeta.png" style="width:5cm" alt="image" /></p>
<h2 data-number="3.2" id="algoritmos-evolutivos"><span class="header-section-number">3.2</span> Algoritmos evolutivos</h2>
<strong>Introducción al capítulo</strong>
<p>Estos algoritmos inspirados en la evolución natural son útiles debido a que nos permiten tratar problemas que con técnicas de búsqueda no informada requerirían de un tiempo de proceso demasiado grande y con técnicas de búsqueda informada corren el riesgo de llegar a un óptimo local.</p>
<p>Una ventaja de los algoritmos evolutivos es que se requiere solo una pequeña cantidad de conocimiento específico sobre el problema que se está tratando, en concreto la función de evaluación (Fitness function) que debe ser optimizada en el proceso <span class="citation" data-cites="streichert2002introduction"></span>, más adelante en este capítulo serán más evidentes las razones que llevan a esta afirmación.</p>
<strong>Orígenes</strong>
<p>Desde la década de los 50s los científicos han estudiado este tipo de algoritmos, en 1954 Nils Barricelli creó el primer algoritmo genético que imitaba la reproducción y mutación natural, su objetivo no era resolver problemas de optimización, sino crear vida artificial. Durante los siguientes años científicos como Alexander Fraser usaron su trabajo, Fraser quería simular la evolución debido a que observarla de manera directa en nuestro mundo requeriría de millones de años.</p>
<p>John Holland es considerado una de las personas más importantes en el campo de los algoritmos genéticos, ya que él introdujo el uso de una población para evaluarla y posteriormente usar procesos como el crossover, recombination, etc. En 1975 publicó su libro que sería la base teórica de muchos trabajos posteriores.</p>
<p>En 1988 John Koza, patentó su idea de usar algoritmos evolutivos para la generación de programas, continuó su trabajo con múltiples publicaciones relacionadas con la programación genética, por lo cual su trabajo es de mucha importancia en esta área de los algoritmos evolutivos.</p>
<p>En 1986 Holland sentó las bases de los sistemas clasificadores (LCS), estos algoritmos tenían el objetivo de solucionar la tarea de clasificación y utilizan elementos de aprendizaje y algoritmos genéticos, Stewart Wilson continuó el desarrollo de nuevos sistemas clasificadores como el “Zeroth-level” usando métodos más modernos de aprendizaje reforzado.</p>
<strong>Definición</strong>
<p>Los algoritmos evolutivos tienen su base en la selección natural, una definición que yo considero apropiada es la siguiente: Los algoritmos evolutivos mediante la heurística son capaces de resolver tareas de optimización imitando aspectos de la evolución natural, suelen trabajar en poblaciones completas de posibles soluciones para una determinada tarea (Streichert, 2002).</p>
<p><strong>NOTA: Diferencia entre un algoritmo evolutivo y un algoritmo genético</strong></p>
<p>Un algoritmo genético es una subclase de los algoritmos evolutivos. Todo algoritmo evolutivo está basado en las leyes de la evolución natural, un algoritmo genético tiene sus bases en el uso de poblaciones, cruzamiento o recombinación (crossover) y mutación. En cambio otros tipos de algoritmos evolutivos se basan principalmente en la mutación.</p>
<strong>Clasificación</strong>
<p>Existen distintos tipos de algoritmos evolutivos, en este capítulo se revisarán aquellos más populares, sin embargo también hay sistemas y algoritmos que presentan un comportamiento híbrido, estos algoritmos no serán cubiertos hasta que se hayan visto los temas necesarios para poder abordarlos de manera completa, un ejemplo de esto último es el algoritmo NEAT (NeuroEvolution of Augmenting Topologies) que combina los algoritmos genéticos con el paradigma conexionista.</p>
<p>A continuación se presentan los tipos de algoritmos evolutivos más comunes:</p>
<figure>
<img src="pandocConversionMedia/ia/AE clasificación.png" id="fig:classification-ae" style="width:14cm" alt="Clasificación de los algoritmos evolutivos más comunes" /><figcaption aria-hidden="true">Clasificación de los algoritmos evolutivos más comunes</figcaption>
</figure>
<strong>Algoritmos genéticos</span> <span id="section:Algoritmos-geneticos" label="section:Algoritmos-geneticos">[section:Algoritmos-geneticos]</strong>
<p>Los componentes principales de los algoritmos genéticos son los siguientes:</p>
<ul>
<li><p>Una función de evaluación a optimizar (fitness function)</p></li>
<li><p>Una población de cromosomas</p></li>
<li><p>Un operador de selección</p></li>
<li><p>Un operador de cruzamiento</p></li>
<li><p>Un operador de mutación</p></li>
</ul>
<p>Antes de describir éstas partes, veamos el funcionamiento básico del algoritmo.</p>
<ol>
<li><p>Se genera una población inicial</p></li>
<li><p>Se evalúa la población (si algún elemento supera algún nivel barrera se da por terminado el algoritmo)</p></li>
<li><p>Se seleccionan los mejores individuos de la población y se guardan en un grupo(en inglés a este grupo se le llama mating pool)</p></li>
<li><p>Se seleccionan pares del grupo generado y se aplica el operador de cruzamiento, también se aplica el operador de mutación de acuerdo a una tasa de mutación determinada por el desarrollador, al terminar la generación de la población se vuelve al paso 2.</p></li>
</ol>
<figure>
<img src="pandocConversionMedia/ia/GA.png" id="fig:df-ga" style="width:5.5cm" alt="Diagrama de flujo de un algoritmo genético" /><figcaption aria-hidden="true">Diagrama de flujo de un algoritmo genético</figcaption>
</figure>
<p>A continuación se presenta un pseudocódigo de la implementación de un algoritmo genético simple, se recomienda leerlo y regresar a esta figura cuando se realice el ejercicio de programación propuesto.</p>
<figure>
<img src="pandocConversionMedia/ia/pse-ga.png" id="fig:pse-ga" style="width:13cm" alt="Pseudocódigo del Algoritmo Genético Simple, Figura tomada de Algoritmos Genéticos. 3 de Febrero 2020, de Universidad del País Vasco Sitio web: http://www.sc.ehu.es/ccwbayes/docencia/mmcc/docs/temageneticos.pdf" /><figcaption aria-hidden="true">Pseudocódigo del Algoritmo Genético Simple, Figura tomada de Algoritmos Genéticos. 3 de Febrero 2020, de Universidad del País Vasco Sitio web: http://www.sc.ehu.es/ccwbayes/docencia/mmcc/docs/temageneticos.pdf</figcaption>
</figure>
<strong>Población</strong>
<p>Estos algoritmos trabajan sobre una población de cromosomas, el término cromosoma hace referencia a un valor o conjunto de valores que representan a una posible solución o individuo. A cada uno de estos valores dentro del cromosoma se les llama gen.</p>
<figure>
<img src="pandocConversionMedia/ia/GA población, cromosoma, gen.png" id="fig:pob-crom-gen" style="width:13cm" alt="Población, cromosoma y gen" /><figcaption aria-hidden="true">Población, cromosoma y gen</figcaption>
</figure>
<p>chromosome = [p1,p2,...,pNpar]</p>
<p><strong>NOTA: Diferencia entre genotipo y fenotipo</strong></p>
<p>Al momento de hablar sobre la representación de los individuos de la población se suelen utilizar los términos genotipo y fenotipo, estos términos fueron creados por Wilhelm Johannsen en 1911, el genotipo es la información hereditaria completa de un organismo y el fenotipo son las propiedades observadas. En el campo de los algoritmos genéticos, el genotipo es una representación de bajo nivel (con menos abstracción) que el fenotipo.</p>
<figure>
<img src="pandocConversionMedia/ia/ga - genotipo vs fenotipo.png" id="fig:dif-gen-fen" style="width:13cm" alt="Diferencia entre genotipo y fenotipo" /><figcaption aria-hidden="true">Diferencia entre genotipo y fenotipo</figcaption>
</figure>
<p>Es importante hacer notar que los genes no tienen que ser de tipo binario; un carácter o un elemento de alguna estructura (como un árbol) puede ser un gen por sí mismo.</p>
<p>Generalmente la población inicial es creada con valores al azar, un parámetro importante que el desarrollador debe determinar es el tamaño de la población ya que si el número es muy reducido no se tendrá suficiente variación y es posible que los individuos nunca sobrepasen un óptimo local, también se debe evitar poblaciones muy grandes para evitar la redundancia y para reducir el tiempo necesario para llegar a una solución adecuada.</p>
<strong>Evaluación</strong>
<p>Para realizar la evaluación de los individuos se requiere tener conocimiento detallado sobre el problema que se está abordando, en algunas ocasiones se requiere realizar una simulación para encontrar el valor de aptitud (Fitness value), es común mantener el máximo valor en 1 y el menor en 0, para favorecer a los individuos con mejor aptitud se puede elevar a alguna potencia.</p>
<p>No siempre se trata de satisfacer un solo objetivo por lo cual a veces se tendrán distintas funciones enfocadas a evaluar los diferentes objetivos y estos deberán ser integrados en un solo valor.</p>
<p>Otra situación importante son los problemas con restricciones, para esto voy a proponer un ejemplo. Si quisiéramos diseñar un algoritmo genético capaz de resolver un sudoku, es probable que definiéramos el problema de la siguiente manera:</p>
<figure>
<img src="pandocConversionMedia/ia/sudoku ga - genotipo vs fenotipo.png" id="fig:sudoku-gen-fen" style="width:11cm" alt="Genotipo y fenotipo en un problema de resolución de sudoku" /><figcaption aria-hidden="true">Genotipo y fenotipo en un problema de resolución de sudoku</figcaption>
</figure>
<p>Como se puede observar en la imagen anterior cada gen es un número del 1 al 9 que representa el valor que tendría en la casilla de la cuadrícula. Sin embargo se presentan ciertas restricciones:</p>
<ol>
<li><p>No se pueden repetir números en un mismo renglón.</p></li>
<li><p>No se pueden repetir números en una misma columna.</p></li>
<li><p>No se pueden repetir números dentro de la misma subcuadrícula.</p></li>
<li><p>Se deben respetar los valores asignados a las casillas dados al momento de plantear el problema.</p></li>
</ol>
<p>Para solucionar problemas con restricciones se pueden tomar diferentes medidas, las más comunes son reparación y penalización, la reparación evita que las restricciones sean violadas y la penalización disminuye el valor de aptitud de un individuo, más adelante se revisará la medida de reparación; en este subtema de evaluación se describe el proceso de penalización.</p>
<p>En este problema específico se podría tener una función como la siguiente:</p>
<p><span class="math inline">\(F(I) = \frac{(243-x-y-z)}{243}\)</span></p>
<p>Siendo x el número de casillas repetidas en los renglones, y el número de casillas repetidas en las columnas y z el número de casillas repetidas en las subcuadrículas. En este problema la función depende altamente de las restricciones, pero supongamos que hacemos un algoritmo genético cuya función sea conducir en el menor tiempo posible con la restricción de no chocar ningún obstáculo, entonces podríamos definir una función que considerará el tiempo pero disminuyera la aptitud según el número de obstáculos golpeados.</p>
<p><span class="math inline">\(F(I) = \frac{(300-T-40*O)}{100}\)</span></p>
<p>Siendo T el tiempo que se tardó el individuo en recorrer la pista y O el número de obstáculos golpeados.</p>
<strong>Selección</span><span id="selection:pse-ga" label="selection:pse-ga">[selection:pse-ga]</strong>
<p>El proceso para la generación de una nueva población involucra el seleccionar padres para realizar el cruzamiento y la mutación, existen diversos métodos utilizados para realizar la selección de los padres, en este libro se explorarán las siguientes opciones <span class="citation" data-cites="SELECTION"></span>:</p>
<ol>
<li><p>Selección por ruleta (Roulette Wheel Selection)</p></li>
<li><p>Muestreo universal estocástico (Stochastic Universal Sampling)</p></li>
<li><p>Selección por rango lineal (Linear Rank Selection)</p></li>
<li><p>Selección por rango exponencial(Exponential Rank Selection)</p></li>
<li><p>Selección por torneo (Tournament Selection)</p></li>
<li><p>Selección por truncamiento (Truncation Selection)</p></li>
</ol>
<p><u>Selección por ruleta</u></p>
<p>En este método la probabilidad de un individuo para ser elegido como padre es directamente proporcional a su valor de aptitud.</p>
<p><span class="math inline">\(p(i)=\frac{f(i)}{\sum_{j=1}^{n} f(j)}\)</span></p>
<p>Donde n es el tamaño de la población y f(i) es la aptitud del individuo i</p>
<p>Una manera de implementar este método es el siguiente:</p>
<ul>
<li><p>Calcular el valor de <span class="math inline">\(S\)</span> (<span class="math inline">\(S = \sum_{j=1}^{n} f(j)\)</span>)</p></li>
<li><p>Inicializar en 0 las variables: <span class="math inline">\(p_{acumulada}\)</span> y <span class="math inline">\(j\)</span></p></li>
<li><p>Generar un número al azar <span class="math inline">\(\alpha\)</span> entre los valores 0 y <span class="math inline">\(S\)</span></p></li>
<li><p>Mientras <span class="math inline">\(p_{acumulada}&lt;\alpha\)</span> y <span class="math inline">\(j&lt;n\)</span>:</p>
<ul>
<li><p><span class="math inline">\(p_{acumulada} = p_{acumulada} + f(j)\)</span></p></li>
<li><p><span class="math inline">\(j = j+1\)</span></p></li>
</ul></li>
<li><p>Fin del ciclo</p></li>
<li><p>Seleccionar individuo j</p></li>
</ul>
<p>Una desventaja de este método es el riesgo que existe donde el algoritmo genético termina de manera prematura en un óptimo local, esto debido a la presencia de un individuo con una aptitud considerablemente superior a la del resto de la población.</p>
<p><u>Muestreo universal estocástico</u></p>
<p>Este método, desarrollado por Baker en 1987, es una variación del anterior y pretende eliminar el riesgo de convergencia prematura en un óptimo local. Consiste en generar un número aleatorio <span class="math inline">\(\alpha\)</span> entre 0 y P (siendo P el promedio de la aptitud de los individuos) y posteriormente elegir a n individuos espaciados de manera uniforme (el valor de espaciado <span class="math inline">\(\beta\)</span> suele ser el promedio de la aptitud pero no es una regla).</p>
<figure>
<img src="pandocConversionMedia/ia/GA SUS.png" id="fig:ga-sel-mue" style="width:13cm" alt="Elección de 5 individuos mediante muestreo universal estocástico" /><figcaption aria-hidden="true">Elección de 5 individuos mediante muestreo universal estocástico</figcaption>
</figure>
<p>Existen diferentes implementaciones de este algoritmo, yo recomiendo utilizar el siguiente proceso para seleccionar m individuos.</p>
<ul>
<li><p>Calcular el valor de <span class="math inline">\(P\)</span> (<span class="math inline">\(P = \frac{1}{n} \sum_{i=1}^{n} f(i)\)</span>)</p></li>
<li><p>Inicializar en 0 las variables: <span class="math inline">\(p_{acumulada}\)</span>, <span class="math inline">\(j\)</span> y <span class="math inline">\(s\)</span></p></li>
<li><p>Generar un número al azar <span class="math inline">\(\alpha\)</span> entre los valores 0 y <span class="math inline">\(P\)</span></p></li>
<li><p>Mientras <span class="math inline">\(s&lt;m\)</span> y <span class="math inline">\(j&lt;n\)</span>:</p>
<ul>
<li><p><span class="math inline">\(p_{acumulada} = p_{acumulada} + f(j)\)</span></p></li>
<li><p><span class="math inline">\(j = j+1\)</span></p></li>
<li><p>Si <span class="math inline">\(p_{acumulada} &lt; \alpha+s*\beta\)</span></p>
<ul>
<li><p>Añadir elemento <span class="math inline">\(j\)</span> al conjunto <span class="math inline">\(C\)</span></p></li>
<li><p><span class="math inline">\(s = s+1\)</span></p></li>
</ul></li>
</ul></li>
<li><p>Fin del ciclo</p></li>
<li><p>Devolver conjunto <span class="math inline">\(C\)</span></p></li>
</ul>
<p><u>Selección por rango lineal</u></p>
<p>Este método pretende evitar la convergencia del algoritmo genético en un óptimo local, es importante hacer notar que una desventaja es que disminuye la diferencia que hay entre los mejores y peores individuos por lo que puede aumentar el tiempo de convergencia, además de aumentar el tiempo de proceso necesario durante la generación de los rangos.</p>
<p>De manera intuitiva se puede decir que se le da un rango de 1 al peor individuo y al mejor un rango n, siendo n el tamaño de la población.</p>
<figure>
<img src="pandocConversionMedia/ia/seleclineal.png" id="fig:ga-sel-lineal" style="width:14cm" alt="Ejemplo del cambio de probabilidad mediante el uso de selección por rango lineal (Derecha)" /><figcaption aria-hidden="true">Ejemplo del cambio de probabilidad mediante el uso de selección por rango lineal (Derecha)</figcaption>
</figure>
<p>La fórmula que se usa para determinar la nueva aptitud en este método es de tipo lineal, un ejemplo sería el siguiente:</p>
<p><span class="math inline">\(f(pos) = \alpha + \frac{pos}{n}\)</span></p>
<p>Mientras mayor sea el valor de <span class="math inline">\(\alpha\)</span> menor será la diferencia entre las probabilidades de los individuos, en la Figura <a href="#fig:ga-sel-lineal" data-reference-type="ref" data-reference="fig:ga-sel-lineal">2.8</a> se usó 0 como valor de <span class="math inline">\(\alpha\)</span>.</p>
<p>Otra fórmula que suele utilizarse es la siguiente:</p>
<p><span class="math inline">\(f(pos)=2-SP+\left ( 2*(SP-1)*\frac{pos-1}{n-1} \right )\)</span></p>
<p>SP corresponde al término en inglés Selective Pressure (presión selectiva) y <span class="math inline">\(2 \geq SP \geq 1\)</span>. A mayor presión selectiva más probabilidad de ser elegidos tienen los mejores individuos.</p>
<p>Para implementar este método se sugieren los siguientes pasos:</p>
<ol>
<li><p>Ordenar los individuos de acuerdo a su aptitud</p></li>
<li><p>Calcular la nueva aptitud de acuerdo a una fórmula lineal</p></li>
<li><p>Implementar selección por ruleta</p></li>
</ol>
<p><u>Selección por rango exponencial</u></p>
<p>Este método pretende aumentar la presión selectiva, se proponen diversas fórmulas, en este libro se sugiere la siguiente:</p>
<p><span class="math inline">\(f(pos)=exp(\frac{pos}{c})\)</span></p>
<p><span class="math inline">\(c= \frac{n*2*(n-1)}{6*(n-1)+n}\)</span></p>
<p>Existen distintos tipos de fórmulas que se pueden aplicar, es importante tratar de evitar fórmulas muy complejas que impacten altamente el tiempo de procesamiento, en la siguiente figura se observa una comparación que utiliza la fórmula propuesta aquí con anterioridad.</p>
<figure>
<img src="pandocConversionMedia/ia/sel-exp.png" id="fig:comp_metodos" style="width:14.5cm" alt="Comparación de probabilidad de selección entre tres métodos distintos" /><figcaption aria-hidden="true">Comparación de probabilidad de selección entre tres métodos distintos</figcaption>
</figure>
<p>Para implementar este método se sugieren los siguientes pasos:</p>
<ol>
<li><p>Ordenar los individuos de acuerdo a su aptitud</p></li>
<li><p>Calcular la nueva aptitud de acuerdo a una fórmula exponencial</p></li>
<li><p>Implementar selección por ruleta</p></li>
</ol>
<p><u>Selección por torneo</u></p>
<p>Este método consiste en obtener <span class="math inline">\(k\)</span> individuos y posteriormente seleccionar el individuo con mayor aptitud, este proceso se repite <span class="math inline">\(n\)</span> veces para obtener todos los padres.</p>
<p>La forma más fácil de implementar esta técnica es con <span class="math inline">\(k=2\)</span> se generan dos números aleatorios <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(\beta\)</span> de 0 al tamaño de la población y se selecciona el elemento <span class="math inline">\(\alpha\)</span> o <span class="math inline">\(\beta\)</span> con mayor aptitud.</p>
<p><u>Selección por truncamiento</u></p>
<p>Este método es bastante simple y no es muy utilizado en la práctica, su mayor caso de aplicación es en poblaciones de gran tamaño.</p>
<p>Consiste en ordenar los individuos de acuerdo a su aptitud y seleccionar una porción de los mismos para realizar la reproducción o cruzamiento entre ellos.</p>
<p>En el siguiente estudio Khalid Jeba <span class="citation" data-cites="SELECTION"></span> analiza los métodos aquí descritos para estudiar el número de generaciones necesarias para llegar a la convergencia, así como el óptimo obtenido, también se propone un nuevo método que busca obtener un mejor óptimo sin sacrificar mucho tiempo para llegar a la convergencia. (<a href="https://www.researchgate.net/publication/259009318_Parent_Selection_Operators_for_Genetic_Algorithms">https://www.researchgate.net/publication/259009318_Parent_Selection_Operators_for_Genetic_Algorithms</a>)</p>
<p>Otros métodos que me gustaría mencionar es la selección uniforme determinista que selecciona todos los elementos de la población para el cruzamiento, y la selección uniforme estocástica que selecciona elementos al azar de la población.</p>
<strong>Cruzamiento</strong>
<p>Los operadores de cruce nos ayudan a generar la siguiente población a evaluar, consisten en generar 1 o más hijos a partir de dos individuos padre, el uso de algoritmos de cruzamiento lleva a un mejor desempeño en comparación a solo utilizar mutación, esto es más evidente cuando se tienen poblaciones grandes <span class="citation" data-cites="CROSSOVER_Spears"></span>. Existen diversas maneras de realizar el cruzamiento, en este libro solo se revisarán algunos de los más comunes, más específicamente se revisarán los siguientes <span class="citation" data-cites="CROSSOVER_REVIEW"></span>: Cruce de 1 punto, Cruce de k puntos, Cruce uniforme y Cruce por promedio.</p>
<p><u>Cruce de 1 punto</u></p>
<p>Este es uno de los operadores de cruce más simples, dados dos individuos padres se elige un punto de cruce pi al azar, posteriormente se crean dos descendientes combinando los dos padres por el punto de cruce.</p>
<figure>
<img src="pandocConversionMedia/ia/GEC-1 punto.png" id="fig:gec-1-punto" style="width:15.5cm" alt="Ejemplo de cruce de 1 punto, en este caso el punto de cruce se encuentra entre el sexto y el séptimo gen" /><figcaption aria-hidden="true">Ejemplo de cruce de 1 punto, en este caso el punto de cruce se encuentra entre el sexto y el séptimo gen</figcaption>
</figure>
<p><u>Cruzamiento de k puntos</u></p>
<p>Este operador es muy similar al anterior, la diferencia consiste en el número de puntos de cruce, se eligen k puntos de cruce para generar los descendientes.</p>
<figure>
<img src="pandocConversionMedia/ia/GEC-k puntos.png" id="fig:gec-k-punto" style="width:15.5cm" alt="Ejemplo de cruce de k-puntos, en este caso se usan 3 puntos de cruce" /><figcaption aria-hidden="true">Ejemplo de cruce de k-puntos, en este caso se usan 3 puntos de cruce</figcaption>
</figure>
<p><u>Cruce uniforme</u></p>
<p>Este método consiste en combinar los genes de ambos padres, para cada gen se genera un número aleatorio que determina si el primer descendiente tomará el valor del gen del primer padre o del segundo.</p>
<p>El pseudocódigo es similar al siguiente, dados dos padres a, b y dos descendientes x, y:</p>
<ul>
<li><p>Para cada gen</p>
<ul>
<li><p>Sea h un número aleatorio entre 0 y 1</p></li>
<li><p>Si h &gt; 0.5</p>
<ul>
<li><p>El valor del gen para x es igual al valor del gen en a</p></li>
<li><p>El valor del gen para y es igual al valor del gen en b</p></li>
</ul></li>
<li><p>Sino</p>
<ul>
<li><p>El valor del gen para x es igual al valor del gen en b</p></li>
<li><p>El valor del gen para y es igual al valor del gen en a</p></li>
</ul></li>
</ul></li>
</ul>
<p><u>Cruce por promedio</u></p>
<p>Este operador se utiliza cuando se tienen genes de tipo entero o real, dados dos padres se genera un solo descendiente, el valor de cada gen es el promedio del valor de los genes de los padres.</p>
<figure>
<img src="pandocConversionMedia/ia/GEC-promedio.png" id="fig:GEC-promedio" style="width:14cm" alt="Ejemplo del uso del cruce por promedio" /><figcaption aria-hidden="true">Ejemplo del uso del cruce por promedio</figcaption>
</figure>
<p>En el siguiente enlace pueden encontrar más técnicas de cruzamiento, algunas técnicas como el cruzamiento promediado se ajustan muy bien a cierto tipo de problemas por lo cuál puede valer la pena leer el siguiente artículo para observar si existe algún algoritmo de cruzamiento que se adapte a nuestro problema (<a href="http://ictactjournals.in/paper/IJSC_V6_I1_paper_4_pp_1083_1092.pdf">http://ictactjournals.in/paper/IJSC_V6_I1_paper_4_pp_1083_1092.pdf</a>).</p>
<strong>Mutación</strong>
<p>La mutación permite que la población mantenga diversidad y mediante la generación de nuevos individuos no presentes en la población actual evita que el algoritmo converja en un valor prematuro.</p>
<p>Este operador se aplica sobre un cromosoma, dada una tasa de mutación (En inglés mutation rate) <span class="math inline">\(p_{m}\)</span> se genera un número aleatorio y si el número es menor a <span class="math inline">\(p_{m}\)</span> se realiza una o más modificaciones en los genes del individuo. En los algoritmos genéticos tradicionales (también llamados canónicos) el valor de <span class="math inline">\(p_{m}\)</span> es fijo, y solo se aplica un operador, sin embargo existen investigaciones que demuestran que es posible utilizar varios operadores con una tasa de mutación dinámica para cada operador, esto permite descubrir cuáles operadores son más útiles sin tener que realizar múltiples pruebas <span class="citation" data-cites="DYNAMIC_MUTATION"></span></p>
<p><u>Bit Flip Mutation</u></p>
<p>Este operador se aplica para genes con valor binario, se selecciona uno o más genes y se invierte su valor.</p>
<figure>
<img src="pandocConversionMedia/ia/Mutation-bitflip.png" id="fig:Mutation-bitflip" style="width:15cm" alt="Aplicación del operador de mutación “Bit Flip”" /><figcaption aria-hidden="true">Aplicación del operador de mutación “Bit Flip”</figcaption>
</figure>
<p><u>Random Resetting</u></p>
<p>Se selecciona uno o más genes y se le asigna al azar uno de los valores permitidos para el gen.</p>
<figure>
<img src="pandocConversionMedia/ia/Mutation-RANDOM RESET.png" id="fig:Mutation-RANDOMRESET" style="width:15cm" alt="Aplicación del operador de mutación “Random Resetting”" /><figcaption aria-hidden="true">Aplicación del operador de mutación “Random Resetting”</figcaption>
</figure>
<p><u>Swap Mutation</u></p>
<p>Consiste en seleccionar uno o más pares de genes e intercambiar su valor.</p>
<figure>
<img src="pandocConversionMedia/ia/Mutation-SWAP.png" id="fig:Mutation-SWAP" style="width:15cm" alt="Aplicación del operador de mutación “Swap mutation”" /><figcaption aria-hidden="true">Aplicación del operador de mutación “Swap mutation”</figcaption>
</figure>
<p><u>Scramble Mutation</u></p>
<p>Consiste en subconjunto de genes y ordenarlos de manera aleatoria para insertarlos nuevamente.</p>
<figure>
<img src="pandocConversionMedia/ia/Mutation-SCRABBLE.png" id="fig:Mutation-SCRABBLE" style="width:15cm" alt="Aplicación del operador de mutación “Scramble mutation”" /><figcaption aria-hidden="true">Aplicación del operador de mutación “Scramble mutation”</figcaption>
</figure>
<p><u>Inverse Mutation</u></p>
<p>Consiste en subconjunto de genes e invertir su orden para insertarlos nuevamente.</p>
<figure>
<img src="pandocConversionMedia/ia/Mutation-Inverse.png" id="fig:Mutation-Inverse" style="width:15cm" alt="Aplicación del operador de mutación “Inverse mutation”" /><figcaption aria-hidden="true">Aplicación del operador de mutación “Inverse mutation”</figcaption>
</figure>
<strong>Resolver problemas con restricciones</strong>
<p>Anteriormente en la sección correspondiente a la evaluación en los algoritmos genéticos se exploró el problema del sudoku como una situación donde existen restricciones, las tres maneras más comunes de implementar algoritmos con este tipo de problemas son las siguientes:</p>
<ol>
<li><p>Uso de Funciones de penalización que reducen severamente el valor de aptitud de los individuos que no satisfacen las restricciones.</p></li>
<li><p>Uso de Funciones de reparación que toman una solución y la modifican para que cumpla con todas las restricciones.</p></li>
<li><p>No permitir que se genere ningún individuo que no cumpla con las restricciones.</p></li>
</ol>
<strong>Elitismo en algoritmos genéticos</strong>
<p>El elitismo en los algoritmos genéticos consiste en asegurar que un porcentaje de los mejores individuos pasen a la siguiente generación de la población, se recomienda mantener este porcentaje por debajo del 10% para asegurar la diversidad de la población. Usualmente estos individuos pasan a la siguiente generación sin ninguna mutación, posteriormente se realiza el proceso de crossover y mutación de manera habitual para completar la nueva población.</p>
<p><strong>¿Porqué utilizar elitismo?</strong></p>
<p>Usar elitismo puede tener un alto impacto en el rendimiento de nuestro algoritmo (Aumentando la velocidad de convergencia) <span class="citation" data-cites="rani2019effectiveness"></span> debido a que no se tienen que re-descubrir soluciones que ya han probado tener una alta aptitud. De esta manera se asegura también que la aptitud del mejor individuo nunca va a reducirse a través del paso de las generaciones de la población.</p>
<p><strong>¿Porqué NO utilizar elitismo?</strong></p>
<p>Usar elitismo puede hacer al algoritmo converger en un óptimo local de manera prematura, esto depende también del porcentaje de la población que se use para aplicar el elitismo, mientras mayor sea el porcentaje mayor riesgo se corre de limitar el espacio de búsqueda de nuestro algoritmo.</p>
<p><strong>Implementación</strong></p>
<p>La manera más simple de implementar elitismo es ordenando los elementos de la población de acuerdo a su aptitud para posteriormente copiar el porcentaje de cromosomas determinados con anterioridad por el desarrollador, es importante no sobrescribir los valores de estos elementos por lo que solo se deben generar la cantidad de individuos restantes de la población.</p>
<strong>Aplicaciones de los algoritmos genéticos</strong>
<p>Los algoritmos genéticos resultan extremadamente para resolver problemas de parametrización, en problemas con múltiples óptimos locales las soluciones basadas en gradientes no suelen resolver el problema por lo cual los algoritmos genéticos son una buena alternativa.</p>
<ul>
<li><p>Machine learning: Se pueden utilizar los algoritmos genéticos para crear sistemas que aprendan reglas de producción o sistemas clasificadores (Wang, Bayer)</p></li>
<li><p>Multimodal optimization: Los algoritmos genéticos nos pueden ayudar a encontrar múltiples soluciones en contraste a solo una.</p></li>
<li><p>Problemas de ingeniería: Si se posee el conocimiento suficiente para crear una buena función de evaluación se pueden resolver problemas de diversas áreas de la ingeniería.</p></li>
</ul>
<strong>Construcción de un algoritmo genético</strong>
<p>A continuación se presenta una tabla que resume los puntos que el desarrollador debe determinar o tomar en cuenta cuando construye un algoritmo genético.</p>
<table>
<caption>Parámetros y consideraciones en la construcción de un algoritmo genético</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Parámetros de la población</th>
<th style="text-align: left;">Tamaño de la población</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Representación de la población</td>
<td style="text-align: left;">Método de selección y parámetros del método seleccionado. Ej. Si se selecciona Selección por rango lineal se debe determinar el valor de Selective Pressure</td>
</tr>
<tr class="even">
<td style="text-align: left;">Cruzamiento</td>
<td style="text-align: left;">Método de cruzamiento</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Mutación</td>
<td style="text-align: left;">Implementación de la mutación sobre nuestra población y tasa de mutación</td>
</tr>
<tr class="even">
<td style="text-align: left;">Elitismo</td>
<td style="text-align: left;">Determinar si se usará o no y el porcentaje de la población que pasaría a la siguiente generación mediante elitismo.</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Terminación</td>
<td style="text-align: left;">Determinar la condición de finalización</td>
</tr>
</tbody>
</table>
<div class="center">
<p>(1,0)<span>420</span></p>
</div>
<p><strong>Ejercicio de programación:</strong></p>
<p>Ejercicio para fortalecer los conocimientos adquiridos:</p>
<p>En cualquier lenguaje de programación hacer un programa capaz de realizar alguna de las siguientes tareas:</p>
<ul>
<li><p>Resolver un tablero de sudoku con algunas celdas llenadas previamente.</p></li>
<li><p>Resolver el problema del viajero. (<a href="https://es.wikipedia.org/wiki/Problema_del_viajante">https://es.wikipedia.org/wiki/Problema_del_viajante</a>)</p></li>
<li><p>Adaptar la posición y rotación de líneas en un espacio tridimensional para representar una imagen. (<a href="https://youtu.be/iV-hah6xs2A">https://youtu.be/iV-hah6xs2A</a>)</p></li>
</ul>
<p>A continuación se presenta un repositorio donde aplicó un algoritmo genético para solucionar tableros de sudoku:</p>
<p><img src="pandocConversionMedia/Pictures/github/genetic.png" style="width:5cm" alt="image" /></p>
<p><a href="https://github.com/amr205/SudokuSolver---Genethic-Algorithm">https://github.com/amr205/SudokuSolver---Genethic-Algorithm</a></p>
<strong>Programación genética</strong>
<p>En este libro se revisarán las bases de la programación genética para culminar con un proyecto que demuestre que se entienden estos conceptos y se poseen las habilidades de programación necesarias para poner en práctica lo aprendido. Si tú como lector quieres explorar más a profundidad este tema recomiendo leer el siguiente libro:</p>
<p>(<a href="http://www.lulu.com/shop/riccardo-poli-and-william-b-langdon-and-nicholas-freitag-mcphee/a-field-guide-to-genetic-programming/ebook/product-17447670.html">http://www.lulu.com/shop/riccardo-poli-and-william-b-langdon-and-nicholas-freitag-mcphee/a-field-guide-to-genetic-programming/ebook/product-17447670.html</a>).</p>
<p><strong>¿Qué es la programación genética?</strong></p>
<p>La programación genética es un tipo de algoritmo evolutivo en el cual se determina “que debe hacerse” y se generan programas computacionales para resolver dicho problema.</p>
<p>El funcionamiento general de la programación genética es muy similar a los algoritmos genéticos ya que también tiene su base en la selección natural de la teoría de la evolución de Darwin. De hecho son tan similares que la Figura <a href="#fig:df-ga" data-reference-type="ref" data-reference="fig:df-ga">2.2</a> presentada para los algoritmos genéticos describe igualmente el flujo de un programa que implementa programación genética.</p>
<p><strong>Diferencia entre un algoritmos genéticos y la programación genética</strong></p>
<p>La respuesta más simple a esta pregunta son los individuos de la población, en la programación genética cada individuo es un programa computacional. Como se verá a continuación esto impacta en la representación de nuestros individuos, generación de la población y en los métodos de cruzamiento y mutación.</p>
<strong>Tipos de programación genética</strong>
<p>De acuerdo a la representación de los programas existen diferentes tipos de programación genética, en este libro se abordará el tipo basado en árboles debido a que es uno de los tipos más comunes.</p>
<p><strong>Programación genética basada en árboles</strong></p>
<p>En este tipo de PG el programa se representa mediante árboles, este tipo de representaciones son bastante comunes y suelen usarse para resolver problemas de un dominio específico. Este tipo de representación suele trabajar muy bien con lenguajes funcionales, una de las primeras implementaciones fue en el lenguaje LISP debido a que la estructura del lenguaje se presta para utilizar este tipo de algoritmos.</p>
<p>John Koza <span class="citation" data-cites="koza1992genetic"></span> menciona que esta representación es más natural que una basada en cadenas de caracteres de longitud fijo (o representaciones de tipo cromosoma) debido a que permite a los programas de la población tener variedad en su tamaño y longitud.</p>
<figure>
<img src="pandocConversionMedia/ia/GP-tree.png" id="fig:GP-tree" style="width:5cm" alt="Representación de un programa mediante un árbol." /><figcaption aria-hidden="true">Representación de un programa mediante un árbol.</figcaption>
</figure>
<p><strong>Programación genética lineal</strong></p>
<p>Este tipo de representación se asemeja mucho más a los lenguajes imperativos ya que los programas son representados como una serie de instrucciones.</p>
<p>Es importante notar la diferencia entre este tipo de algoritmos y los algoritmos genéticos, una de las diferencias claves consiste en el hecho de que los programas generados pueden tener diferente tamaño (cantidad de instrucciones). A pesar de su estructura lineal este tipo de programación genética es capaz de generar soluciones para problemas de alta complejidad <span class="citation" data-cites="opensourceLGP"></span>. En la siguiente figura se puede observar una comparación entre la representación lineal y la representación lineal.</p>
<figure>
<img src="pandocConversionMedia/ia/gp-tree1e1.png" id="fig:gp-tree1e1" style="width:14cm" alt="Comparación entre la representación basada en árboles (izquierda) y la representación lineal, el array proporcionado como argumento para el algoritmo de programación genética lineal es el siguiente r=x1,x2,1.0,1.0,0.0,1.0, Figura tomada de Jed Simson. (2017). Open-Source Linear Genetic Programming. : Faculty of Computing and Mathematical Sciences University of Waikato, Waikato, New Zealand." /><figcaption aria-hidden="true">Comparación entre la representación basada en árboles (izquierda) y la representación lineal, el array proporcionado como argumento para el algoritmo de programación genética lineal es el siguiente r=<span>x1,x2,1.0,1.0,0.0,1.0</span>, Figura tomada de Jed Simson. (2017). Open-Source Linear Genetic Programming. : Faculty of Computing and Mathematical Sciences University of Waikato, Waikato, New Zealand.<span class="citation" data-cites="opensourceLGP"></span></figcaption>
</figure>
<p><strong>Otros tipos de programación genética</strong></p>
<p>Existen otros tipos de representaciones como la evolución gramatical que utiliza la estructura gramatical del lenguaje para generar programas, así como otros tipos de representaciones, sin embargo estos tipos de PG se encuentran fuera del alcance de este libro.</p>
<strong>Representación de los individuos</strong>
<p>NOTA: Como se mencionó anteriormente este libro está centrado en la programación genética basada en árboles, por lo cual todos los subtemas posteriores del tema de programación genética usan solamente esta representación.</p>
<p>Los programas que se generan no suelen ser programas completos como los que nosotros como desarrolladores desarrollamos, en cambio suelen ser de dominios más específicos. Como se mencionó anteriormente los programas suelen representarse como árboles sintácticos, en formas más avanzadas de la programación genética, el programa consta de diferentes subrutinas unidas entre sí, en este libro solo se tratará la forma básica que consiste de un solo árbol sintáctico <span class="citation" data-cites="opensourceLGP"></span>.</p>
<p>Para formar el árbol sintáctico se utilizan un conjunto de funciones y un conjunto de elementos terminales, los nodos internos utilizan elementos del conjunto de funciones y las hojas del árbol toman valores del conjunto de elementos terminales. Estos conjuntos deben contener los elementos suficientes para poder generar soluciones apropiadas para nuestro problema planteado.</p>
<figure>
<img src="pandocConversionMedia/ia/GP-tree2.png" id="fig:GP-tree2" style="width:14cm" alt="Árbol sintáctico de la operación (9 / b)+a." /><figcaption aria-hidden="true">Árbol sintáctico de la operación (9 / b)+a.</figcaption>
</figure>
<p><strong>Conjunto terminal</strong></p>
<p>Este conjunto puede contener los siguientes elementos <span class="citation" data-cites="opensourceLGP"></span>:</p>
<ul>
<li><p>Constantes: Estas suelen ser generadas de manera aleatoria durante la creación del árbol o creadas durante el proceso de mutación. El símbolo <span class="math inline">\(\Re\)</span> representa una constante aleatoria efímera (En inglés llamada ephemeral random constant), esta constante representa un conjunto de constantes fijas. Ej <span class="math inline">\(\Re = \{ x | x\)</span> es un entero y <span class="math inline">\(0 \leq x \leq 10 \}\)</span></p></li>
<li><p>Funciones sin argumentos: Este tipo de funciones pueden regresar un valor distinto cada vez que se usan, un ejemplo sería una función que genere un número aleatorio.</p></li>
<li><p>Valores de entrada externos: Son los argumentos del algoritmo de PG, suelen ser representados con el nombre de alguna variable, en la Figura <a href="#fig:GP-tree2" data-reference-type="ref" data-reference="fig:GP-tree2">2.20</a> a y b serían un ejemplo de este tipo de elementos.</p></li>
</ul>
<p><strong>Conjunto de funciones</strong></p>
<p>Las funciones estarán determinadas por el tipo de problema que se necesita resolver, en el caso de la Figura <a href="#fig:GP-tree2" data-reference-type="ref" data-reference="fig:GP-tree2">2.20</a> las funciones son de carácter aritmético. Para que nuestro algoritmo de PG funcione de manera correcta se tienen que cumplir dos propiedades: consistencia de tipo y seguridad en la evaluación.</p>
<p><u>Consistencia de tipos</u></p>
<p>Para cumplir con la consistencia de tipo todas nuestras funciones tienen que utilizar argumentos del mismo tipo y devolver valores del mismo tipo, esto puede limitar el tipo de funciones que podemos incluir en nuestro conjunto, sin embargo algunas funciones pueden ser re-interpretadas para que trabajen con el mismo tipo que las demás. Ejemplo: Las función IF-THEN trabaja con dos argumentos, uno booleano y uno numérico, si la quisiéramos usar con operadores aritméticos podríamos reestructurarla para que tome tres argumentos numéricos y si el primer argumento sea mayor al segundo devuelva el valor del tercero, así se habría conservado la consistencia de tipos.</p>
<p>Si no se cumple la consistencia de tipos se tendrían que implementar medidas en la fase de cruzamiento y mutación que asegurarán que los árboles generados siguieran siendo válidos.</p>
<p><u>Seguridad en la evaluación</u></p>
<p>Básicamente se debe evitar que el programa produzca errores al ejecutarse, un ejemplo claro es el de la división sobre cero. Se pueden tomar distintas acciones para tratar este tipo de situaciones, la primera es reducir altamente la aptitud de los programas que produzcan errores, la segunda es utilizar funciones adaptadas para responder con algún valor ante estas situaciones, la función de división protegida, denotada comúnmente con el símbolo % suele devolver un valor de 1 ante una división sobre 0.</p>
<strong>Generación de la población inicial</strong>
<p>Existen diferentes maneras en las cuales se puede generar la población inicial, tener programas duplicados en nuestra población es un gasto de recursos computacionales por lo que se sugiere evitar que se generen, sin embargo es recomendable pero no necesario <span class="citation" data-cites="koza1992genetic"></span>. A continuación se describen dos técnicas básicas (y comunes) para generar una población inicial.</p>
<p><u>Full</u></p>
<p>El desarrollador define una profundidad de los programas, se genera un nodo raíz a partir del conjunto de funciones y se va formando el árbol a partir de estos elementos hasta que se llega a la profundidad definida, en ese momento se seleccionan elementos del conjunto terminal.</p>
<figure>
<img src="pandocConversionMedia/ia/Full -GP.png" id="fig:Full-GP" style="width:14cm" alt="Ejemplo de tres individuos de un población generada con el método full con una profundidad de 3." /><figcaption aria-hidden="true">Ejemplo de tres individuos de un población generada con el método full con una profundidad de 3.</figcaption>
</figure>
<p><u>Grow</u></p>
<p>El desarrollador define la profundidad máxima de los programas, cuando se generan los nodos del árbol estos se generan a partir de la combinación del conjunto de funciones y el conjunto terminal, si se llega a la profundidad máxima solo se seleccionan elementos del conjunto terminal. Esto permite generar árboles con distinto tamaño.</p>
<figure>
<img src="pandocConversionMedia/ia/GROW-GP.png" id="fig:GROW-GP" style="width:14cm" alt="Ejemplo de tres individuos de un población generada con el método grow con una profundidad de 3." /><figcaption aria-hidden="true">Ejemplo de tres individuos de un población generada con el método grow con una profundidad de 3.</figcaption>
</figure>
<p>Koza <span class="citation" data-cites="koza1992genetic"></span> sugiere generar la mitad de la población usando el método full y la otra mitad usando el método grow, al uso de esta combinación se le conoce como “ramped half and half”.</p>
<strong>Evaluación de los individuos</strong>
<p>La evaluación de la aptitud de los individuos depende ampliamente del tipo de problema que se trata de resolver, para evaluar un individuo se tiene que ejecutar el programa, en problemas donde tenemos un conjunto de entradas con su correspondiente salida, se podría calcular el resultado con base en la diferencia entre el resultado proporcionado por el programa y el resultado esperado.</p>
<p><span class="math inline">\(\frac{1}{m} \sum_{i=0}^{m}(y_i-x_i)^{2}\)</span></p>
<p>Donde <span class="math inline">\(m\)</span> es el tamaño del conjunto que contiene las entradas con la salida correspondiente, <span class="math inline">\(y_i\)</span> es la salida esperada y <span class="math inline">\(x_i\)</span> es la salida obtenida.</p>
<p>Como se mencionó anteriormente se deben penalizar los programas que generen errores en su ejecución. Muchos de las aplicaciones prácticas requieren de funciones de evaluación multiobjetivo, en este caso se podría analizar la diferencia entre el resultado esperado y el obtenido, el tiempo de ejecución, y los recursos de memoria utilizados, de esta manera se podría obtener una solución que encontrará un buen balance entre estos tres aspectos.</p>
<p>Para correr el programa se puede construir la sentencia para ejecutar en algún lenguaje como por ejemplo LISP, otra opción es evaluar nuestro programa dentro del mismo lenguaje haciendo uso de una función de evaluación, a continuación se presenta un algoritmo que realiza esta última tarea, se recomienda al lector interiorizar y reflexionar sobre el algoritmo que se presenta a continuación y como usa la recursividad para obtener el valor del programa.</p>
<figure>
<img src="pandocConversionMedia/ia/pse-gp.png" id="fig:pse-gp" style="width:14cm" alt="Algoritmo que evalúa un programa representado mediante un árbol sintáctico, Figura tomada de Jed Simson. (2017). Open-Source Linear Genetic Programming. : Faculty of Computing and Mathematical Sciences University of Waikato, Waikato, New Zealand." /><figcaption aria-hidden="true">Algoritmo que evalúa un programa representado mediante un árbol sintáctico, Figura tomada de Jed Simson. (2017). Open-Source Linear Genetic Programming. : Faculty of Computing and Mathematical Sciences University of Waikato, Waikato, New Zealand.<span class="citation" data-cites="opensourceLGP"></span></figcaption>
</figure>
<strong>Selección</strong>
<p>Debido a que los programas generados ya poseen un valor de aptitud se pueden utilizar los métodos descritos en la sección de selección para algoritmos genéticos <a href="#selection:pse-ga" data-reference-type="ref" data-reference="selection:pse-ga">[selection:pse-ga]</a> de este libro, así como cualquier otro método estándar de selección en algoritmos evolutivos.</p>
<p>En este libro se sugiere analizar el comportamiento del algoritmo de programación genética con el método de selección elegido para determinar si es conveniente utilizar algún método con mayor o menor presión selectiva (A mayor presión selectiva mayor probabilidad hay de que los mejores individuos sean seleccionados como padres). Como punto de inicio se puede utilizar el método de selección por torneo debido a su fácil implementación.</p>
<strong>El rol de los operadores de cruzamiento y mutación</strong>
<p>Han existido discusiones de acuerdo a la importancia de los operadores de cruzamiento y mutación en los algoritmos evolutivos, un punto de vista tradicional nos indica que la mutación nos permite mantener diversidad en nuestra población y explorar el espacio de soluciones de nuestro problema, en cambio el cruzamiento nos permite ir mejorando la aptitud promedio de nuestra población y generar mejores individuos para llegar a la convergencia de nuestro algoritmo. La pregunta no es ¿Cruzamiento ó mutación?, lo ideal es usar ambas y encontrar el balance haciendo uso de los parámetros que como desarrolladores podemos modificar.</p>
<p>Si queremos analizar el comportamiento del uso de cruzamiento o mutación por separado se puede observar <span class="citation" data-cites="luke1997comparison"></span> que en general el desempeño de algoritmos de programación genética que usan solo cruzamiento superan a aquellos que solo usan mutación y esta diferencia se hace más marcada al incrementar el tamaño de la población (Esto tiene sentido que ya que sin la mutación se requiere de una población grande para poseer suficiente diversidad para la convergencia exitosa del algoritmo).</p>
<p>Debido a que la representación de los individuos es muy distinta a la representación usada en los algoritmos genéticos los métodos de cruzamiento y mutación difieren a los presentados anteriormente.</p>
<strong>Cruzamiento</strong>
<p>A continuación se presenta uno de los métodos más comunes para realizar el cruzamiento en un algoritmo genético.</p>
<p><u>Subtree crossover (Cruzamiento de un punto)</u></p>
<p>Dados dos programas padres A y B se selecciona un punto de cruzamiento (un nodo) en cada padre <span class="math inline">\(P_a\)</span> y <span class="math inline">\(P_b\)</span> , para crear un nuevo programa se toma una copia del programa A y se reemplaza el subárbol cuya raíz es el nodo <span class="math inline">\(P_a\)</span> por el subárbol del padre B cuya raíz sea el punto <span class="math inline">\(P_b\)</span>. Esta técnica puede usarse para crear uno o dos hijos, el otro hijo tendría como base al padre B y se reemplazaría el subárbol cuya raíz es el nodo <span class="math inline">\(P_b\)</span> por el subárbol del padre A.</p>
<figure>
<img src="pandocConversionMedia/ia/GP - crossover.png" id="fig:GP - crossover" style="width:12cm" alt="Representación de la operación de cruzamiento, en la imagen se encuentran marcados con color azul los puntos de cruzamiento." /><figcaption aria-hidden="true">Representación de la operación de cruzamiento, en la imagen se encuentran marcados con color azul los puntos de cruzamiento.</figcaption>
</figure>
<p>Este es uno de los métodos más simples y existen versiones distintas del mismo, por ejemplo size-fair crossover es una variante que asegura que ambos subárboles utilizados para el cruzamiento tengan el mismo tamaño. Debido al alcance de este libro solo se mencionará este método de cruzamiento, si se desean conocer otras maneras de aplicar el operador de cruzamiento se recomienda leer el capítulo 5.3 del libro “A Field Guide to Genetic Programing” <span class="citation" data-cites="polilang08gp"></span>.</p>
<strong>Mutación</strong>
<p>A continuación se presentan tres de los métodos más comunes para realizar la operación de mutación, de igual manera si se desean conocer más métodos se recomienda leer el capítulo 5.2 del libro “A Field Guide to Genetic Programing” <span class="citation" data-cites="polilang08gp"></span>.</p>
<p><u>Point mutation (Node replacement mutation)</u></p>
<p>Este método es muy similar al método Bit Flip mutation utilizado en los algoritmos genéticos, se selecciona un nodo en el árbol y se le cambia el valor, si este es un nodo de tipo terminal se cambia por otro nodo del mismo tipo, si el nodo es un nodo interno se cambia por otro nodo del conjunto de funciones que tenga el mismo número de argumentos.</p>
<figure>
<img src="pandocConversionMedia/ia/GP -Point mutation.png" id="fig:GP-Point-mutation" style="width:14cm" alt="Resultado del operador de mutación “point mutation”" /><figcaption aria-hidden="true">Resultado del operador de mutación “point mutation”</figcaption>
</figure>
<p><u>Subtree mutation</u></p>
<p>Se selecciona de manera aleatoria un subárbol dentro del individuo y este se reemplaza por un subárbol generado de manera aleatoria. La forma más básica de este método no limita la profundidad del nuevo subárbol, sin embargo existen variantes que restringen la profundidad del nuevo subárbol a ser del mismo tamaño o a ser como máximo 15% (o algún otro porcentaje) más profundo que el subárbol original.</p>
<figure>
<img src="pandocConversionMedia/ia/GP -Subtree mutation.png" id="fig:GP-Subtree-mutation" style="width:14cm" alt="Resultado del operador de mutación “subtree mutation”" /><figcaption aria-hidden="true">Resultado del operador de mutación “subtree mutation”</figcaption>
</figure>
<p><u>Shrink mutation</u></p>
<p>Se selecciona de manera aleatoria un subárbol dentro del individuo y este se reemplaza por un nodo terminal. El objetivo de este método de mutación es el de reducir el tamaño del programa.</p>
<strong>Construcción de un algoritmo de programación genética</strong>
<p>A continuación se presenta una tabla que resume los puntos que el desarrollador debe determinar o tomar en cuenta cuando construye un algoritmo de programación genética.</p>
<table>
<caption>Parámetros y consideraciones en la construcción de un algoritmo de programación genética</caption>
<thead>
<tr class="header">
<th style="text-align: left;">Parámetros de la población</th>
<th style="text-align: left;">Tamaño de la población</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Representación de la población</td>
<td style="text-align: left;">Determinar el conjunto de funciones y el conjunto terminal (En el conjunto terminal hay que determinar los valores que puede tomar la constante aleatoria efímera <span class="math inline">\(\Re\)</span>)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Selección</td>
<td style="text-align: left;">Método de selección y parámetros del método seleccionado. Ej. Si se selecciona Selección por rango lineal se debe determinar el valor de Selective Pressure</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Cruzamiento</td>
<td style="text-align: left;">Método de cruzamiento.</td>
</tr>
<tr class="even">
<td style="text-align: left;">Mutación</td>
<td style="text-align: left;">Implementación de la mutación sobre nuestra población y tasa de mutación</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Terminación</td>
<td style="text-align: left;">Determinar la condición de finalización</td>
</tr>
</tbody>
</table>
<div class="center">
<p>(1,0)<span>420</span></p>
</div>
<p><strong>Ejercicio de programación:</strong></p>
<p>En cualquier lenguaje de programación hacer un programa capaz de obtener una formula a partir de los datos de entrada y salida.</p>
<p><img src="pandocConversionMedia/Pictures/github/progen.png" style="width:4cm" alt="image" /></p>
<p>(<a href="https://github.com/amr205/FunctionDiscoverer---Genetic-Programming">https://github.com/amr205/FunctionDiscoverer---Genetic-Programming</a>)</p>
<strong>Sistemas clasificadores (Learning classifier system)</strong>
<p>Los sistemas clasificadores buscan aprender un conjunto de reglas que se almacenan y se aplican para realizar la tarea de clasificación. Este tipo de algoritmo de clasificación utiliza las bases de los algoritmos evolutivos para el aprendizaje de las reglas (Por su funcionamiento también se considera un algoritmo de machine learning de aprendizaje supervisado o reforzado, si se quiere conocer a que se refiere esto se recomienda leer los primeros temas del capítulo Machine Learning).</p>
<p><strong>¿En qué consiste la tarea de clasificación?</strong></p>
<p>Dado un nuevo ejemplo de un elemento de un dominio específico ser capaz de etiquetarlo de manera correcta (asignarle un ejemplo). Estos elementos o instancias comparten una estructura que contiene una serie finita de atributos. Las etiquetas pueden ser de carácter discreto o continuo.</p>
<p>La tarea de clasificación puede servirnos para un espectro amplio de problemas, incluso nos puede servir para determinar qué acción realizar ante una situación determinada, el elemento del dominio sería la situación actual del entorno y la etiqueta la acción a realizar.</p>
<strong>Funcionamiento básico de las reglas en un LCS</strong>
<p>Antes de analizar los tipos de LCS más comunes y su funcionamiento se describirá qué son las reglas y cómo determinan la clasificación de un ejemplo del dominio.</p>
<p>Para poder modelar el dominio se utilizan reglas, cada regla es parte de ese modelo. Cada regla está compuesta de una condición y una acción, la condición nos indica el valor que deberían tomar uno o más atributos, si esta condición se cumple la acción nos dice la clase a la cual corresponde el ejemplo. Supongamos que se tiene un problema donde cada ejemplo del dominio contiene 7 atributos que pueden tomar el valor de 0 o 1.</p>
<figure>
<img src="pandocConversionMedia/ia/LCS - Instancia.png" id="fig:LCS-Instancia" style="width:6cm" alt="Representación de una instancia que contiene 7 atributos donde cada uno de ellos puede tomar el valor de 0 o 1." /><figcaption aria-hidden="true">Representación de una instancia que contiene 7 atributos donde cada uno de ellos puede tomar el valor de 0 o 1.</figcaption>
</figure>
<p>Como se mencionó anteriormente la condición de una regla contiene los valores esperados en uno o más atributos (se suelen preferir reglas con menos atributos ya que son más generales, más adelante en este capítulo se verá cómo se favorecen este tipo de reglas), estas reglas suelen ser descritas como una sentencia condicional, a continuación se presentan reglas aplicadas sobre la instancia anterior para demostrar de manera visual su comportamiento.</p>
<figure>
<img src="pandocConversionMedia/ia/LCS - Regla.png" id="fig:LCS-Regla" style="width:11cm" alt="Reglas diferentes siendo aplicadas a una misma instancia." /><figcaption aria-hidden="true">Reglas diferentes siendo aplicadas a una misma instancia.</figcaption>
</figure>
<p>En la figura <a href="#fig:LCS-Regla" data-reference-type="ref" data-reference="fig:LCS-Regla">2.28</a> se puede observar que la única regla cuya condición se cumple es la regla 1 por ende la acción de esta regla indica que pertenece a la clase A. Si hubiera varias reglas que coincidieran la predicción estaría basada en la clase con mayor número de reglas cuya condición se cumpliera. Ejemplo: Si para una instancia 5 reglas coinciden, 3 de ellas reglas con acción clase A y 2 con acción clase B, la clase que a predecir sería la clase A.</p>
<p>Esta explicación de cómo se utilizan las reglas para clasificar se retomará más adelante en el capítulo, en este momento se espera que el lector entienda su funcionamiento básico para observar la utilidad del algoritmo.</p>
<strong>Tipos de LCS</strong>
<p>Los tipos más comunes de LCS que utilizan algoritmos evolutivos son LCS estilo Pittsburgh <span class="citation" data-cites="LCS_smith"></span> y el estilo Michigan <span class="citation" data-cites="HOLLAND1978313"></span>, estos dos estilos fueron contemporáneos. Actualmente LCS estilo Pittsburgh siguen siendo utilizados, sin embargo el estilo Michigan de LCS se ha convertido en el estándar <span class="citation" data-cites="SOW_LCS_SURVEY"></span>.</p>
<p>El estilo Pittsburgh usa como único elemento de adaptación un algoritmo genético, cada individuo de la población es un conjunto de reglas que se usan para la clasificación, es decir cada individuo es una solución completa al problema de clasificación.</p>
<p>El estilo Michigan utiliza elementos de aprendizaje reforzado en conjunto con un algoritmo genético cuyos individuos son reglas, este algoritmo se utiliza para descubrir nuevas reglas y es altamente elitista. En este libro nos centraremos en el estilo Michigan debido a que actualmente es el estándar de los LCS que usan algoritmos evolutivos, además en este libro ya se cubrió el tema de algoritmos genéticos y se espera que el lector de este libro sea capaz de implementar un LCS estilo Pittsburgh haciendo uso de los conocimientos adquiridos en la sección <a href="#section:Algoritmos-geneticos" data-reference-type="ref" data-reference="section:Algoritmos-geneticos">[section:Algoritmos-geneticos]</a> (Algoritmos genéticos).</p>
<figure>
<img src="pandocConversionMedia/ia/comp-lcs.png" id="fig:comp-lcs" style="width:12cm" alt="Comparación entre el uso de algoritmos genéticos en los dos estilos (Pittsburgh-Derecha, Michigan-Izquierda), En el estilo Michigan un set de reglas evoluciona, en cambio en el estilo Pittsburgh poblaciones formadas por conjuntos de reglas compiten de una manera tradicional (basada fuertemente en el funcionamiento de los algoritmos genéticos). Figura tomada de Bacardit, J., Bernadó-Mansilla, E., and Butz, M.V. (2007). Learning Classifier Systems: Looking Back and Glimpsing Ahead. IWLCS. " /><figcaption aria-hidden="true">Comparación entre el uso de algoritmos genéticos en los dos estilos (Pittsburgh-Derecha, Michigan-Izquierda), En el estilo Michigan un set de reglas evoluciona, en cambio en el estilo Pittsburgh poblaciones formadas por conjuntos de reglas compiten de una manera tradicional (basada fuertemente en el funcionamiento de los algoritmos genéticos). Figura tomada de Bacardit, J., Bernadó-Mansilla, E., and Butz, M.V. (2007). Learning Classifier Systems: Looking Back and Glimpsing Ahead. IWLCS. <span class="citation" data-cites="LCS_LBGA"></span></figcaption>
</figure>
<strong>Mecanismos principales en un LCS</strong>
<p>Este libro se centrará en el estilo Michigan, a partir de este punto se sobreentiende que el estilo que se está describiendo es este. Antes de presentar los componentes principales que contiene un LCS se describirán los mecanismos principales de un LCS con la finalidad de que sea más fácil identificar la finalidad de cada componente.</p>
<p><strong>Discovery o “descubrimiento”</strong></p>
<p>Este componente se refiere a la creación o el descubrimiento de nuevas reglas que no se encuentren actualmente en nuestra población, idealmente estas reglas serán mejores para solucionar el problema de clasificación. La forma más común de realizar este mecanismo es mediante un algoritmo genético <span class="citation" data-cites="UrbanowiczLCS"></span>. El funcionamiento de este algoritmo genético es el descrito en la sección <a href="#section:Algoritmos-geneticos" data-reference-type="ref" data-reference="section:Algoritmos-geneticos">[section:Algoritmos-geneticos]</a>(Algoritmos genéticos) de este libro.</p>
<p><strong>Learning o aprendizaje</strong></p>
<p>El aprendizaje, en el contexto de la inteligencia artificial puede ser descrito como la mejora en el desempeño de una tarea en un ambiente a través de la adquisición de conocimiento, resultado de la experiencia en dicho ambiente <span class="citation" data-cites="rug01_000857792"></span>.</p>
<p>Como se verá posteriormente a mayor detalle en este capítulo cada regla que se encuentra dentro de la población tiene un conjunto de parámetros asociados, estos parámetros son actualizados en cada iteración mediante el mecanismo de aprendizaje.</p>
<p>El tipo de aprendizaje usado comúnmente en un LCS es aprendizaje reforzado, en este el agente interactúa con el ambiente y recibe una recompensa o penalización si se desempeña en este (el ambiente) de manera correcta o incorrecta respectivamente (asignación de créditos, “credit assignment”). Otro tipo de aprendizaje que puede usarse en un LCS es el aprendizaje supervisado, aquí durante el proceso de aprendizaje cada instancia es acompañada por la etiqueta de la clase a la cual pertenece, aquí los parámetros de las reglas son actualizados dependiendo de si la regla pudo clasificar de manera correcta o no la instancia.</p>
<p>Dentro del estilo Michigan existen diferentes implementaciones, estas implementaciones determinan el estilo de aprendizaje utilizado y los parámetros asociados a las reglas.</p>
<strong>Componentes y procesos de un LCS con aprendizaje reforzado</strong>
<figure>
<img src="pandocConversionMedia/ia/LCS-RL.jpg" id="fig:LCS-RL" style="width:15cm" alt="Representación del proceso y los componentes que forman parte de un LCS con aprendizaje reforzado, en la figura cada elemento de la población de reglas contiene tres elementos: C el clasificador, A la acción correspondiente,  F  la aptitud (fitness)." /><figcaption aria-hidden="true">Representación del proceso y los componentes que forman parte de un LCS con aprendizaje reforzado, en la figura cada elemento de la población de reglas contiene tres elementos: <span>C</span> el clasificador, <span>A</span> la acción correspondiente, <span> F </span> la aptitud (fitness).</figcaption>
</figure>
<p>En la figura <a href="#fig:LCS-SL" data-reference-type="ref" data-reference="fig:LCS-SL">2.33</a> he tratado de representar el proceso que sigue un LCS con aprendizaje supervisado, a continuación describiré los diferentes elementos presentes en la figura.</p>
<p><strong>Environment o entorno</strong></p>
<p>el elemento con el cual nuestro agente interactúa, el agente contiene sensores que nos permiten obtener información y actuadores que nos permiten modificar el entorno. Para entenderlo propongo el siguiente ejemplo: Tenemos un programa que juega baseball, mediante los sensores recibe la velocidad de la pelota,su distancia, y el ángulo de la misma, y mediante los actuadores puede determinar la velocidad y el ángulo con el cual el debe mover el bate.</p>
<p><strong>Población de reglas</strong></p>
<p>Este set contiene las reglas (clasificadores) que nos ayudan a realizar la tarea de clasificación.</p>
<p>Como se ve en la figura <a href="#fig:LCS-Regla" data-reference-type="ref" data-reference="fig:LCS-Regla">2.28</a>, el cuerpo de la regla o condición { C } no contiene un modelo, sino una parte del mismo, mediante un conjunto de reglas se puede modelar el problema.</p>
<p>Los caracteres que forman el cuerpo de la regla no están limitados a 0 y 1, dependiendo de cómo se forma el genotipo de las instancias del dominio del problema se formará de igual manera la regla. En la literatura se suele utilizar # para denotar el “wildcard”, este elemento de la regla no se considerará para el proceso de matching, si representamos las tres reglas presentes en la figura <a href="#fig:LCS-Regla" data-reference-type="ref" data-reference="fig:LCS-Regla">2.28</a> usando # como wildcard se verían de la siguiente manera: #|#|#|#|0|1|#, #|#|0|#|1|1|#, #|#|0|0|#|#|#.</p>
<p>Además del cuerpo de la regla, en LCS con aprendizaje reforzado, cada regla tiene asociada la acción { A } que se realizará en el entorno, esta acción puede estar compuesta de un solo valor o un conjunto de valores, estos valores no están limitados al tipo binario y la forma está determinada por los valores que esperan los actuadores de nuestro agente. Por poner un ejemplo supongamos que nuestro agente debe manejar un dron y espera dos valores, un primer valor entero que especifique hacia que dirección (0-Adelante, 1-Atrás, 2-Izquierda, 3-Derecha) y un segundo valor flotante que detalle la velocidad con la que debe moverse. Además de estos dos elementos cada regla tiene asociado un valor de aptitud { F } y otros valores (que dependen de la implementación específica del LCS) llamados parámetros que nos sirven para realizar el proceso de aprendizaje y descubrimiento de reglas.</p>
<p><strong>Matching</strong></p>
<p>Es el proceso mediante el cual se seleccionan las reglas cuya condición satisface a la instancia en la iteración actual del proceso de aprendizaje. La Figura <a href="#fig:LCS-Regla" data-reference-type="ref" data-reference="fig:LCS-Regla">2.28</a> muestra este proceso siendo aplicado sobre una instancia. Aquellas reglas cuya condición sea satisfecha pasan al conjunto de elementos llamados “match set” [ M ].</p>
<p><strong>Covering</strong></p>
<p>Si el match set [ M ] se encuentra vacío se realiza el siguiente proceso, se seleccionan un subconjunto de las características de nuestra instancia actual, el resto de elementos se llenan con wildcards para formar el cuerpo de una nueva regla, se le asigna una acción al azar y se inicializan con el promedio de los valores de la población. El número de wildcards está determinada por un valor <span class="math inline">\(p_\#\)</span> determinado por el programador.</p>
<p>Comúnmente los LCS inician con un conjunto de reglas [ N ] vacío (No en todas las implementaciones), por lo cual este proceso nos ayuda también a inicializar las reglas del LCS.</p>
<figure>
<img src="pandocConversionMedia/ia/LCS - Covering.jpg" id="fig:LCS - Covering" style="width:13cm" alt="Representación visual del proceso de covering." /><figcaption aria-hidden="true">Representación visual del proceso de covering.</figcaption>
</figure>
<p><strong>Action selection</strong></p>
<p>Durante este proceso se determina la acción que se realizará en el entorno y se forma el action set [ A ], la forma de realizar este proceso depende altamente de la implementación.</p>
<p><strong>Estrategia de aprendizaje</strong></p>
<p>Tras realizar la acción en nuestro entorno se nos devuelve un valor de recompensa P, usando este valor se modificarán los parámetros de las reglas, los parámetros y la manera en la que se modifican dependen de la implementación.</p>
<p><strong>Descubrimiento de reglas</strong></p>
<p>Como se mencionó anteriormente la manera más común de realizar esta parte del proceso en LCS estilo Michigan es mediante el uso de un algoritmo genético, este algoritmo genético suele ser altamente elitista por lo cuál solo una o dos reglas nuevas se añaden en cada iteración del proceso de aprendizaje. Los detalles del algoritmo como el tipo de cruzamiento, mutación y selección son dependientes de la implementación.</p>
<p><strong>Eliminación de reglas</strong></p>
<p>En los LCS se trata de mantener un número de reglas constante, en esta parte del proceso se eliminan las reglas con menor valor de aptitud hasta que el número de reglas sea igual o menor al límite establecido.</p>
<p>Algunas implementaciones de LCS pueden contener algunos componentes extras como el proceso de subsumption que se encarga de eliminar reglas específicas cuyo valor de aptitud sea menor o igual que el de una regla más generalizada.</p>
<strong>ZCS (LCS con aprendizaje reforzado)</strong>
<figure>
<img src="pandocConversionMedia/ia/zcs.png" id="fig:zcs" style="width:12cm" alt="Representación del sistema clasificador ZCS. Figura tomada de Wilson, Stewart. (1994). ZCS: A zeroth level classifier system. Evolutionary Computation. 2. 10.1162/evco.1994.2.1.1. " /><figcaption aria-hidden="true">Representación del sistema clasificador ZCS. Figura tomada de Wilson, Stewart. (1994). ZCS: A zeroth level classifier system. Evolutionary Computation. 2. 10.1162/evco.1994.2.1.1. <span class="citation" data-cites="wilste_zcs"></span></figcaption>
</figure>
<p>El sistema clasificador “Zeroth-level” System Classifier (ZCS) fue introducido por Wilson <span class="citation" data-cites="wilste_zcs"></span>, este LCS toma como base los trabajos de Holland y utiliza aprendizaje reforzado como estrategia de aprendizaje. Como se puede observar en la figura <a href="#fig:zcs" data-reference-type="ref" data-reference="fig:zcs">2.32</a> la arquitectura del sistema clasificador ZCS es muy similar a la arquitectura presentada en la Figura <a href="#fig:LCS-RL" data-reference-type="ref" data-reference="fig:LCS-RL">2.30</a>.</p>
<p><strong>Funcionamiento del ZCS</strong></p>
<p>El ZCS comienza con una población de reglas [ P ] generada de manera aleatoria, el valor inicial de aptitud que toman las reglas es el valor <span class="math inline">\(S_0\)</span>. En diversas publicaciones el valor de aptitud es llamado fitness o strength.A continuación se describe una iteración en el proceso de aprendizaje en un ZCS <span class="citation" data-cites="cadrik_zcs"></span>:</p>
<ol>
<li><p>Se obtiene la información de entrada del entorno</p></li>
<li><p>Se realiza el proceso de matching para obtener el match set [ M ]. <strong>(matching)</strong></p></li>
<li><p>Si [ M ] se encuentra vacío se activa el mecanismo de covering (el único parámetro en ZCS que se requiere para cada regla es el valor de aptitud) añadiendo una nueva regla a la población, eliminando la regla con menor aptitud en la población de reglas y regresando al paso 2. <strong>(covering)</strong>.</p></li>
<li><p>Usando el método de ruleta (descrito en la sección <a href="#selection:pse-ga" data-reference-type="ref" data-reference="selection:pse-ga">[selection:pse-ga]</a>) se selecciona una regla R. Se copia el valor del action set [ A ] al conjunto [ A-1 ], Se vacía el action set [ A ] y cada regla que contenga la misma acción que la regla R se añade al action set [ A ]. <strong>(action selection)</strong></p></li>
<li><p>Se actualiza el valor de aptitud de cada regla en [ M ] que no se encuentre en [ A ] de acuerdo a la siguiente fórmula. (empieza la estrategia de aprendizaje)</p>
<p><span class="math display">\[fitness_j=fitness_j-fitness_j*\tau\]</span></p>
<p><span class="math inline">\(\tau\)</span> es un parámetro (no un parámetro de una regla sino del LCS) determinado por el programador o usuario, el dominio de <span class="math inline">\(\tau\)</span> es (0,1).</p></li>
<li><p>Se calcula la siguiente variable para cada regla que se encuentra en [ A ]</p>
<p><span class="math display">\[value_j = fitness_j * \beta\]</span></p>
<p><span class="math inline">\(\beta\)</span> es un segundo parámetro cuyo valor tiene el mismo dominio que <span class="math inline">\(\tau\)</span>. Posteriormente se actualiza el valor de aptitud de las reglas en [ A ] de acuerdo a la siguiente fórmula.</p>
<p><span class="math display">\[fitness_j=fitness_j-value_j\]</span></p>
<p>Se guarda temporalmente el valor “Bucket” B definido de la siguiente manera:</p>
<p><span class="math display">\[B = \sum_{j=1}^{b}value_j\]</span></p></li>
<li><p>Se ejecuta la acción en el entorno y se obtiene un valor de recompensa reward. Usando este valor se actualiza el valor de aptitud de las reglas en [ A ] de la siguiente manera:</p>
<p><span class="math display">\[fitness_j=fitness_j+\beta*\frac{reward}{|A|}\]</span></p>
<p>En la fórmula anterior | A | es la cardinalidad del conjunto [ A ]</p></li>
<li><p>Por último para terminar la estrategia de aprendizaje se actualiza el valor del conjunto [A-1]:</p>
<p><span class="math display">\[fitness_j = fitness_j +\gamma*\frac{B}{|A-1|}\]</span></p>
<p>Donde <span class="math inline">\(\gamma\)</span> es un parametro del LCS cuyo valor esta entre 0 y 1.</p>
<p><strong>(termina la estrategia de aprendizaje)</strong></p></li>
<li><p>El siguiente paso es el proceso de descubrimiento de reglas, Wilson <span class="citation" data-cites="wilste_zcs"></span> no describe los detalles del algoritmo genético, sin embargo C<span>á</span>drik y Mach <span class="citation" data-cites="cadrik_zcs"></span>, mencionan que se usa un algoritmo genético con selección por ruleta, cruzamiento de un punto y para la mutación cada carácter del genotipo tiene una probabilidad pm de mutar tomando uno de los tres valores posibles 0,1 y # (siendo # un wildcard). Este algoritmo es altamente elitista, por ende solo se generan dos reglas nuevas que se añaden al conjunto [ P ] <strong>(descubrimiento de reglas)</strong>.</p></li>
<li><p>Para mantener constante el número de reglas en la población [ P ] se eliminan dos reglas de la población, preferiblemente aquellas con un valor bajo de aptitud. <strong>(eliminación de reglas)</strong></p></li>
</ol>
<strong>Componentes y procesos de un LCS con aprendizaje supervisado</strong>
<figure>
<img src="pandocConversionMedia/ia/LCS-SL.jpg" id="fig:LCS-SL" style="width:14.5cm" alt="Representación del proceso y los componentes que forman parte de un LCS con aprendizaje supervisado, en la figura cada elemento de la población de reglas contiene tres elementos: C el clasificador, A la acción correspondiente,  F  la aptitud (fitness)." /><figcaption aria-hidden="true">Representación del proceso y los componentes que forman parte de un LCS con aprendizaje supervisado, en la figura cada elemento de la población de reglas contiene tres elementos: <span>C</span> el clasificador, <span>A</span> la acción correspondiente, <span> F </span> la aptitud (fitness).</figcaption>
</figure>
<p>Podemos observar que el LCS con aprendizaje supervisado no difiere tanto en comparación a un LCS con aprendizaje reforzado, la principal diferencia radica en la ausencia del entorno, aquí para el proceso de aprendizaje se requiere de un set de entrenamiento que contiene ejemplos de nuestro dominio con su etiqueta correspondiente.</p>
<p>Para evitar ser repetitivo no mencionaré los componentes que también se encuentran en una arquitectura LCS con aprendizaje reforzado y me centraré en las diferencias.</p>
<p>En lugar de un action set tenemos un correct set [ C ] este set contiene todos los elementos del match set [ M ] que contengan la misma etiqueta (acción) que la instancia de la iteración actual.</p>
<p>Para el proceso de aprendizaje ya no es necesario interactuar con el entorno, una vez creados el match set [ M ] y correct set [ C ] se puede proceder a la actualización de parámetros, los parámetros y la manera en la que se actualizan es dependiente de la implementación.</p>
<p>Otra diferencia es el momento en el que el mecanismo de covering se activa, en los LCS con aprendizaje reforzado se utilizaban cuando el match set [ M ] estaba vacío, sin embargo en este tipo de LCS se activa el mecanismo cuando el correct set [ C ] no tiene ningún elemento, además de esto la clase que toma la regla creada por el covering debe tener la misma clase que la instancia de la iteración actual.</p>
<strong>UCS (LCS con aprendizaje supervisado)</strong>
<p>El clasificador UCS deriva del XCS (un clasificador basado en la exactitud o “accuracy” en inglés, con aprendizaje reforzado), a diferencia del clasificador XCS adapta sus componentes para utilizar aprendizaje supervisado.</p>
<p><strong>Parámetros de las reglas o clasificadores en UCS</strong></p>
<p>Estos parámetros tendrán que ser actualizados durante el proceso de aprendizaje: exactitud o “accuracy” { acc }, aptitud o “fitness” { F }, tamaño del correct set o “correct set size” { cs }, “numerosity” { num } y experiencia o “experience” { exp }.</p>
<p>La aptitud y exactitud de la regla nos sirve para determinar la calidad de la misma, el tamaño del correct set es el tamaño promedio del correct set [ C ] en los cuales ha participado, el valor de “numerosity” indica cuantas veces se encuentra presente la misma regla en la población [ P ] y la experiencia nos indica cuantas veces esta regla ha pertenecido a algún match set [ M ]. <span class="citation" data-cites="orriols2006further"></span>.</p>
<p>A continuación se describe una iteración en el proceso de aprendizaje en un clasificador UCS:</p>
<ol>
<li><p>Se obtiene una instancia xi del set de entrenamiento [ X ] junto con su clase correspondiente.</p></li>
<li><p>Se realiza el proceso de matching para obtener el match set [ M ]. <strong>(matching)</strong></p></li>
<li><p>Se obtienen todas las reglas del match set [ M ] que posean la misma clase o etiqueta de la instancia actual <span class="math inline">\(x_i\)</span> para formar el correct set [ C ].</p></li>
<li><p>Si [ C ] se encuentra vacío se activa el mecanismo de covering, los parámetros son inicializados de la siguiente manera: exp = 1, num = 1, cs = 1, acc = 1 and F = 1. Después de añadir la nueva regla se elimina la regla con menor valor de aptitud. <strong>(covering)</strong>.</p></li>
<li><p>Ahora se van a actualizar los valores de los parámetros de las reglas: Se aumenta el valor de experiencia { exp } de todas las reglas en el match set [ M ], y se actualiza el valor de exactitud de las reglas de acuerdo a si estas pertenecen o no al correct set [ C ]:</p>
<p><span class="math display">\[acc=\frac{clasificacionses_{correctas}}{exp}\]</span></p>
<p>Para poder lograr actualizar los parámetros yo propongo el aplicar las siguientes fórmulas en el orden mostrado, primero empezamos aplicando las siguientes fórmulas sobre todos los elementos del match set [ M ]:</p>
<p><span class="math display">\[exp_j=exp_j+1\]</span></p>
<p><span class="math display">\[acc_j=acc_j*\frac{exp_j-1}{exp_j}\]</span></p>
<p>Ahora actualizamos los siguientes valores de las reglas presentes en el correct set [ C ]:</p>
<p><span class="math display">\[acc_j=acc_j+\frac{1}{exp_j}\]</span></p>
<p><span class="math display">\[css_j=\frac{css_j*((acc_j*exp_j)-1)+|C|}{exp_j}\]</span></p>
<p>Por último actualizamos el valor de aptitud de todos los elementos en el match set [ M ]</p>
<p><span class="math display">\[F=(acc_j)^{v}\]</span></p>
<p>Donde v en la fórmula anterior suele tener el valor v = 10. <strong>(estrategia de aprendizaje)</strong></p></li>
<li><p>El siguiente paso es el proceso de descubrimiento de reglas, se puede utilizar un algoritmo genético con selección por ruleta, cruzamiento de un punto y para la mutación cada carácter del genotipo tiene una probabilidad pm de mutar tomando uno de los tres valores posibles 0,1 y # (siendo # un wildcard). Este algoritmo es altamente elitista, por ende solo se generan dos reglas nuevas que se añaden al conjunto [ P ] (descubrimiento de reglas). Los iniciales que toman los parámetros son los siguientes: exp = 0, num = 1, cs = (csp1 + csp2)/2 (Donde p1 y p2 son los padres), acc = 1 y F=1. <strong>(descubrimiento de reglas)</strong></p></li>
<li><p>Para mantener constante el número de reglas en la población [ P ] se eliminan dos reglas de la población, preferiblemente aquellas con un valor bajo de aptitud. <strong>(eliminación de reglas)</strong></p></li>
</ol>
<strong>Conclusión de los LCS</strong>
<p>Actualmente gracias a técnicas de Deep Learning se han logrado resolver tareas de clasificación muy complejas, por lo tanto el uso de los LCS ha disminuido, sin embargo los LCS se han aplicado exitosamente para resolver fenómenos biológicos. Es interesante observar como John Holland incursionó en el campo de los algoritmos genéticos y luego usando ideas propias del machine learning desarrolló un algoritmo híbrido que utiliza algoritmos genéticos como un componente del sistema. En mi opinión una de las ventajas de estos sistemas es la facilidad con la cuál puede ser interpretada una regla, sin embargo mientras más grande es el tamaño de la población se vuelve más confuso el interpretar el sistema como un conjunto.</p>
<p>En este tema solo se vieron dos implementaciones específicas de los LCS y existen muchas otras que podrían adaptarse a algún problema que se quiera resolver, por estás razones colocaré aquí el link del trabajo de Urbanowicz <span class="citation" data-cites="UrbanowiczLCS"></span>. (<a href="https://www.researchgate.net/publication/26850330_Learning_Classifier_Systems_A_Complete_Introduction_Review_and_Roadmap">https://www.researchgate.net/publication/26850330_Learning_Classifier_Systems_A_Complete_Introduction_Review_and_Roadmap</a>)</p>
<strong>Panorama actual de los algoritmos evolutivos</strong>
<p>La investigación y el desarrollo de los algoritmos evolutivos lleva más de 50 años por lo cual hoy en día existen algoritmos robustos que permiten solucionar diversos problemas. Han demostrado que pueden dar soluciones a problemas difíciles, sin embargo a pesar de tener resultados en el ámbito académico se puede observar que en las industrias ha tenido menor éxito. Las nuevas tendencias apuntan al uso de algoritmos híbridos que combinen diversos paradigmas para solucionar problemas más complejos <span class="citation" data-cites="slossEA"></span>.</p>
<p>En lo personal considero que los algoritmos evolutivos si tienen aplicaciones importantes como su uso en la parametrización de dispositivos y programas, es importante observar las ventajas que nos provee cada tipo de algoritmo para poder identificar aquellos problemas que puedan ser resueltos utilizando un determinado tipo de programa. (La posibilidad de encontrar explorar un espacio de soluciones y encontrar una buena solución haciendo uso de una función de aptitud me parece una de las grandes ventajas ya que existen problemas que no pueden utilizar un algoritmo de optimización basado en el uso de gradientes).</p>
<h2 data-number="3.3" id="inteligencia-artificial-simbólica"><span class="header-section-number">3.3</span> Inteligencia Artificial Simbólica</h2>
<strong>Introducción al capítulo</strong>
<p>A continuación se presentan tres de las implicaciones principales de los sistemas de inteligencia artificial simbólica <span class="citation" data-cites="flasinski2016symbolic"></span>:</p>
<ul>
<li><p>Un modelo que represente un sistema inteligente puede ser definido de manera explícita.</p></li>
<li><p>El conocimiento de estos modelos puede ser representado de manera simbólica (Estos símbolos suelen ser de alto nivel por lo cual pueden ser interpretados por humanos, algunos ejemplos son el uso de grafos, fórmulas lógicas, fórmulas matemáticas, etc)</p></li>
<li><p>Las operaciones mentales y cognitivas pueden ser descritas de manera formal utilizando las estructuras que corresponden al conocimiento descrito en nuestros modelos.</p></li>
</ul>
<p>En los modelos de inteligencia artificial se asume que muchos aspectos de la inteligencia pueden ser simulados mediante la manipulación de símbolos.</p>
<strong>Ventajas y desventajas del paradigma simbólico</strong>
<p>Entre las ventajas de estos sistemas se encuentran las siguientes <span class="citation" data-cites="GARNELO201917"></span>:</p>
<ul>
<li><p><strong>Interpretabilidad:</strong> Debido al uso de símbolos (generalmente de alto nivel, como nodos, predicados, etc) y la naturaleza de las operaciones realizadas con ellos (transición entre estados válidos, operaciones de inferencia, etc) es fácil entender el funcionamiento de los sistemas y la manera en la cual llegan a los resultados obtenidos.</p></li>
<li><p><strong>Generalización:</strong> Las representaciones simbólicas de alto nivel pueden permitir generalización.</p></li>
<li><p><strong>Eficiencia de los datos:</strong> Este paradigma a diferencia de otros no requiere una gran cantidad de datos (un ejemplo de lo contrario son muchos algoritmos del paradigma conexionista), el uso de los símbolos también permite que estos puedan ser reutilizados en otros escenarios.</p></li>
</ul>
<p>Dentro de las principales desventajas es el hecho de que el conocimiento no suele ser aprendido sino diseñado de manera “manual”, otro punto a considerar es el hecho de que hay conocimiento demasiado complejo como para ser plasmado de esta manera. Por lo anteriormente mencionado no hubo mucho avance con este paradigma en el reconocimiento de imágenes y el procesamiento del lenguaje natural.</p>
<strong>Orígenes</strong>
<p>Uno de los primeros programas basados en el uso de reglas lógicas fue “Logic Theorist” creado por Allen Newell, Herbert A. Simon y Cliff Shaw en 1956, este programa eventualmente demostró 38 de los primeros 52 teoremas del trabajo Principia Mathematica.</p>
<p>El trabajo realizado por Newell, Simon y Shaw precedió a la conferencia de Dartmouth, a pesar de que ellos ya habían realizado un programa que utilizaba uno de los paradigmas más importantes de la inteligencia artificial simbólica (Simulación cognitiva) parece que nadie salvo ellos se dieron cuenta de la importancia de su trabajo a largo plazo <span class="citation" data-cites="mccorduck2004machines"></span>.</p>
<p>La idea de usar la lógica como representación de la información en un programa se le atribuye a John McCarthy por su propuesta del “advice taker” en 1958. El programa propuesto por John McCarthy era un programa hipotético, J. Alan Robinson en 1963 desarrolló una manera de implementar deducción en una computadora mediante el algoritmo de resolución y unificación, sin embargo las implementaciones de estos algoritmos resultaban en programas que tardaban demasiadas iteraciones en dar resultados.</p>
<p>En 1970 se obtuvieron mejores resultados al reducir la lógica al uso de cláusulas de Horn, de esta manera se desarrollaron mejores algoritmos de deducción y se creó el lenguaje de programación Prolog (Un lenguaje de programación declarativo basado en la programación lógica).</p>
<p><strong>Clasificación</span> Existen diversos acercamientos a la inteligencia artificial simbólica que cumplen con las características presentadas al inicio de este capítulo, a continuación se presenta una pequeña descripción de cada uno de ellos <span class="citation" data-cites="flasinski2016symbolic"></strong>:</p>
<ul>
<li><p><strong>Simulación cognitiva:</strong> Se basa en simular habilidades cognitivas del ser humano (resolución de problemas, razonamiento, aprendizaje) mediante la definición de algoritmos que implementen la heurística. Por lo tanto, en el diseño de estos algoritmos se trata de descubrir conceptos y reglas que nos permiten resolver problemas. Anteriormente se mencionó que el trabajo de Newell, Simon y Shaw (Logic Theorist) incorporaba este acercamiento de manera exitosa.</p></li>
<li><p><strong>Acercamiento basado en lógica:</strong> John McCarthy fue el precursor de este tipo de sistemas ya que aseguraba que un sistema inteligente debería de estar basado en sistemas formales de razonamiento lógica en lugar de “simuladores” de procesos mentales basados en algoritmos heurísticos. De esta manera el conocimiento podía ser representado mediante reglas lógicas y un programa universal (un programa dedicado a resolver problemas mediante la inferencia) se encargaría de encontrar la solución.</p></li>
<li><p><strong>Representación de conocimiento basado en reglas:</strong> Newell y Simon continuaron su investigación en modelos cognitivos y en 1972 propusieron sistemas basados en la memoria a corto y largo plazo. La memoria a largo plazo (production memory) es representada por reglas simples (si .... entonces ...) y la memoria a corto plazo (working memory) contiene la información del entorno sobre el cual opera, continuamente monitorea los datos de la memoria a corto plazo para determinar si alguna regla de la production memory se cumple, en caso de que la condición de la regla sea satisfecha se ejecuta la acción de la regla que puede ser una conclusión, la adición de una regla a la memoria a largo plazo, una acción que permita interactuar con el entorno, etc. Este acercamiento no tuvo tanto éxito, uno de sus programas más relevantes fue la creación de un sistema experto basado en reglas, estos sistemas expertos son una subclase de los sistemas expertos que se pueden producir usando el acercamiento basado en la lógica.</p></li>
<li><p><strong>Representación estructurada del conocimiento:</strong> Este acercamiento se basa en la manipulación de estructuras que contienen conocimiento, estas estructuras pueden ser redes semánticas, marcos (frames), etc. Mediante el uso de estas estructuras se busca desarrollar programas capaces de resolver problemas específicos.</p></li>
</ul>
<p>De estos acercamientos yo considero que el más exitoso fue el de la programación lógica (o acercamiento basado en lógica), gracias a este acercamiento se desarrollaron los sistemas expertos que dieron lugar al boom de la inteligencia artificial (1980–1987), sin embargo es importante tener en cuenta las limitaciones, ventajas y desventajas de este tipo de sistemas.</p>
<p>Este capítulo se centrará en el acercamiento basado en lógica debido no solamente a ser el de mayor éxito, sino también por su base formal.</p>
<strong>Simulación cognitiva</strong>
<p>Como se mencionó anteriormente la simulación cognitiva se basa en simular habilidades cognitivas del ser humano mediante la definición de algoritmos que implementen la heurística. Vamos a profundizar un poco en su funcionamiento y luego exploraremos de manera simple el funcionamiento del programa “logic theorist”.</p>
<p>En la resolución de problemas partimos de un estado inicial que representa la situación actual del problema, mediante funciones de transición podemos pasar a otros estados (tomando el ejemplo del ajedrez estas funciones de transición serían todos los movimientos válidos) si estos estados son nuestra solución se les llama “goal states” en caso de que no lo sea son estados intermedios. Un espacio de estados está constituido por estos estados (inicial, intermedio y objetivo), se puede representar mediante un grafo, donde los nodos son los estados y los ejes son las transiciones entre los mismos.</p>
<p>En la simulación cognitiva podemos usar estos conceptos para generar soluciones, partiendo de un estado inicial se aplican funciones de transición para ampliar nuestro espacio de estados y buscar una nueva solución, aquí podemos observar que el espacio de estados crecería de manera exponencial en la búsqueda de soluciones por lo cual estos algoritmos suelen implementar heurística para cortar algunas de las ramas y reducir el espacio de búsqueda.</p>
<p>Ahora vamos a observar como el programa “logic theorist” utiliza estos conceptos para probar teoremas matemáticos:</p>
<p>Parte de un conjunto de teoremas, que es nuestro estado inicial. Utiliza diferentes funciones de transición para expandir el espacio de estados, estas funciones pueden ser las siguientes:</p>
<ul>
<li><p>Método de reemplazo</p></li>
<li><p>Método de separación (modus ponendo ponens)</p></li>
<li><p>Método de encadenamiento</p></li>
</ul>
<p>Estos métodos se aplican sobre teoremas que se quieren comprobar, utilizando los teoremas en nuestro estado actual, si alguno de estos métodos logra comprobar la veracidad de un teorema, este se añade a los teoremas comprobados ampliando así nuestro espacio de estados.</p>
<p>Logic theorist utiliza la heurística en el funcionamiento de estos métodos tomando los axiomas comprobados que sean más “prometedores” en la comprobación del teorema.</p>
<strong>Programación lógica</strong>
<p>Para explorar este acercamiento del paradigma simbólico vamos a partir de la pregunta ¿Qué es la razón?, la razón la capacidad de la mente humana de establecer relaciones entre ideas o conceptos y obtener conclusiones o formar juicios, este acercamiento busca simular o imitar esta facultad de la mente por medio del razonamiento lógico, dado un conjunto de juicios que mantienen relaciones lógicas entre sí (premisas) se puede deducir o inferir un nuevo juicio al que denominamos conclusión.</p>
<p>“La ciencia que estudia que tipos de esquemas de inferencia aseguran la validez de las conclusiones es la lógica” <span class="citation" data-cites="munoz2013introduccion"></span>.</p>
<p>Mediante la lógica podemos representar el conocimiento y utilizarlo de tal manera que si las premisas son verdaderas, la conclusión también lo será.</p>
<strong>La lógica formal</strong>
<p>La lógica formal o lógica matemática estudia los principios y métodos que se emplean para diferenciar el razonamiento correcto del incorrecto. Analicemos el siguiente razonamiento:</p>
<p>Si estoy corriendo entonces voy más lento<br />
Estoy corriendo<br />
-Por lo tanto: voy más lento</p>
<p>Este razonamiento podría parecer incorrecto debido a que sabemos que si corremos vamos más rápido, sin embargo la lógica formal estudia la lógica del razonamiento, si le asignamos letras a las distintas proposiciones podemos damos cuenta de que en realidad este razonamiento es correcto.</p>
<p>p: estoy corriendo<br />
q: voy más lento</p>
<p>p → q<br />
p<br />
(1,0)<span>50</span><br />
q</p>
<p>Podemos decir que esta inferencia posee validez formal</p>
<strong>Clasificación de la lógica</strong>
<p>La lógica tiene diversas subdivisiones, cada una con su propia semántica y sintaxis, algo importante es observar cómo cada una de las divisiones de la lógica expande la lógica del orden anterior, en consecuencia es más expresiva y por ende requiere de añadir más recursos o eliminar restricciones sobre el uso de los ya existentes <span class="citation" data-cites="munoz2013introduccion"></span>.</p>
<figure>
<img src="pandocConversionMedia/ia/Division in logic.png" id="fig:Division-in-logic" style="width:8cm" alt="Representación de las diversas divisiones en la lógica." /><figcaption aria-hidden="true">Representación de las diversas divisiones en la lógica.</figcaption>
</figure>
<p>También se puede dividir la lógica en lógica clásica y no clásica, en la lógica clásica las fórmulas lógicas solo pueden tener dos valores (verdadero o falso), por eso se le llama cálculo bivalente, en la lógica no clásica las fórmulas pueden tomar más valores, un ejemplo es la lógica trivalente que además de los valores verdadero y falso contempla un tercer valor que no representa que el valor se desconoce o es incierto <span class="citation" data-cites="munoz2013introduccion"></span>.</p>
<p>Existen otro tipo de lógicas que contemplan elementos como el tiempo, en el cual el valor de verdad depende del momento actual o en el que dio lugar.</p>
<p><strong>Nota: Diferencia entre lógica de predicados y cálculo de predicados</strong></p>
<p>Es común encontrar estos términos y preguntarse la diferencia entre los mismos, estos términos suelen usarse de manera intercambiable y representan lo mismo, cada cálculo o división de la lógica debe componerse de los siguientes elementos <span class="citation" data-cites="munoz2013introduccion"></span>:</p>
<ul>
<li><p>La <strong>semántica</strong> de la lógica, el significado de cada uno de los elementos que la compone.</p></li>
<li><p>Una <strong>sintaxis</strong> que nos permita formar combinaciones correctas de los elementos primitivos . Mediante la definición de un conjunto de <strong>reglas de formación</strong> podemos definir como es una <strong>fórmula bien</strong> formada (fbf, otro término con el cual es probable encontrarse), de esta manera se puede determinar si la combinación de los elementos es correcta o no.</p></li>
<li><p>Un conjunto de <strong>reglas de transformación</strong> de carácter algorítmico que nos permitan ir de una fbf a otra, estas transformaciones deben asegurar la validez formal de las fórmulas lógicas.</p></li>
</ul>
<p>En este tema veremos cómo podemos utilizar la lógica de primer orden para implementar un sistema experto, este programa emula las capacidades de tomar decisiones del ser humano, debido a que como se mencionó aquí los cálculos de la lógica se construyen sobre la lógica del orden anterior primero revisaremos la lógica de orden cero.</p>
<strong>Lógica de orden cero o proposicional</strong>
<p>La lógica proposicional es la más simple de los tipos de lógica y como su nombre indica está basada en sentencias o proposiciones, una <strong>sentencia o proposición</strong> es una oración capaz de tener un valor de verdad (verdadero o falso).</p>
<p>Mediante las proposiciones podemos representar información, ejemplo:</p>
<p>p: estoy corriendo<br />
q: voy más rápido</p>
<p>Estas dos proposiciones contienen un solo elemento por lo cual son conocidas como <strong>proposiciones atómicas o proposiciones simples</strong> (También se les conoce como proposiciones primitivas).</p>
<p>Mediante el uso de conectores operadores lógicos podemos formar <strong>proposiciones compuestas</strong>, que nos muestran las relaciones entre las proposiciones, ejemplo (si llueve, entonces voy más rápido):</p>
<p>p → q<br />
<strong>Operadores lógicos</strong></p>
<p>A continuación se describirán los diferentes operadores lógicos y mediante el uso de tablas de verdad <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> se mostrará su comportamiento (1 - Verdadero, 0 - Falso):</p>
<p><u>Negación ¬</u></p>
<p>Cuando la variable es verdadera al negarla se convierte en falsa, y si es falsa, al negarla se hace verdadera.</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">A</th>
<th style="text-align: left;">¬A</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">0</td>
<td style="text-align: left;">1</td>
</tr>
</tbody>
</table>
<p><u>Disyunción v</u></p>
<p>Es falsa cuando ambas proposiciones son falsas.</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">A</th>
<th style="text-align: left;">B</th>
<th style="text-align: left;">A v B</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
</tr>
</tbody>
</table>
<p><u>Conjunción <span class="math inline">\(\Lambda\)</span></u></p>
<p>Solo es verdadera cuando ambas proposiciones son verdaderas.</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">A</th>
<th style="text-align: left;">B</th>
<th style="text-align: left;">A <span class="math inline">\(\Lambda\)</span> B</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
</tr>
</tbody>
</table>
<p><u>Condicional →</u></p>
<p>Solo es falsa cuando la primera proposición es verdadera y la segunda falsa.</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">A</th>
<th style="text-align: left;">B</th>
<th style="text-align: left;">A → B</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">1</td>
</tr>
</tbody>
</table>
<p><u>Bicondicional <span class="math inline">\(\leftrightarrow\)</span></u></p>
<p>Solo es verdadera cuando ambas proposiciones tienen el mismo valor.</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">A</th>
<th style="text-align: left;">B</th>
<th style="text-align: left;">A <span class="math inline">\(\leftrightarrow\)</span> B</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">1</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">0</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">1</td>
</tr>
</tbody>
</table>
<p>Utilizando estas conectivas podemos representar conocimiento más complejo</p>
<p>Si es sábado o es domingo entonces saco a pasear a mi perro y desayuno hotcakes.<br />
a: es sábado<br />
b: es domingo<br />
c: saco a pasear a mi perro<br />
d: desayuno hotcakes</p>
<p>(a v b) → (c <span class="math inline">\(\Lambda\)</span> d)</p>
<p>Aquí quiero hacer notar el uso de la condicional, cuando no es sábado o domingo puede ser que saque a pasear a mi perro y desayune hotcakes, pero siempre que sea sábado o domingo voy a sacar a mi perro a pasear y desayunar hotcakes.</p>
<p>Ahora vamos a dar las reglas de formación para crear fórmulas bien formadas usando la notación de Backus-Naur (BNF):</p>
<p>&lt; Fórmula &gt; ::= ProposiciónAtómica<br />
| ¬ &lt; Fórmula &gt;<br />
| &lt; Fórmula &gt; <span class="math inline">\(\Lambda\)</span> &lt; Fórmula &gt;<br />
| &lt; Fórmula &gt; v &lt; Fórmula &gt;<br />
| &lt; Fórmula &gt; → &lt; Fórmula &gt;<br />
| &lt; Fórmula &gt; <span class="math inline">\(\leftrightarrow\)</span> &lt; Fórmula &gt;<br />
| ( &lt; Fórmula &gt; )</p>
<p><strong>Tipos de fórmulas bien formadas en lógica proposicional</strong></p>
<p><u>Tautología:</u> es una fbf que siempre es verdadera para cualquier interpretación (para cualquier combinación de valores de verdad que tomen sus proposiciones atómicas).</p>
<p>Un ejemplo simple de tautología es la siguiente: A v (¬A)</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">A</th>
<th style="text-align: left;">(¬ A)</th>
<th style="text-align: left;">A v ( ¬ A )</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">1</td>
</tr>
<tr class="even">
<td style="text-align: left;">0</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
</tr>
</tbody>
</table>
<p><u>Contradicción:</u> es una fbf que siempre es falsa para cualquier interpretación (para cualquier combinación de valores de verdad que tomen sus proposiciones atómicas).</p>
<p>Un ejemplo simple de contradicción es la siguiente: A <span class="math inline">\(\Lambda\)</span> (¬A)</p>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">A</th>
<th style="text-align: left;">(¬ A)</th>
<th style="text-align: left;">A <span class="math inline">\(\Lambda\)</span> (¬A)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">0</td>
<td style="text-align: left;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">0</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">0</td>
</tr>
</tbody>
</table>
<p><u>Contingencia:</u> es aquella proposición que puede ser verdadera o falsa dependiendo de los valores de las proposiciones que la integran.</p>
<p>Otro concepto importante son las equivalencias lógicas, las equivalencias lógicas se dan cuando dos proposiciones p y q son equivalentes en la lógica.</p>
<p>Es decir: p <span class="math inline">\(\leftrightarrow\)</span> q</p>
<p><strong>Reglas de inferencia</strong></p>
<p>Estas reglas de transformación nos permiten deducir nuevas proposiciones a partir de premisas. Considero importante estas reglas de transformación como parte de la lógica proposicional, sin embargo para los temas posteriores no es imperativo que se entiendan a detalle estas reglas, de cualquier manera recomiendo revisar algunas para entender como podemos deducir nuevas proposiciones a partir de conocimiento previo.</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">——–</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">P v Q</td>
<td style="text-align: left;">P → (P v Q)</td>
<td style="text-align: left;">adición</td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">——–</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">P</td>
<td style="text-align: left;">(P <span class="math inline">\(\Lambda\)</span> Q) → P</td>
<td style="text-align: left;">simplificación</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">P → Q</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">———-</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Q</td>
<td style="text-align: left;">[P <span class="math inline">\(\Lambda\)</span> (P → Q)] → Q</td>
<td style="text-align: left;">modus ponens</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">P → Q</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">———–</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">¬ P</td>
<td style="text-align: left;">[¬ Q <span class="math inline">\(\Lambda\)</span> (P → Q)] → ¬ P</td>
<td style="text-align: left;">modus tollens</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">¬ P</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">———–</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Q</td>
<td style="text-align: left;">[(P v Q) <span class="math inline">\(\Lambda\)</span> ¬ P] → Q</td>
<td style="text-align: left;">silogismo disyuntivo</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Q → R</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">———–</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">P → R</td>
<td style="text-align: left;">[(P → Q) <span class="math inline">\(\Lambda\)</span> (Q → R)] → [P → R]</td>
<td style="text-align: left;">silogismo hipotético</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">P v R</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">———–</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Q v S</td>
<td style="text-align: left;">[(P → Q) <span class="math inline">\(\Lambda\)</span> (R → S) <span class="math inline">\(\Lambda\)</span> (P v R)] → [Q v S]</td>
<td style="text-align: left;">dilema constructivo</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Q v S</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">————-</td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">P v R</td>
<td style="text-align: left;">[(P → Q) <span class="math inline">\(\Lambda\)</span> (R → S) <span class="math inline">\(\Lambda\)</span> ( Q v S)] → [ P v R]</td>
<td style="text-align: left;">dilema destructivo</td>
</tr>
</tbody>
</table>
<p><strong>Reglas de reemplazo</strong></p>
<p>Este tipo de reglas de transformación nos permiten transformar las fórmulas en otras fórmulas con equivalencia lógica, otra diferencia es la bidireccionalidad de las mismas y que pueden ser aplicadas en porciones de la fórmula, si desean conocer más de este tema considero que en el siguiente link hay información útil: <a href="https://www.iep.utm.edu/prop-log/">https://www.iep.utm.edu/prop-log/</a></p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">Doble negación</td>
<td style="text-align: left;">¬ ¬ a = a</td>
</tr>
<tr class="even">
<td style="text-align: left;">Conmutatividad</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">a v b = b v a</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Asociatividad</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">(a v b) v c = a v (b v c)</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Tautología</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">a v a = a</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Ley de morgan</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">¬(a v b) = ¬ a <span class="math inline">\(\Lambda\)</span> ¬ b</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">Implicación material</td>
<td style="text-align: left;">a → b = ¬ a v b</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Distribución</td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">a v (b <span class="math inline">\(\Lambda\)</span> c) = (a v b) <span class="math inline">\(\Lambda\)</span> (a v c)</td>
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Exportación</td>
<td style="text-align: left;">a → (b → c) = (a <span class="math inline">\(\Lambda\)</span> b) → c</td>
</tr>
<tr class="even">
<td style="text-align: left;">Transposición</td>
<td style="text-align: left;">a → b = ¬ b → ¬ a</td>
</tr>
</tbody>
</table>
<p><strong>Limitaciones de la lógica proposicional</strong></p>
<p>Como se mencionó anteriormente la lógica de orden cero es el tipo más básico de lógica lo que implica que no posee un lenguaje lo suficientemente expresivo para representar una diversa cantidad de conocimientos del mundo real, pongamos a continuación un ejemplo simple, ¿Cómo representamos (usando la lógica proposicional) las siguientes oraciones?</p>
<p>Todos los hombres son mortales<br />
Sócrates es un hombre<br />
Entonces: Sócrates es mortal</p>
<p>Podemos observar que en la lógica proposicional carecemos de los recursos lingüísticos necesarios para representar este conocimiento.</p>
<strong>Lógica de primer orden o de predicados</strong>
<p>La lógica proposicional mediante oraciones declarativas representa hechos, la lógica de primer orden o lógica de predicados aumenta la expresividad permitiendo representar los objetos y sus relaciones <span class="citation" data-cites="guerra_repcon"></span>.</p>
<figure>
<img src="pandocConversionMedia/ia/Modelo-log-primer.png" id="fig:Modelo-log-primer" style="width:14cm" alt="Modelo que contiene cinco objetos, dos relaciones binarias, tres relaciones unita-rias (indicadas mediante etiquetas sobre los objetos), y una función unitaria: pierna izquierda. Figura tomada de Russel Stuart; Norvig Peter. (2006). Inteligencia Artificial. Un enfoque moderno. Pearson Prentice Hall. Madrid, España. " /><figcaption aria-hidden="true">Modelo que contiene cinco objetos, dos relaciones binarias, tres relaciones unita-rias (indicadas mediante etiquetas sobre los objetos), y una función unitaria: pierna izquierda. Figura tomada de Russel Stuart; Norvig Peter. (2006). Inteligencia Artificial. Un enfoque moderno. Pearson Prentice Hall. Madrid, España.<span class="citation" data-cites="russell2004inteligencia"></span> </figcaption>
</figure>
<p>En la figura <a href="#fig:Modelo-log-primer" data-reference-type="ref" data-reference="fig:Modelo-log-primer">3.2</a> se puede observar un modelo en el que se incluye la noción de relaciones, funciones y objetos. A continuación, se describen los nuevos recursos de los que disponemos en la lógica de primer orden.</p>
<ul>
<li><p><strong>Objetos:</strong> Nos permiten expresarnos acerca de los diferentes elementos en un determinado dominio. Al conjunto de todos los objetos utilizados se les conoce como <strong>Dominio</strong> o <strong>Universo de discurso</strong> <span class="citation" data-cites="guerra_repcon"></span>.</p></li>
<li><p><strong>Función:</strong> Una función es un tipo especial de relación que mapea un conjunto de objetos de entrada con un único objeto de salida. Al conjunto de todas las funciones se le conoce como <strong>Base funcional</strong> <span class="citation" data-cites="guerra_repcon"></span>.</p>
<p>Las funciones nos sirven para evitar la necesidad de declarar muchos objetos, supongamos que tuviéramos como Dominio los estados de un país, si quisiéramos formar predicados que tuvieran como objetos sus capitales tendríamos dos opciones crear un nuevo objeto para cada estado o crear una función llamada por ejemplo: “capital”.</p></li>
<li><p><strong>Predicado:</strong> El predicado indica relaciones entre objetos, al conjunto de todos los predicados se le conoce como <strong>Base relacional</strong> <span class="citation" data-cites="guerra_repcon"></span>.</p>
<p>Supongamos que tenemos dos objetos, Juan y Pablo, si quisieramos indicar que Juan es hijo de Pablo podríamos hacerlo mediante el siguiente predicado: esHijo(Juan,Pablo)</p></li>
<li><p><strong>Variables:</strong> Son un elemento importante para la lógica de primer orden y suelen ser representadas mediante cualquier secuencia de caracteres que inicie con mayúscula, éstas variables representan a objetos del universo de discurso <span class="citation" data-cites="guerra_repcon"></span>.</p>
<p>Un ejemplo de un predicado que usa variables sería el siguiente: esHijo(X,Y), más adelante veremos cómo pueden usarse para expresar conocimiento.</p></li>
<li><p><strong>Cuantificadores:</strong> El cuantificador universal <span class="math inline">\(\forall\)</span> que nos permite expresar relaciones acerca de todos los objetos en el dominio <span class="citation" data-cites="guerra_repcon"></span>.<br />
<span class="math inline">\(\forall\)</span> X podría leerse como “Para todo objeto X”.<br />
El cuantificador existencial <span class="math inline">\(\exists\)</span> nos permite expresar la existencia de un objeto en el dominio <span class="citation" data-cites="guerra_repcon"></span>. Por ejemplo podríamos expresar la siguiente oración: “Existe un objeto X que es azul y es grande”<br />
<span class="math inline">\(\exists\)</span>X esAzul(X) <span class="math inline">\(\Lambda\)</span> esGrande(X)<br />
Se pueden utilizar múltiples cuantificadores en una fórmula pero es importante tomar en cuenta que el orden de lo mismo si importa, por ejemplo <span class="math inline">\(\forall\)</span>X <span class="math inline">\(\exists\)</span>Y es interpretado como para todo X existe un elemento Y, en cambio <span class="math inline">\(\exists\)</span>X <span class="math inline">\(\forall\)</span>Y es interpretado como existe algún elemento X para el cual todos los elementos Y.</p></li>
<li><p><strong>Términos:</strong> Son todos los elementos que nos permitan denotar objetos y están formados por funciones, variables y constantes. Un ejemplo sería el siguiente calif ( hermano( alex ) , sma ) es un término que denota la calificación obtenida por el hermano de Álex en el curso de Sistemas Multi-Agentes <span class="citation" data-cites="guerra_repcon"></span>.</p></li>
</ul>
<p>Ahora veremos la sintaxis de la lógica de primer orden para posteriormente ver algunos ejemplos de fbf.</p>
<figure>
<img src="pandocConversionMedia/ia/sint-log-primer.png" id="fig:sint-log-primer" style="width:14cm" alt="Sintaxis de la lógica de primer orden en BNF. Figura tomada de Russel Stuart; Norvig Peter. (2006). Inteligencia Artificial. Un enfoque moderno. Pearson Prentice Hall. Madrid, España.  " /><figcaption aria-hidden="true">Sintaxis de la lógica de primer orden en BNF. Figura tomada de Russel Stuart; Norvig Peter. (2006). Inteligencia Artificial. Un enfoque moderno. Pearson Prentice Hall. Madrid, España. <span class="citation" data-cites="russell2004inteligencia"></span> </figcaption>
</figure>
<p>Ahora veamos un ejemplo:</p>
<p><u>Dado como dominio las personas, representar el siguiente conocimiento:</u></p>
<p>Todos los maestros son responsables<br />
Algunos maestros son doctores<br />
Todos los miembros del grupo son maestros o alumnos<br />
Juan es maestro<br />
Juan le da clase a Pedro<br />
Algunos maestros le dan clase a todos los alumnos<br />
<u>Solución:</u></p>
<p>D = <span> personas </span><br />
<span class="math inline">\(\forall\)</span>X maestro(X) → responsable(X)<br />
<span class="math inline">\(\exists\)</span>X ( maestro(X) <span class="math inline">\(\Lambda\)</span> doctor(X) )<br />
<span class="math inline">\(\forall\)</span>X miembro(X) → ( maestro(X) v alumno(X) )<br />
maestro(Juan)<br />
daClase(Juan,Pedro)<br />
<span class="math inline">\(\exists\)</span>X <span class="math inline">\(\forall\)</span>Y maestro(X) <span class="math inline">\(\Lambda\)</span> alumno(Y) <span class="math inline">\(\Lambda\)</span> daClase(X,Y)</p>
<p><strong>Sustitución en la lógica de primer orden</strong></p>
<p>La sustitución es un conjunto finito de pares de la forma { v1→t1, v2→t2, ... vn→tn }, (también es utilizada la notación { v1/t1, v2/t2, ... vn/tn }, cuando se aplica una sustitución a una expresión se obtiene una nueva, reemplazando en la expresión original cada aparición de la variable vi por el término ti (1 <span class="math inline">\(\leq\)</span> i <span class="math inline">\(\leq\)</span> n) <span class="citation" data-cites="navarro_prolog"></span>.</p>
<p>Ejemplo:</p>
<p><span class="math inline">\(\alpha\)</span> = esPequeño(x) <span class="math inline">\(\Lambda\)</span> juegaMucho(x) → esNiño(x)</p>
<p>Sust( <span>x/Juan</span>, <span class="math inline">\(\alpha\)</span> ) = esPequeño(Juan) <span class="math inline">\(\Lambda\)</span> juegaMucho(Juan) → esNiño(Juan)</p>
<p>Sust( <span>x/hijo(Pedro)</span>, <span class="math inline">\(\alpha\)</span> ) = esPequeño(hijo(Pedro)) <span class="math inline">\(\Lambda\)</span> juegaMucho(hijo(Pedro)) → esNiño(hijo(Pedro))</p>
<p><strong>Inferencia en la lógica de primer orden</strong></p>
<p><strong>Reglas de inferencia para cuantificadores y proposicionalización</strong></p>
<p>Si eliminamos los cuantificadores de nuestros predicados podemos utilizar las reglas de inferencia de la lógica proposicional <span class="citation" data-cites="russell2004inteligencia"></span>.</p>
<p><u>Regla de especificación universal:</u> Podemos inferir cualquier sentencia obtenida por sustitución de la variable por un término base (un término sin variables) <span class="citation" data-cites="russell2004inteligencia"></span>.</p>
<p><span class="math display">\[\frac{\forall v  \; \alpha}{Sust(\{ v/g,\alpha \})}\]</span></p>
<p>Ejemplo:</p>
<p><span class="math inline">\(\alpha\)</span> = esPequeño(x) <span class="math inline">\(\Lambda\)</span> juegaMucho(x) → esNiño(x)</p>
<p>Sust( <span>x/Juan</span>, <span class="math inline">\(\alpha\)</span> ) = esPequeño(Juan) <span class="math inline">\(\Lambda\)</span> juegaMucho(Juan) → esNiño(Juan)</p>
<p><u>Regla de especificación existencial:</u> Esta regla es más complicada ya que requiere que el símbolo de constante k no aparezca en ninguna otra parte de la base de conocimientos<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> <span class="citation" data-cites="russell2004inteligencia"></span>.</p>
<p><span class="math display">\[\frac{\exists v  \; \alpha}{Sust(\{ v/k,\alpha \})}\]</span></p>
<p>Para reducir a la inferencia proposicional partimos de dos ideas <span class="citation" data-cites="russell2004inteligencia"></span>:</p>
<ul>
<li><p>Toda sentencia que haga uso del cuantificador existencial se puede sustituir por el conjunto de todas las especificaciones posibles.</p></li>
<li><p>Mediante el uso de la regla de especificación universal, se pueden aplicar las sustituciones de todos los términos base posibles para obtener una base de conocimiento proposicional, a esta técnica se le conoce como proposicionalización.</p></li>
</ul>
<p>Al hacer uso de estas ideas podemos aplicar posteriormente las reglas de inferencia vistas en el tema anterior.</p>
<p><strong>Modus Ponens Generalizado</strong></p>
<p>El Modus Ponens Generalizado es una versión del Modus Ponens que puede ser usada directamente en la lógica de predicados sin la necesidad de aplicar la proposicionalización.</p>
<p>La ventaja clave de este tipo de reglas “elevadas” es que solo realizan aquellas sustituciones que se necesitan para realizar la inferencia <span class="citation" data-cites="russell2004inteligencia"></span>. A continuación se muestra el proceso de inferencia:</p>
<p><span class="math display">\[\frac{p_{1}^{&#39;},p_{1}^{&#39;},...,p_{n}^{&#39;},(p_{1} \Lambda p_{2} \Lambda ... \Lambda p_{n} \rightarrow q)}{Sust(\theta,q)}\]</span></p>
<p>Se tienen premisas de implicación <span class="math inline">\(p_i\)</span> y sentencias atómicas en nuestra base de conocimientos <span class="math inline">\(p_{i}^{&#39;}\)</span>, para aplicar esta regla de inferencia se tiene que encontrar una sustitución <span class="math inline">\(\theta\)</span> que permita que al aplicarse en las premisas de implicación y las sentencias de la base de conocimientos las haga idénticas.</p>
<p>A continuación se presenta un ejemplo:</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\forall\)</span>x esPequeño(x) <span class="math inline">\(\Lambda\)</span> juegaMucho(x) → esNiño(x)</td>
</tr>
<tr class="even">
<td style="text-align: left;">esPequeño(Juan)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">juegaMucho(Juan)</td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(p_1\)</span> = esPequeño(x)</td>
<td style="text-align: left;"><span class="math inline">\(p_2\)</span> = juegaMucho(x)</td>
<td style="text-align: left;">q = esNiño(x)</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(p_{1}^{&#39;}\)</span> = esPequeño(Juan)</td>
<td style="text-align: left;"><span class="math inline">\(p_{2}^{&#39;}\)</span> = juegaMucho(Juan)</td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>Para lograr que las sentencias atómicas sean iguales a las premisas de implicación se aplica la sustitución <span class="math inline">\(\theta\)</span> = { x/Juan }, por lo tanto</p>
<p>Sust(<span class="math inline">\(\theta\)</span>,q) = esNiño(Juan)</p>
<p>Vamos a explorar un segundo ejemplo que contenga una sentencia atómica con una variable, para esto supondremos que todos los individuos de nuestro dominio juegan mucho:</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\forall\)</span>x esPequeño(x) <span class="math inline">\(\Lambda\)</span> juegaMucho(x) → esNiño(x)</td>
</tr>
<tr class="even">
<td style="text-align: left;">esPequeño(Juan)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\forall\)</span>y juegaMucho(y)</td>
</tr>
</tbody>
</table>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(p_1\)</span> = esPequeño(x)</td>
<td style="text-align: left;"><span class="math inline">\(p_2\)</span> = juegaMucho(x)</td>
<td style="text-align: left;">q = esNiño(x)</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(p_{1}^{&#39;}\)</span> = esPequeño(Juan)</td>
<td style="text-align: left;"><span class="math inline">\(p_{2}^{&#39;}\)</span> = juegaMucho(y)</td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>Para lograr que las sentencias atómicas sean iguales a las premisas de implicación se aplica la sustitución <span class="math inline">\(\theta\)</span> = { x/Juan }, por lo tanto</p>
<p>Sust(<span class="math inline">\(\theta\)</span>,q) = esNiño(Juan)</p>
<p><u>Unificación</u></p>
<p>Hasta este momento no nos hemos preguntado cómo encontrar el valor de la substitución que permita que expresiones lógicas distintas se hagan lógicas, a este proceso se le conoce como unificación <span class="citation" data-cites="russell2004inteligencia"></span>.</p>
<p>Existen ocasiones donde se puede obtener más de un unificador, por ejemplo:</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">Unificar( madre(María,x), madre(y,z) ) = { y/María, z/Juan, x/Juan }</td>
</tr>
<tr class="even">
<td style="text-align: left;">Unificar( madre(María,x), madre(y,z) ) = { y/María, x/z }</td>
</tr>
</tbody>
</table>
<p>Si se realizan las sustituciones se puede observar que ambas unificaciones son válidas, generalmente se va a buscar obtener el <strong>unificador más general (UMG)</strong>, cada par de expresiones lógicas tiene su umg que es aquel que aplica menos restricciones sobre las variables. En el ejemplo anterior el umg sería: { y/María, x/z }.</p>
<p>Existe un algoritmo para obtener el umg, sin embargo en este libro no se detallará su funcionamiento debido a que en las herramientas modernas no se suele tener la necesidad de programar el algoritmo de unificación.</p>
<p>Si se tienen dudas o se quiere profundizar en la lógica proposicional o de predicados recomiendo leer el libro de Russel y Norvig <span class="citation" data-cites="russell2004inteligencia"></span>.</p>
<strong>Cláusulas de Horn</strong>
<p>Las cláusulas de Horn son fórmulas lógicas con una estructura particular, son una disyunción de literales con a lo sumo (como máximo) un literal positivo.</p>
<p>¬ <span class="math inline">\(p_1\)</span> v ¬ <span class="math inline">\(p_2\)</span> v ... ¬ <span class="math inline">\(p_k\)</span> v q</p>
<p>Una cláusula de Horn también puede ser representada de la siguiente forma (para lograr esta representación se hace uso de reglas de transformación, se hace uso de la ley de morgan y la regla de implicación material):</p>
<p>(<span class="math inline">\(p_1\)</span> <span class="math inline">\(\Lambda\)</span> <span class="math inline">\(p_2\)</span> <span class="math inline">\(\Lambda\)</span> ... <span class="math inline">\(\Lambda\)</span> <span class="math inline">\(p_k\)</span>) → q</p>
<p>A la literal no negada (q) se le conoce como la cabeza de la cláusula y al resto de literales se les conoce como el cuerpo.</p>
<p><strong>Importancia de las cláusulas de Horn</strong></p>
<p>Como veremos a lo largo de este tema, las cláusulas de Horn juegan un rol muy importante en la programación lógica, mediante el uso de este tipo de fórmulas lógicas se pueden utilizar mecanismos de inferencia eficientes.</p>
<p><strong>Desventajas de las cláusulas de Horn</strong></p>
<p>Si bien es cierto que limitan la expresividad de la lógica de primer orden generalmente son lo suficientemente expresivas para representar una vasta cantidad de conocimiento.</p>
<p>La inferencia con cláusulas de Horn es indecidible <a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. Sin embargo es semidecidible, cuando la fórmula es un teorema a veces se puede demostrar su validez, sin embargo cuando la fórmula no es un teorema siempre se puede demostrar su inconsistencia.</p>
<p><strong>Tipos de cláusulas de Horn</strong></p>
<p>A continuación se desglosan las tres posibles formas que puede tener una fórmula lógica y que cumplan con la estructura de una cláusula de Horn. Las cláusulas determinadas son aquellas que tienen un literal positivo, estas a su vez se dividen en hechos y reglas, aquellas cláusulas que no tienen ningún literal positivo se llaman objetivos determinados.</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">Hecho</td>
<td style="text-align: left;">q</td>
</tr>
<tr class="even">
<td style="text-align: left;">Regla</td>
<td style="text-align: left;">¬ <span class="math inline">\(p_1\)</span> v ¬ <span class="math inline">\(p_2\)</span> v ... ¬ <span class="math inline">\(p_k\)</span> v q</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Objetivo</td>
<td style="text-align: left;">¬ <span class="math inline">\(p_1\)</span> v ¬ <span class="math inline">\(p_2\)</span> v ... ¬ <span class="math inline">\(p_k\)</span></td>
</tr>
</tbody>
</table>
<p><strong>Inferencia mediante cláusulas de Horn</strong></p>
<p><strong>Encadenamiento hacia adelante</strong></p>
<p>Si tenemos nuestra base de conocimiento descrita mediante cláusulas de horn se puede realizar un algoritmo de encadenamiento hacia adelante muy sencillo que consiste en encontrar todas las reglas cuyo cuerpo pueda ser satisfecho con los hechos actuales y agregar a la base de hechos la cabeza de las reglas. Se repetirá el proceso hasta que no se puedan generar hechos nuevos o se haya comprobado algún objetivo. Hay que evitar añadir “renombramientos” a nuestra base de hechos, un renombramiento se da cuando sustituimos una variable por otra, lo cual da por resultado un predicado que tiene exactamente el mismo significado, ejemplo:</p>
<p>Come(x, hamburguesa) significa lo mismo que Come(y, hamburguesa)</p>
<p>En la figura <a href="#fig:pse-enca-adel" data-reference-type="ref" data-reference="fig:pse-enca-adel">3.4</a> se muestra el pseudocódigo del algoritmo de encadenamiento hacia adelante.</p>
<figure>
<img src="pandocConversionMedia/ia/pse-enca-adel.png" id="fig:pse-enca-adel" style="width:15cm" alt="Algoritmo de encadenamiento hacia adelante simple. Figura tomada de Russel Stuart; Norvig Peter. (2006). Inteligencia Artificial. Un enfoque moderno. Pearson Prentice Hall. Madrid, España.  " /><figcaption aria-hidden="true">Algoritmo de encadenamiento hacia adelante simple. Figura tomada de Russel Stuart; Norvig Peter. (2006). Inteligencia Artificial. Un enfoque moderno. Pearson Prentice Hall. Madrid, España. <span class="citation" data-cites="russell2004inteligencia"></span> </figcaption>
</figure>
<p>Este algoritmo de encadenamiento es ineficiente ya que cada iteración trataría de agregar hechos ya conocidos, para mejorar la eficiencia se podría usar un encadenamiento hacia adelante incremental que utilizará solo aquellas reglas cuyo cuerpo contenga algún conjuntor <span class="math inline">\(p_i\)</span> que se unifique con un hecho obtenido en la iteración anterior.</p>
<div class="center">
<p>(1,0)<span>420</span></p>
</div>
<p><strong>Ejercicio de programación:</strong></p>
<p>Realizar un programa capaz de realizar encadenamiento hacia adelante usando cualquier lenguaje.Este ejercicio puede ayudar a comprender los conceptos aprendidos en este capítulo.</p>
<p>En mi caso usé (junto con mis compañeros de equipo en ese trabajo) el lenguaje de programación Java, añadiré el link al repositorio por si alguien quiere revisar el código del algoritmo. <img src="pandocConversionMedia/Pictures/github/encad-adel.png" style="width:4cm" alt="image" /></p>
<p>(<a href="https://github.com/amr205/LogicProgramming---Forward-chaining">https://github.com/amr205/LogicProgramming---Forward-chaining</a>)</p>
<p><strong>Encadenamiento hacia atrás</strong></p>
<p>Con el encadenamiento hacia adelante vamos “descubriendo” nuevos hechos y paramos cuando no se pueden inferir nuevos hechos o se ha cumplido una meta. En el encadenamiento hacia atrás partimos de la meta que queremos demostrar y tratamos de determinar su validez.</p>
<p>Un algoritmo simple de encadenamiento hacia atrás sería el siguiente.</p>
<ul>
<li><p>Se tiene un objetivo</p></li>
<li><p>Se recorren las reglas y se selecciona la regla que permita unificar la cabeza de la regla con el objetivo, de esta manera se obtiene el umg y se sustituye el cuerpo de la regla con el umg, todos los predicados dentro de la regla se vuelven sub-objetivos y para cada uno de ellos se debe realizar este proceso.</p></li>
<li><p>Si no se encontró ninguna regla se recorren los hechos, si el objetivo es igual a algún hecho ese objetivo se considera como verdadero, en caso contrario se considera falso.</p></li>
</ul>
<p>Veamos el siguiente ejemplo:</p>
<p>En nuestra base de conocimientos tenemos los siguientes hechos y reglas.</p>
<ol>
<li><p>haceCroac(Fritz)</p></li>
<li><p>comeMoscas(Fritz)</p></li>
<li><p>haceCroac(x) <span class="math inline">\(\Lambda\)</span> comeMoscas(x)→esRana(x)</p></li>
<li><p>canta(x)<span class="math inline">\(\Lambda\)</span>tieneAlas(x)→esCanario(x)</p></li>
<li><p>esRana(x)→esVerde(x)</p></li>
<li><p>esCanario(x)→esAmarillo(x)</p></li>
</ol>
<p>El objetivo es determinar si: esVerde(Fritz)</p>
<p>A continuación se muestra un diagrama de cómo se realiza el encadenamiento hacia atrás para demostrar que el objetivo es verdadero.</p>
<figure>
<img src="pandocConversionMedia/ia/BC-esRana.png" id="fig:BC-esRana" style="width:12cm" alt="Proceso de encadenamiento hacia atrás del objetivo esVerde(Fritz)." /><figcaption aria-hidden="true">Proceso de encadenamiento hacia atrás del objetivo esVerde(Fritz).</figcaption>
</figure>
<p><strong>Mecanismo de resolución SLD</strong></p>
<p>Para realizar un encadenamiento hacia atrás podemos utilizar el mecanismo de resolución SLD (Selective Linear Definite clause resolution). Para explicar cómo funciona este mecanismo primero hay que entender la función de selección <span class="math inline">\(\varphi\)</span>, esta función dado un objetivo Q devuelve uno y solo uno de los átomos de Q.</p>
<p>Ejemplo:</p>
<p>Q = <span class="math inline">\(A_1\)</span> <span class="math inline">\(\Lambda\)</span> <span class="math inline">\(A_2\)</span> <span class="math inline">\(\Lambda\)</span> <span class="math inline">\(A_j\)</span> <span class="math inline">\(\Lambda\)</span>...<span class="math inline">\(\Lambda\)</span> <span class="math inline">\(A_n\)</span><br />
<span class="math inline">\(\varphi\)</span>(Q) = <span class="math inline">\(A_j\)</span></p>
<p><strong>Funcionamiento del mecanismo de resolución SLD</strong></p>
<p>En este caso la función de selección devolverá el primer átomo del objetivo. Dado un objetivo Q de la forma <span class="math inline">\(A_1\)</span> <span class="math inline">\(\Lambda\)</span> <span class="math inline">\(A_2\)</span> <span class="math inline">\(\Lambda\)</span> <span class="math inline">\(A_j\)</span> <span class="math inline">\(\Lambda\)</span>...<span class="math inline">\(\Lambda\)</span> <span class="math inline">\(A_n\)</span>. se buscará la primera sentencia C del programa <span class="math inline">\(B_1\)</span> <span class="math inline">\(\Lambda\)</span> ... <span class="math inline">\(\Lambda\)</span> <span class="math inline">\(B_m\)</span> → H tal que <span class="math inline">\(\varphi\)</span>(Q) = A y H sean unificables por un umg <span class="math inline">\(\theta\)</span>. Entonces la nueva pregunta <span class="math inline">\(Q^{&#39;}\)</span> (el resolvente) será igual a la sustitución Sust( (<span class="math inline">\(B_1\)</span> <span class="math inline">\(\Lambda\)</span> ... <span class="math inline">\(\Lambda\)</span> <span class="math inline">\(B_m\)</span> <span class="math inline">\(\Lambda\)</span> <span class="math inline">\(A_2\)</span> <span class="math inline">\(\Lambda\)</span> ... <span class="math inline">\(\Lambda\)</span> <span class="math inline">\(A_n\)</span>), <span class="math inline">\(\theta\)</span>). El proceso continuará de igual forma hasta obtener la pregunta vacía (lo que corresponde a un éxito, se obtiene una pregunta vacía si existe un umg <span class="math inline">\(\theta\)</span> tal que Sust(Q,<span class="math inline">\(\theta\)</span>)=Sust(C,<span class="math inline">\(\theta\)</span>)), o una pregunta para la cual no exista resolvente con ninguna sentencia del programa (lo que corresponderá a un fracaso) <span class="citation" data-cites="navarro_prolog"></span>.</p>
<p>Vamos a explorar este proceso separándolo en pasos:</p>
<ol>
<li><p>Se tiene un objetivo Q de la forma <span class="math inline">\(A_1\)</span> <span class="math inline">\(\Lambda\)</span> <span class="math inline">\(A_2\)</span> <span class="math inline">\(\Lambda\)</span> <span class="math inline">\(A_j\)</span> <span class="math inline">\(\Lambda\)</span>...<span class="math inline">\(\Lambda\)</span> <span class="math inline">\(A_n\)</span></p></li>
<li><p>Se selecciona un átomo A del objetivo Q, A = <span class="math inline">\(\varphi\)</span>(Q)</p></li>
<li><p>Se busca la primera sentencia C de la forma <span class="math inline">\(B_1\)</span> <span class="math inline">\(\Lambda\)</span> ... <span class="math inline">\(\Lambda\)</span> <span class="math inline">\(B_m\)</span> → H tal que A y H sean unificables por un umg <span class="math inline">\(\theta\)</span>.</p></li>
<li><p>Se obtiene el nuevo resolvente (también llamado derivación ya que <span class="math inline">\(Q^{&#39;}\)</span> deriva de Q), <span class="math inline">\(Q^{&#39;}\)</span> = Sust( (<span class="math inline">\(B_1\)</span> <span class="math inline">\(\Lambda\)</span> ... <span class="math inline">\(\Lambda\)</span> <span class="math inline">\(B_m\)</span> <span class="math inline">\(\Lambda\)</span> <span class="math inline">\(A_2\)</span> <span class="math inline">\(\Lambda\)</span> ... <span class="math inline">\(\Lambda\)</span> <span class="math inline">\(A_n\)</span>), <span class="math inline">\(\theta\)</span>) En este paso cuando la sentencia C es un hecho solo se tendría la cabeza H de la cláusula por lo cual <span class="math inline">\(Q^{&#39;}\)</span> sería igual a <span class="math inline">\(Q^{&#39;}\)</span> = Sust( (<span class="math inline">\(A_2\)</span> <span class="math inline">\(\Lambda\)</span> ... <span class="math inline">\(\Lambda\)</span> <span class="math inline">\(A_n\)</span>), <span class="math inline">\(\theta\)</span>)</p></li>
</ol>
<p>Este proceso se repite siendo <span class="math inline">\(Q^{&#39;}\)</span> el nuevo objetivo hasta que se cumpla una de las siguientes condiciones:</p>
<ul>
<li><p>En el paso 3 no se encontró ninguna sentencia que permita generar un nuevo resolvente, por lo cual la resolución fracaso.</p></li>
<li><p>Tras el paso 4 <span class="math inline">\(Q^{&#39;}\)</span> es igual a una pregunta vacía, lo que corresponde a un éxito.</p></li>
</ul>
<strong>Sistemas expertos</strong>
<p>Los sistemas expertos son sistemas basados en conocimiento diseñados para realizar tareas que normalmente requerirán un experto. Estos sistemas son usados para resolver problemas de dominio específico y se comportan como un sistema asesor en la toma de decisiones <span class="citation" data-cites="tms_ES"></span>.</p>
<p>El desarrollo de los sistemas expertos empezó alrededor del año 1965 con un proyecto de Edward Feigenbaum, a quien se le atribuye el título de padre de los sistemas expertos), el desarrollo de estos sistemas continuó durante las siguientes décadas, donde fueron utilizados tanto en la industria como académicamente. Su auge fue durante el boom de la inteligencia artificial (1980–1987), en la actualidad la popularidad de los sistemas expertos ha decaído y si bien existen sistemas expertos implementados en diversas aplicaciones la opinión popular parece indicar que fallaron en cumplir las expectativas esperadas <span class="citation" data-cites="leph_ES"></span>.</p>
<p><strong>Componentes de los sistemas expertos</strong></p>
<p>A continuación se describen los principales componentes de un sistema experto <span class="citation" data-cites="tms_ES"></span>:</p>
<ul>
<li><p><u>Interfaz de usuario:</u> Es el mecanismo mediante el cual el usuario final va a interactuar con el sistema experto.</p></li>
<li><p><u>Base de conocimiento:</u> Contiene todo el conocimiento adquirido del experto a manera de reglas y hechos.</p></li>
<li><p><u>Motor de inferencia:</u> Es el mecanismo que se encarga de realizar la inferencia manipulando las reglas y hechos de la base de conocimiento.</p></li>
<li><p><u>Subsistema de explicación o justificación:</u> Este módulo o subsistema es el encargado de explicar el razonamiento mediante el cual el sistema experto llegó a una conclusión.</p></li>
<li><p><u>Subsistema de adquisición de conocimiento:</u> Este módulo o subsistema permite al usuario añadir nuevo conocimiento sin la necesidad de que un ingeniero o personal especializado se vea involucrado en este proceso. Algunos sistemas expertos cuentan con un módulo de aprendizaje que les permite adaptarse de acuerdo a la información que reciben.</p></li>
</ul>
<figure>
<img src="pandocConversionMedia/ia/SistemaExperto.png" id="fig:SistemaExperto" style="width:12cm" alt="Representación gráfica de los componentes de un sistema experto." /><figcaption aria-hidden="true">Representación gráfica de los componentes de un sistema experto.</figcaption>
</figure>
<p><strong>Desarrollo de un sistema experto</strong></p>
<p>Para el desarrollo de un sistema experto se tiene que realizar la extracción del conocimiento para posteriormente desarrollar el sistema. A continuación se presentan algunos pasos sugeridos que se pueden seguir durante el desarrollo:</p>
<ol>
<li><p><u>Identificación del problema:</u> Es muy importante saber qué problema pretende resolver nuestro sistema experto y los objetivos que van a utilizar nuestros usuarios finales. También en esta fase el desarrollador debe realizar una investigación sobre el dominio del problema con el fin de tratar de adquirir conocimiento general sobre el problema o situación a resolver. Posteriormente se debe obtener información de expertos mediante técnicas como la entrevista (es importante la investigación previa para realizar preguntas puntuales).</p></li>
<li><p><u>Conceptualización del conocimiento:</u> En esta fase se debe representar el conocimiento mediante técnicas como los marcos, redes semánticas, etc. Existen libros sobre la ingeniería del conocimiento que repasan este tipo de técnicas. En esta sección se recomienda mantener la comunicación con el experto para que nos indique si nuestras representaciones son adecuadas y coinciden con su conocimiento.</p></li>
<li><p><u>Formalización del conocimiento:</u> El conocimiento se va a representar mediante un modelo formal, es importante tomar en cuenta como va a funcionar nuestro modelo de inferencia, lo más probable es que tengamos que representar nuestro conocimiento mediante el uso de cláusulas de Horn.</p></li>
<li><p><u>Implementación del sistema experto:</u> En esta fase se desarrollará el sistema experto y se realizará la programación necesaria, se pueden usar herramientas existentes para facilitar el desarrollo.</p></li>
<li><p><u>Validación y mantenimiento del sistema:</u> Se debe validar que las respuestas del sistema experto y de los expertos coincidan de manera consistente.</p></li>
</ol>
<p><strong>Uso del lenguaje de programación prolog</strong></p>
<p>PROLOG es un lenguaje declarativo de programación lógica diseñado para representar y utilizar el conocimiento que se tiene sobre un determinado dominio.</p>
<p><strong>¿Qué es un lenguaje declarativo?</strong></p>
<p>Existen dos estilos principales en los lenguajes de programación, imperativos y declarativos. Los programas en los lenguajes imperativos constan de instrucciones que nos permiten modificar el estado de un programa mediante la modificación de variables, básicamente se describe el proceso de cómo hacer algo; ejemplos de estos lenguajes son Java, C++, PHP. En los programas de los lenguajes declarativos se describe qué se quiere hacer pero no se especifica el cómo; PROLOG es un ejemplo de este tipo de lenguajes.</p>
<p><strong>Sintaxis de la base de conocimientos</strong></p>
<p>En un programa de prolog se pueden guardar reglas y hechos, estas reglas y hechos deben ser cláusulas de Horn, a continuación se describe la sintaxis: Los objetos tienen que iniciar con minúscula y las variables con mayúscula.</p>
<p><u>Sintaxis de una regla en prolog</u></p>
<p>Cabeza :- Cuerpo.</p>
<p>Las cláusulas del cuerpo pueden estás separadas por “,” que representa una conjunción o “;” que representa una disyunción.</p>
<p>Ejemplo:</p>
<p>haceCroac(x)<span class="math inline">\(\Lambda\)</span>comeMoscas(x)→esRana(x)</p>
<p>Esta regla se representaría de la siguiente manera en prolog:</p>
<p>esRana(X) :- haceCroac(X),comeMoscas(X).</p>
<p><u>Sintaxis de un hecho en prolog</u></p>
<p>Cabeza.</p>
<p>Ejemplo:</p>
<p>haceCroac(Fritz)</p>
<p>Este hecho se representaría de la siguiente manera en prolog:</p>
<p>haceCroac(fritz).</p>
<p><strong>Objetivos en prolog</strong></p>
<p>Una vez tenemos descrita nuestra base de conocimientos podemos realizar “preguntas” mediante los objetivos. Para preguntar ¿es fritz verde? construiríamos el objetivo en prolog “esVerde(fritz).”, también podemos hacer uso de variables para preguntar ¿Quién es verde? construyendo el objetivo de la siguiente manera “esVerde(X).”.</p>
<p><strong>Inferencia en prolog</strong></p>
<p>Prolog utiliza como método de inferencia el mecanismo de resolución SLD descrito anteriormente en este libro.</p>
<p><strong>Ejercicio de programación:</strong></p>
<p>Realizar el desarrollo de un sistema experto del tema que el lector prefiera y usando cualquier lenguaje de programación. Yo recomiendo utilizar un lenguaje de programación como prolog para no tener que realizar la programación del motor de inferencia.</p>
<p><img src="pandocConversionMedia/Pictures/github/sisema-experto.png" style="width:5cm" alt="image" /></p>
<p>(<a href="https://github.com/amr205/animals-prolog">https://github.com/amr205/animals-prolog</a>)</p>
<h1 data-number="4" id="parte-cuatro-machine-learning"><span class="header-section-number">4</span> Parte cuatro: Machine Learning</h1>
<h2 data-number="4.1" id="introducción-al-capítulo"><span class="header-section-number">4.1</span> Introducción al capítulo</h2>
<strong>Definición</strong>
<p>El machine learning o aprendizaje automático es una disciplina del campo de la inteligencia artificial que pretende generar sistemas capaces de aprender a través de la “experiencia”. El problema de aprendizaje puede ser descrito de la siguiente manera: Un programa se dice que aprende a través de la experiencia <span class="math inline">\(E\)</span> con respecto a un tipo de tareas <span class="math inline">\(T\)</span> y una medición de su desempeño <span class="math inline">\(P\)</span>, si su desempeño en las tareas <span class="math inline">\(T\)</span>, medidas por <span class="math inline">\(P\)</span>, mejora a través de la experiencia E <span class="citation" data-cites="mitchell1997machine"></span>.</p>
<p>Esta definición puede ser muy formal sin embargo describe un problema general sobre el cual se puede aplicar machine learning. Dicho de forma más simple en el aprendizaje automático no se desarrolla de manera explicita la lógica que nos permite ir de unos datos de entrada a un resultado, en cambio se proporcionan datos de entrada junto con los resultados que esperamos aprender y los usamos para entrenar un algoritmo de aprendizaje, este algoritmo genera un "programa" que nos permite predecir el resultado a partir de nuevos datos de entrada.</p>
<figure>
<img src="pandocConversionMedia/ia/whatisml.png" id="fig:whatisml" style="width:12cm" alt="Comparación entre la programación tradicional y el aprendizaje automático." /><figcaption aria-hidden="true">Comparación entre la programación tradicional y el aprendizaje automático.</figcaption>
</figure>
<strong>Clasificación</strong>
<p>Existen tres tipos de algoritmos principales dependiendo del tipo de aprendizaje que realizan, a continuación se describen de manera breve:</p>
<ul>
<li><p><strong>Aprendizaje supervisado:</strong> Se aprende a través de ejemplos que se encuentran previamente clasificados o emparejados con un valor, un ejemplo puede ser un clasificador de imágenes que debe aprender a distinguir entre perros y gatos que para el proceso de aprendizaje requerirá de un conjunto de imágenes asociadas a la clase correcta.</p></li>
<li><p><strong>Aprendizaje no supervisado:</strong> Este tipo de algoritmos aprenden a través de ejemplos sin clasificar y tienen que aprender patrones que les permitan organizarlos de alguna manera, un ejemplo podría el siguiente: una tienda de ropa necesita elegir las medidas que tendrán sus prendas de ropa para las tallas chica, mediana y grande, con el objetivo de lograr esto se recopilan las medidas de la gente que vive cerca de la tienda y se utiliza un algoritmo de machine learning que le indica cuales serían las medidas adecuadas (más adelante en este libro veremos que clase de algoritmo podría ser útil para esta tarea).</p></li>
<li><p><strong>Aprendizaje semi-supervisado:</strong> En este tipo de algoritmo nuestro set de entrenamiento contiene ejemplos clasificados y no clasificados, la mayoría de los ejemplos no suelen estar clasificados, aunque usar ejemplos sin clasificar pueda parecer contra-intuitivo estos añaden información sobre el problema lo que puede resultar en un mejor modelo.</p></li>
<li><p><strong>Aprendizaje reforzado:</strong> Este tipo de algoritmos aprenden a través de la experiencia, interactúan con su entorno y reciben recompensas que les indican si las acciones realizadas han sido correctas o no.</p></li>
</ul>
<strong>Problemas que resuelve</strong>
<p>Los algoritmos de machine learning nos permiten resolver principalmente problemas de clasificación,regresión, asociación y agrupamiento, a continuación se describe su significado <span class="citation" data-cites="burkov2019hundred"></span>:</p>
<ul>
<li><p><strong>Clasificación:</strong> este problema consiste en asignar una etiqueta a un ejemplo sin clasificar, uno de los ejemplos más famosos es la detección de spam.</p></li>
<li><p><strong>Regresión:</strong> este problema consiste en predecir un valor dado un ejemplo sin etiquetar, por ejemplo otorgar las características de una casa y predecir su costo.</p></li>
<li><p><strong>Agrupación (Clustering):</strong> Consiste en agrupar los datos de tal forma que los elementos de estos grupos sean similares, esto puede ser útil por ejemplo para segmentar nuestros clientes según su forma de comprar.</p></li>
<li><p><strong>Asociación:</strong> Consiste en relacionar instancias de nuestro set de entrenamiento con características similares, por ejemplo encontrar la noticia más similar a la que acaba de leer el usuario.</p></li>
</ul>
<figure>
<img src="pandocConversionMedia/ia/mltasks.png" id="fig:mltasks" style="width:14cm" alt="Clasificación del aprendizaje automático y los tipos de problemas o tareas que pueden solucionar." /><figcaption aria-hidden="true">Clasificación del aprendizaje automático y los tipos de problemas o tareas que pueden solucionar.</figcaption>
</figure>
<p><strong>¿En este libro ya utilizamos machine learning?</strong></p>
<p>Si, en el tema Sistemas clasificadores (Learning classifier system) realizamos algoritmos de machine learning y precisamente vimos como uno de ellos pertenece a la categoría de aprendizaje supervisado y el otro a la categoría de aprendizaje reforzado.</p>
<strong>Importancia del machine learning</strong>
<p>Este tipo de algoritmos nos permiten resolver tareas que de otra manera serían prácticamente imposibles, por poner un ejemplo simple, sin el uso de este tipo de algoritmos cómo sería posible crear un algoritmo al cual le dieras una imagen y la clasificara como un perro o un gato.</p>
<p>Hoy en día el machine learning ha sido aplicado en una variedad de ámbitos de manera exitosa, a continuación se listan algunos de ellos:</p>
<ul>
<li><p>Procesamiento del lenguaje natural</p></li>
<li><p>Computer vision (Procesamiento de imágenes)</p></li>
<li><p>Evaluación de clientes</p></li>
<li><p>Sistemas de recomendación</p></li>
<li><p>Sistemas de detección de anomalías</p></li>
<li><p>Reconocimiento de genes en secuencias de ADN</p></li>
<li><p>Etc.</p></li>
</ul>
<p>El paradigma simbólico visto en el capítulo anterior tiene el problema de que el aprendizaje no se adquiere directamente del entorno o a través de ejemplos, por lo cual hay dominios muy complejos de modelar o al ser vaciado el conocimiento se corre el riesgo de perder detalles importantes del modelo, el machine learning hoy en día presenta una gran oportunidad debido a que la cantidad de datos e información generada en estos últimos años hacen posible el uso de estos algoritmos para la resolución de problemas complejos.</p>
<h2 data-number="4.2" id="aprendizaje-supervisado"><span class="header-section-number">4.2</span> Aprendizaje supervisado</h2>
<strong>Introducción al capítulo</strong>
<p>En este capítulo se revisarán diversos algoritmos de machine learning que utilizan aprendizaje supervisado, antes de revisar distintos algoritmos que realizan la tarea de clasificación o regresión vamos a observar algunas generalidades presentes en este tipo de aprendizaje.</p>
<p>El proceso suele iniciar con la recolección de los datos. Estos datos van a conformar nuestro conjunto de datos (dataset), consisten de una serie de pares de datos (entrada, salida). Los valores de entrada pueden ser cualquier cosa, correos, imágenes, etc. Los valores de salida pueden ser etiquetas que correspondan a una clase (perros, gatos, etc), valores numéricos (precio, probabilidad, etc), o secuencia de datos <span class="citation" data-cites="burkov2019hundred"></span>.</p>
<p>Para poder procesar los datos la entrada suele estar compuesta de un vector de atributos (feature vector ó attribute vector), por ejemplo si cada elemento de nuestro conjunto de datos esta compuesto de color, anchura y altura, nuestro vector de atributos debería representar adecuadamente esto, algunos algoritmos requieren que nuestros vectores estén compuestos de datos númericos, por lo cual para el ejemplo anterior se podría descomponer el atributo de colos en tres atributos que serían el valor de la intensidad del color en el canal rojo, azul y verde. El vector de atributos de una instancia con color azul, anchura de 3 metros y altura de 15 sería el siguiente: [ 0,0,1,3,15 ], al número de atributos de nuestro vector se le conoce como dimensionalidad, en este ejemplo simple se tiene una dimensionalidad de 6.</p>
<p>Es deber del analista de datos determinar cómo convertir una entidad del mundo real a un vector de atributos y como transformar o extraer las características relevantes del problema. Un ejemplo más complejo sería el convertir un correo electrónico, esta tarea la dejaré para más adelante ya que será uno de los ejercicios a realizar en temas posteriores.</p>
<p>Los tipos de atributos que puede contener nuestro conjunto de datos son los siguientes:</p>
<ul>
<li><p><strong>Datos numéricos:</strong> Estos tipo de datos pueden ser números continuos (Que pueden tomar cualquier valor dentro de un rango) o discretos (Solo pueden tomar ciertos valores dentro de un rango), los datos numéricos continuos suelen ser usados en medidas como la altura, el peso, etc y los datos numéricos discretos en aquellas cosas que deben ser contabilizadas como el número de hijos, número de ocurrencias de un evento, etc.</p></li>
<li><p><strong>Datos ordinales:</strong> Son aquellos datos en los que existen variables en categorías ordenadas, la distancia entre dos categorías no se establece en este tipo de datos, por ejemplo si tuviéramos el atributo “calidad del servicio” este campo podría tomar los siguientes valores { “malo”, “regular”, “bueno”, “excelente” } y se da por entendido que el valor “malo” es más cercano a “regular” que a “excelente”.</p></li>
<li><p><strong>Datos categóricos:</strong> Son aquellos datos en los que existen variables en categorías no ordenadas, por ejemplo el color de un auto { “rojo”, “azul”, “amarillo”, “verde”}.</p></li>
</ul>
<p>En el aprendizaje automático también se suelen usar como datos el texto que suele estar compuesto de una serie de palabras, o las secuencias temporales que contienen datos asociados a un valor temporal como fecha, hora o fecha y hora.</p>
<p>Nuestro conjunto de datos suele estar dividido en otros subconjuntos, al inicio de este capítulo usaremos solamente el set de entrenamiento pero más adelante veremos cómo utilizar los otros, a continuación se describen los principales subconjuntos:</p>
<ul>
<li><p><strong>Set de entrenamiento (training set):</strong> Estos elementos que ya poseen clasificación son aquellos que nos servirán para entrenar a nuestro algoritmo.</p></li>
<li><p><strong>Set de prueba (test set):</strong> Con estos elementos se probará el desempeño de nuestro algoritmo, usando instancias que nuestro algoritmo no observó durante el entrenamiento.</p></li>
<li><p><strong>Set de validación (validation set):</strong> Este conjunto se utiliza para ajustar parámetros del algoritmo para obtener un mejor resultado, dependiendo del algoritmo existen diferentes hiperparametros <a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> a optimizar y también existen diferentes técnicas para usar este conjunto.</p></li>
</ul>
<p>Usando nuestro conjunto de datos, aplicaremos un <strong>algoritmo de aprendizaje</strong>, existen dos divisiones principales de estos algoritmos:</p>
<ul>
<li><p><strong>Algoritmos de aprendizaje paramétricos:</strong> Estos algoritmos optimizan una función de una forma determinada, por ende hacen suposiciones acerca de la forma de la función de la cual provienen los datos, para optimizar esta función se aprenden los valores de los parámetros a través del proceso de aprendizaje. Ejemplos de parámetros son los pesos en las redes neuronales, los coeficientes en regresión lineal o los vectores de soporte en una máquina de soporte de vectores.</p></li>
<li><p><strong>Algoritmos de aprendizaje no paramétricos:</strong> Estos algoritmos no hacen suposiciones acerca de la forma que tiene la función de la cual provienen los datos, por lo cual carecen de parámetros que se estiman a partir de los datos de entrada.</p></li>
</ul>
<p>Los algoritmos de aprendizaje no paramétricos tienen la ventaja de que al no hacer suposiciones sobre la forma de la función es posible obtener muy buenos modelos, sin embargo tienen la desventaja de tener un proceso de aprendizaje y predicción generalmente mayor en comparación a los algoritmos de aprendizaje paramétricos, además de usualmente requerir mayor cantidad de datos de entrenamiento para dar buenos resultados.</p>
<p>Los algoritmos de aprendizaje paramétricos suelen estar compuestos de lo siguiente <span class="citation" data-cites="burkov2019hundred"></span>:</p>
<ul>
<li><p><strong>Una función de pérdida (loss function):</strong> Nos permite medir la diferencia entre el resultado obtenido por el algoritmo de aprendizaje y el valor de salida real de una sola instancia.</p></li>
<li><p><strong>Un criterio de optimización (optimization criteria):</strong> El criterio mediante el cual se va medir la efectividad del modelo, este criterio está basado en la función de pérdida, un ejemplo podría ser <strong>una función de coste o error (cost function)</strong>, esta función mide el error del algoritmo de aprendizaje a través de todas las instancias, suele ser el promedio del valor obtenido al aplicar la función de pérdida sobre cada instancia.</p></li>
<li><p><strong>Una rutina de optimización (optimization routine):</strong> Este es el proceso mediante el cual se va a manejar la información para encontrar una solución al criterio de optimización.</p></li>
</ul>
<p>El resultado de aplicar el algoritmo de aprendizaje sobre un conjunto de datos es un <strong>modelo</strong>, este modelo nos permitirá realizar predicciones sobre los nuevos elementos no asociados a una información de salida.</p>
<p>En la especialización de machine learning realizado por la Universidad de Washington en la plataforma de Coursera se presenta una imagen similar a la siguiente que muestra los elementos descritos anteriormente.</p>
<figure>
<img src="pandocConversionMedia/ia/Aprendizaje supervisado diagrama.png" id="fig:Aprendizaje-supervisado-diagrama" style="width:14cm" alt="Diagrama representando un problema de aprendizaje supervisado, donde se tiene un set de entrenamiento con datos de entrada X y datos de salida Y, se entrena un modelo con parámetros W para generar predicciones Ŷ" /><figcaption aria-hidden="true">Diagrama representando un problema de aprendizaje supervisado, donde se tiene un set de entrenamiento con datos de entrada X y datos de salida Y, se entrena un modelo con parámetros W para generar predicciones Ŷ</figcaption>
</figure>
<p>Se invita al lector a identificar los elementos aquí descritos en el tema UCS (LCS con aprendizaje supervisado) de este libro.</p>
<p>Antes de explorar algunos de los diferentes algoritmos de aprendizaje vamos a revisar una rutina de optimización que nos permitirá aprender los parametros <span class="math inline">\(W\)</span> de nuestros modelos. Es por esto que se motiva al lector entender claramente las partes y procesos que forman parte del aprendizaje supervisado presente en la figura <a href="#fig:Aprendizaje-supervisado-diagrama" data-reference-type="ref" data-reference="fig:Aprendizaje-supervisado-diagrama">2.1</a>.</p>
<strong>Descenso del gradiente</strong>
<p>En esta sección examinaremos el funcionamiento básico de la rutina de optimización llamada descenso del gradiente, esta rutina tiene diversas variantes y algunas implementaciones más complejas que pretenden mejorarla sin embargo en este capitulo nos centraremos en la más simple.</p>
<p><strong>¿Porqué este tema se encuentra en esta sección del libro?</strong></p>
<p>Al inicio puede parecer un poco contra intuitivo el revisar este tema antes de ver algún algoritmo de aprendizaje de regresión o clasificación, sin embargo esta rutina es utilizada por diversos algoritmos y es ampliamente usada actualmente, por lo cuál considero importante que el lector entienda su funcionamiento de manera general para posteriormente ver su implementación específica en los temas posteriores. Otra razón para colocar esta información aquí es la posibilidad de encontrarlo fácilmente en el índice por si se requiere repasar el funcionamiento de esta rutina de optimización.</p>
<p><strong>¿Qué es el descenso del gradiente?</strong></p>
<p>El descenso del gradiente es una manera de minimizar una función objetivo (referido como criterio de optimización en la introducción del capítulo) J(<span class="math inline">\(\theta\)</span>) donde los parámetros del modelo <span class="math inline">\(\theta \in \mathbb{R}^{d}\)</span> son ajustados de manera iterativa en la dirección contraria al gradiente de la función objetivo respecto a los parámetros <span class="math inline">\(\nabla _{\theta} J(\theta)\)</span> <span class="citation" data-cites="ruder2017overview"></span>.</p>
<p>Esta definición formal es bastante adecuada una vez se entienden los conceptos que se están utilizando, sin embargo puede carecer de sentido antes de entender lo que esta realizando conceptualmente, por ello a continuación vamos a revisar los diferentes elementos descritos.</p>
<p><u>Función objetivo <span class="math inline">\(J(\theta)\)</span></u></p>
<p>La función objetivo como fue descrito en la introducción del capítulo mide la efectividad de nuestro modelo usando generalmente una función de coste o error, mientras menor sea el valor quiere decir que el desempeño de nuestro algoritmo de aprendizaje es mejor. Por intuición sabemos que hay una combinación de valores en nuestros parámetros <span class="math inline">\(\theta\)</span> que minimizan esta función objetivo.</p>
<p>Para simplificar el problema y para poder mostrar de manera gráfica esta situación en la figura <a href="#fig:cost_function_min" data-reference-type="ref" data-reference="fig:cost_function_min">2.2</a> se puede observar que existe un valor para <span class="math inline">\(\theta_1\)</span> que minimiza la función <span class="math inline">\(J(\theta)\)</span>.</p>
<figure>
<img src="pandocConversionMedia/ia/cost_function_min.png" id="fig:cost_function_min" style="width:6cm" alt="Representación visual de la función J(\theta), en esta figura el valor mínimo de J(\theta) se encuentra señalado con un punto rojo" /><figcaption aria-hidden="true">Representación visual de la función <span class="math inline">\(J(\theta)\)</span>, en esta figura el valor mínimo de <span class="math inline">\(J(\theta)\)</span> se encuentra señalado con un punto rojo</figcaption>
</figure>
<p><u>Gradiente <span class="math inline">\(\nabla _{\theta} J(\theta)\)</span></u></p>
<p>Cuando nosotros empezamos el entrenamiento iniciamos con valores aleatorios de <span class="math inline">\(\theta\)</span> por lo cual nuestro objetivo es lograr encontrar los valores <span class="math inline">\(\theta\)</span> que optimizen la función <span class="math inline">\(J(\theta)\)</span>, entonces nuestra pregunta es ¿Cómo pasar de nuestro valor inicial al valor óptimo?.</p>
<figure>
<img src="pandocConversionMedia/ia/cost_function_min_init.png" id="fig:cost_function_min_init" style="width:9cm" alt="Representación visual de la función J(\theta), en esta figura el valor mínimo de J(\theta) se encuentra señalado con un punto rojo y el valor inicial se encuentra marcado con el punto verde" /><figcaption aria-hidden="true">Representación visual de la función <span class="math inline">\(J(\theta)\)</span>, en esta figura el valor mínimo de <span class="math inline">\(J(\theta)\)</span> se encuentra señalado con un punto rojo y el valor inicial se encuentra marcado con el punto verde</figcaption>
</figure>
<p>En el caso presentado en la figura <a href="#fig:cost_function_min_init" data-reference-type="ref" data-reference="fig:cost_function_min_init">2.3</a> solo tenemos un parámetro <span class="math inline">\(\theta\)</span> por lo cual mediante el uso de una derivada podemos obtener la pendiente e ir en la dirección contraria para irnos acercando al valor de <span class="math inline">\(\theta\)</span> que minimize <span class="math inline">\(J(\theta)\)</span>.</p>
<p>Recordemos que podemos entender una derivada <span class="math inline">\(dy/dx\)</span> de una función <span class="math inline">\(y=f(x)\)</span> como una razón de cambio respecto a la variable x (visualizada como una tangente en el punto que se deriva, o la pendiente de la función en un punto determinado), entonces de esta manera al calcular la derivada de <span class="math inline">\(J(\theta)\)</span> respecto a <span class="math inline">\(\theta\)</span> podemos obtener la dirección hacia la cual debemos llevar nuestro valor <span class="math inline">\(\theta\)</span> para minimizar la función.</p>
<figure>
<img src="pandocConversionMedia/ia/cost_function_der.png" id="fig:cost_function_der" style="width:7cm" alt="Representación visual de la función J(\theta), en esta figura el valor mínimo de J(\theta) se encuentra señalado con un punto rojo y el valor inicial se encuentra marcado con el punto verde y la recta tangente a la función J(\theta) se encuentra dibujada con color negro." /><figcaption aria-hidden="true">Representación visual de la función <span class="math inline">\(J(\theta)\)</span>, en esta figura el valor mínimo de <span class="math inline">\(J(\theta)\)</span> se encuentra señalado con un punto rojo y el valor inicial se encuentra marcado con el punto verde y la recta tangente a la función <span class="math inline">\(J(\theta)\)</span> se encuentra dibujada con color negro.</figcaption>
</figure>
<p>¿Qué hacemos si tenemos más de un parámetro?</p>
<p>La respuesta es relativamente sencilla, el objetivo es obtener el gradiente, el gradiente es una generalización multivariable de la derivada. Mientras que una derivada se puede definir solo en funciones de una sola variable, para funciones de varias variables, el gradiente toma su lugar. El gradiente es una función de valor vectorial, a diferencia de una derivada, que es una función de valor escalar. De esta manera al obtener el gradiente sabremos en que dirección actualizar cada uno de nuestros parámetros.</p>
<p>El cálculo del gradiente dependerá del algoritmo de aprendizaje que se este utilizando por lo cual en este momento no veremos ningún ejemplo en específico.</p>
<p><u>Descenso del gradiente</u></p>
<p>Ahora que sabemos que es el gradiente y porqué queremos obtenerlo, el descenso del gradiente tiene mucho más sentido.</p>
<p>Esta rutina de optimización en su forma más básica (Descenso del gradiente por lotes o Batch Gradient Descent) consiste en calcular el gradiente de la función objetivo <span class="math inline">\(J(\theta)\)</span> respecto a los parámetros <span class="math inline">\(\theta\)</span> a través de todo el set de entrenamiento para de manera iterativa ajustar los parámetros del algoritmo de aprendizaje de acuerdo a la siguiente fórmula:</p>
<p><span class="math display">\[\label{eqn:gradient_descent}
\theta = \theta - \alpha \cdot  \nabla _{\theta} J(\theta)\]</span></p>
<p>Donde:</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">controla que tan grande es la actualización de los parámetros.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
<p>Es importante no usar valores muy grandes de <span class="math inline">\(\alpha\)</span> ya que podríamos no llegar a ningún mínimo local, sin embargo valores muy bajos de <span class="math inline">\(\alpha\)</span> harán que tardemos mucho en llegar al mínimo. Más adelante dentro del tema de machine learning se verán algunas técnicas para ajustar los parámetros de nuestros algoritmos de aprendizaje. Para finalizar este tema me gustaría mostrar la siguiente imagen sacada del curso de Machine Learning en Coursera impartido por Andrew Ng.</p>
<figure>
<img src="pandocConversionMedia/ia/gd_andrewng.png" id="fig:cost_function_der_two_params" style="width:9cm" alt="Descenso del gradiente con dos parámetros \theta_0 y \theta_1" /><figcaption aria-hidden="true">Descenso del gradiente con dos parámetros <span class="math inline">\(\theta_0\)</span> y <span class="math inline">\(\theta_1\)</span></figcaption>
</figure>
<p><strong>Variaciones del descenso del gradiente</strong></p>
<p>A continuación se listan distintas variaciones de esta rutina de optimización para que al momento de estar aplicando este tipo de algoritmos en la vida real cuando el lector se encuentre con dichas variaciones tenga un lugar para consultar sus diferencias, así como revisar sus ventajas y desventajas. Si es tu primera vez leyendo este libro recomiendo continuar con la siguiente sección y volver al terminar el cápitulo.</p>
<ul>
<li><p><strong>Batch gradient descent</strong>: Versión básica de esta rutina de optimización, se utilizan todos los elementos del conjunto de datos para calcular el gradiente. <span class="math display">\[\label{eqn:batch_gradient_descent}
\theta = \theta - \alpha \cdot  \nabla _{\theta} J(\theta)\]</span></p></li>
<li><p><strong>Stochastic Gradient Descent (SGD):</strong>: En esta variante del descenso del gradiente se actualiza el valor de los parametros calculando el gradiente para cada uno de los elementos en el conjunto de datos. <span class="math display">\[\label{eqn:stochastic_gradient_descent}
\theta = \theta - \alpha \cdot  \nabla _{\theta} J_{i}(\theta)\]</span> Donde:</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;">elemento del conjunto de datos seleccionado al azar.</td>
</tr>
</tbody>
</table>
<p><u>Ventajas:</u> Ayuda a lograr una convergencia más rápida cuando el conjunto de datos es muy grande.</p>
<p><u>Desventajas:</u> Debido a las altas variaciones en cada actualización de valores en los parámetros es posible que no converja en un optimo global .<br />
</p></li>
<li><p><strong>Mini-batch Gradient Descent:</strong>: En esta variante del descenso del gradiente se actualiza el valor de los parametros calculando el gradiente en un subconjunto aleatorio de tamaño m del conjunto de datos. <span class="math display">\[\label{eqn:mini_batch_gradient_descent}
\theta = \theta - \alpha \cdot   \frac{1}{m} \sum_{i=1}^{n}  \nabla _{\theta} J_{i}(\theta)\]</span> <u>Ventajas:</u> Otorga un balance entre costo computacional y velocidad, puede ser utilizado en conjuntos de datos grandes.</p>
<p><u>Desventajas:</u> Es necesario elegir el valor de <span class="math inline">\(m\)</span> para el subconjunto de datos.<br />
</p></li>
<li><p><strong>Momentum Gradient Descent:</strong>: En esta variante se añade “momento” a la actualización de los parámetros. <span class="math display">\[\label{eqn:momentum_gradient_descent}
\begin{split}
v_{t} &amp;= \gamma v_{t-1} + \alpha \cdot  \nabla _{\theta} J(\theta_{t-1})
\\
\theta_{t} &amp;= \theta_{t-1} - v_{t+2}
\end{split}\]</span> Donde:</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left;"></td>
</tr>
<tr class="odd">
<td style="text-align: left;">vector de velocidad anterior.</td>
</tr>
</tbody>
</table>
<p><u>Ventajas:</u> En funciones con mucho ruido o curvatura ayuda a evitar que se converja en un óptimo local.</p>
<p><u>Desventajas:</u> Si el valor de <span class="math inline">\(\gamma\)</span> es grande el vector de parámetros puede oscilar alrededor del valor óptimo (local o global).<br />
</p></li>
<li><p><strong>Adagrad</strong>: En esta variante el valor de la tasa de aprendizaja se adapta para cada parametro basado en el valor historico del gradiente. Parametros con un valor grande en el gradiente tienen una tasa de aprendizaje reducida, aquellos con un valor pequeño en el gradiente tienen una tasa de aprendizaje aumentada.</p>
<p><u>Ventajas:</u> En funciones con parametros en diferentes escalas ayuda a acelerar la convergencia en un valor optimo.</p>
<p><u>Desventajas:</u> Debido a que reduce la tasa de aprendizaje con valores grandes en el historico del gradiente, el aprendizaje puede llegar a detenerse antes antes de converger en un óptimo<br />
</p></li>
<li><p><strong>RMSProp</strong>: Al igual que en Adagrad el valor de la tasa de aprendizaja se adapta, sin embargo en lugar de usar el valor historico del gradiente, usa una ventana en movimiento del promedio del cuadrado de los gradientes</p>
<p><u>Ventajas:</u> En funciones con parametros en diferentes escalas ayuda a acelerar la convergencia en un valor optimo.</p>
<p><u>Desventajas:</u> Debido a que reduce la tasa de aprendizaje con valores grandes en el historico del gradiente, el aprendizaje puede llegar a detenerse antes antes de converger en un óptimo. Es necesario encontrar un valor óptimo para los hiperparámetros.<br />
</p></li>
<li><p><strong>Adam</strong>: Combina las ideas de Adagrad y RMSProp de una manera eficiente.</p>
<p><u>Ventajas:</u> Tiene buenos resultados en un amplio rango de problemas donde se usen redes neuronales. El valor por defecto de los hiperparámetros suele funcionar adecuadamente.</p>
<p><u>Desventajas:</u> Es necesario encontrar un valor óptimo para los hiperparámetros.<br />
</p></li>
</ul>
<p>Es fácil entender la necesidad de variantes como SGD o Mini-Batch, ya que en conjuntos de datos grandes no es realisticamente posible usar la versión básica del descenso del gradiente. Intuitivamente podemos comprender que al introducir momento en la rutina de optimización evitamos quedarnos atascados en un óptimo local. Es más complicado obtener la intuición de las razones por las cuales variantes como Adagrad y RMSProp son útiles para acelerar la convergencia en un valor óptimo, yo recomiendo ver los primeros minutos de la siguiente lección para entender conceptualmente sus beneficios.</p>
<p><a href="https://www.youtube.com/watch?v=_e-LFe_igno&amp;t=392s&amp;ab_channel=DeepLearningAI">RMS Prop (C2W2L07)</a></p>
<p>En la práctica se suele utilizar Adam u otras variantes modernas debido a que suelen comportarse bien en un amplio rango de problemas.</p>
<strong>Regresión</strong>
<p><strong>Regresión lineal</strong> <strong>Suposiciones del algoritmo</strong></p>
<p>Este algoritmo de aprendizaje paramétrico supone que hay una relación lineal entre las características <span class="math inline">\(X\)</span> que describen una instancia y una variable <span class="math inline">\(Y\)</span> que se quiere predecir.</p>
<p><strong>Descripción del modelo</strong></p>
<p>La regresión lineal es un modelo matemático usado para aproximar la relación de dependencia entre una variable dependiente <span class="math inline">\(Y\)</span> y las variables independientes <span class="math inline">\(X\)</span>. Este modelo puede ser expresado como:</p>
<p><span class="math display">\[\label{eqn:linear_regression}
\hat{Y}  = \beta _1 x_1 + \beta _2 x_2 + ... + \beta _n x_n + \beta _0\]</span></p>
<p>Donde:</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\hat{Y}\)</span> es la predicción que produce el modelo.</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(x_1,x_2,...,x_n\)</span> son las variables independientes.</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\beta _0,\beta _1,...,\beta _n\)</span> son los parámetros de nuestro modelo</td>
</tr>
</tbody>
</table>
<p>Si consideramos que solo tenemos una variable independiente <span class="math inline">\(x_1\)</span> nuestro modelo tendría la siguiente forma:</p>
<p><span class="math display">\[\hat{Y}  = \beta _1 x_1 + \beta _0\]</span></p>
<p>Este modelo simple es la ecuación de la recta, es decir <span class="math inline">\(\hat{Y}  = \beta _1 x_1 + \beta _0\)</span> es lo mismo que <span class="math inline">\(y = mx + b\)</span>. Si se tienen 2 variables independientes se utilizaría un plano para la regresión, siempre se trata de modelar un hiperplano <a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a>, cuando solo se tiene una variable independiente al modelo se le conoce como regresión lineal simple, en caso de tener dos o más variables se le conoce como regresión lineal múltiple.</p>
<figure>
<img src="pandocConversionMedia/ia/Linear regression.png" id="fig:LinearRegression" style="width:8.3cm" alt="Ejemplo de una regresión lineal con una variable dependiente y una variable independiente." /><figcaption aria-hidden="true">Ejemplo de una regresión lineal con una variable dependiente y una variable independiente.</figcaption>
</figure>
<p>La fórmula <a href="#eqn:linear_regression" data-reference-type="ref" data-reference="eqn:linear_regression">[eqn:linear_regression]</a> puede ser vectorizada de la siguiente manera, asumiendo que:</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(X_0 = 1\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">Los atributos de nuestros datos de entrada se encuentran en una matriz X de dimensión (m x n)</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Las etiquetas de nuestros datos de entrada se encuentran en una matriz Y de dimensión (m x 1)</td>
</tr>
<tr class="even">
<td style="text-align: left;">Los parámetros de nuestro modelo se encuentran en una matriz <span class="math inline">\(\beta\)</span> de dimensión (n x 1)</td>
</tr>
</tbody>
</table>
<p>Donde m es el número de instancias y n el número de atributos o características más uno (se suma uno por <span class="math inline">\(X_0\)</span>)</p>
<p><span class="math display">\[X=\begin{bmatrix}
         X_{0}^{1} &amp;   X_{1}^{1} &amp; ...  &amp;   X_{n}^{1} \\
         X_{0}^{2} &amp;   X_{1}^{2} &amp; ...  &amp;   X_{n}^{2} \\
         ... &amp;   ... &amp; ...  &amp;   ... \\
         X_{0}^{m} &amp;   X_{1}^{m} &amp; ...  &amp;   X_{n}^{m} 
     \end{bmatrix}\]</span></p>
<p><span class="math display">\[Y=\begin{bmatrix}
         Y^{1}\\
         Y^{2}\\
         ...\\
         Y^{m}
        \end{bmatrix}\]</span></p>
<p><span class="math display">\[\beta=\begin{bmatrix}
         \beta_{0}\\
         \beta_{1}\\
         ...\\
         \beta_{n}
        \end{bmatrix}\]</span></p>
<p><span class="math display">\[\label{eqn:linear_regression_vec}
\hat{Y}  = X \beta\]</span></p>
<p><strong>Solución mediante la forma cerrada</strong></p>
<p>Dada la ecuación <a href="#eqn:linear_regression_vec" data-reference-type="ref" data-reference="eqn:linear_regression_vec">[eqn:linear_regression_vec]</a> se pueden calcular los parámetros <span class="math inline">\(\beta\)</span> de la siguiente forma:</p>
<p><span class="math display">\[\label{eqn:linear_regression_closed_form_solution}
\beta = (X&#39; X)^{-1}X&#39;Y\]</span></p>
<p>Donde:</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(X&#39;\)</span> es la matriz transpuesta de <span class="math inline">\(X\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\((X&#39; X)^{-1}\)</span> es la matriz inversa de <span class="math inline">\((X&#39; X)\)</span></td>
</tr>
</tbody>
</table>
<p>Esta es una manera simple de obtener el valor de los parámetros del modelo, sin embargo no escala bien cuando utilizamos grandes cantidades de datos, es por eso que generalmente se suele utilizar el descenso del gradiente para el entrenamiento del modelo.</p>
<p><strong>Solución mediante descenso del gradiente</strong></p>
<p>Como se describió en la ecuación <a href="#eqn:gradient_descent" data-reference-type="ref" data-reference="eqn:gradient_descent">[eqn:gradient_descent]</a> mediante el descenso del gradiente podemos actualizar el valor de los parámetros para optimizar una función de coste. Como función de coste vamos a utilizar el Error cuadrático medio (Mean Squared error - MSE), esta función tiene la siguiente forma:</p>
<p><span class="math display">\[\label{eqn:mean_squared_error}
J(\beta)=\frac{1}{n} \sum_{i=1}^{n}\left (Y - \hat{Y}  \right )^{2}\]</span></p>
<p>Vamos a modificar un poco la ecuación con el fin de que al calcular el gradiente resulte una ecuación más sencilla, la ecuación quedaría de la siguiente manera:</p>
<p><span class="math display">\[\label{eqn:mean_squared_error_modified}
J(\beta)=\frac{1}{2n} \sum_{i=1}^{n}\left (\hat{Y} - Y  \right )^{2}\]</span></p>
<p>El gradiente de la ecuación <a href="#eqn:mean_squared_error_modified" data-reference-type="ref" data-reference="eqn:mean_squared_error_modified">[eqn:mean_squared_error_modified]</a> es el siguiente: (Su cálculo queda fuera del alcance de este libro)</p>
<p><span class="math display">\[\label{eqn:gradient_mean_squared_error_modified}
\nabla _{\beta} J(\beta) =  \frac{1}{n} \left ( X&#39; (\hat{Y}-Y ) \right )\]</span></p>
<p>Por ende la actualización de los parámetros quedaría de la siguiente forma:</p>
<p><span class="math display">\[\label{eqn:linear_regression_gradient_descent}
\theta = \theta - \alpha \cdot \frac{1}{n} \left ( X&#39; (\hat{Y}-Y ) \right )\]</span></p>
<p><strong>Ejercicio de programación:</strong></p>
<p>Ejercicio para fortalecer los conocimientos adquiridos:</p>
<ol>
<li><p>En un lenguaje de programación matemático como Octave, Julia o Matlab resolver un problema de regresión lineal implementando la solución de forma cerrada.</p></li>
<li><p>En un lenguaje de programación matemático como Octave, Julia o Matlab resolver un problema de regresión lineal implementando la solución mediante el descenso del gradiente.</p></li>
<li><p>En cualquier lenguaje de programación utilizar alguna librería como scikit-learn para resolver un problema de regresión lineal.</p></li>
</ol>
<p>A continuación se presenta un link a las soluciones en caso de que el lector lo requiera:</p>
<p><img src="pandocConversionMedia/Pictures/github/libro-ia.png" style="width:6cm" alt="image" /></p>
<p><a href="https://github.com/amr205/Introduccion-a-la-IA---Libro">https://github.com/amr205/Introduccion-a-la-IA---Libro</a></p>
<strong>Regresión polinomial</strong>
<p>En regresión polinomial se ajusta un modelo no lineal entre las variables independientes <span class="math inline">\(X\)</span> y la variable dependiente <span class="math inline">\(y\)</span>, a pesar de esto todos los parámetros de este modelo son lineales y la regresión polinomial puede considerarse un caso especial de regresión lineal múltiple.</p>
<figure>
<img src="pandocConversionMedia/ia/reg_poli.png" id="fig:LinearRegressionPoli" style="width:8.3cm" alt="Ejemplo de una un modelo de regresión polinomial de grado 3" /><figcaption aria-hidden="true">Ejemplo de una un modelo de regresión polinomial de grado 3</figcaption>
</figure>
<p>En la figura <a href="#fig:Aprendizaje-supervisado-diagrama" data-reference-type="ref" data-reference="fig:Aprendizaje-supervisado-diagrama">2.1</a> se puede observar como nuestras variables de entrada <span class="math inline">\(X\)</span> pasan por un proceso de extracción de características para obtener <span class="math inline">\(h(X)\)</span>, en el tema anterior <span class="math inline">\(X = h(X)\)</span>, en regresión polinomial cada variable <span class="math inline">\(x_j^i\)</span> generaremos características elevando esta variable hasta la <span class="math inline">\(k\)</span> potencia. De tal forma que:</p>
<p><span class="math display">\[X=\begin{bmatrix}
         X_{0}^{1} &amp;   X_{1}^{1} &amp; ...  &amp;   X_{n}^{1} \\
         X_{0}^{2} &amp;   X_{1}^{2} &amp; ...  &amp;   X_{n}^{2} \\
         ... &amp;   ... &amp; ...  &amp;   ... \\
         X_{0}^{m} &amp;   X_{1}^{m} &amp; ...  &amp;   X_{n}^{m} 
     \end{bmatrix}\]</span></p>
<p><span class="math display">\[h(X)=\begin{bmatrix}
         X_{0}^{1} &amp;   X_{1}^{1} &amp; ...  &amp;   X_{n}^{1}  &amp; (X_{1}^{1})^2 &amp; ...  &amp; (X_{n}^{1})^2 &amp; ... &amp; (X_{1}^{1})^k  &amp; ... &amp; (X_{n}^{1})^k\\
         X_{0}^{2} &amp;   X_{1}^{2} &amp; ...  &amp;   X_{n}^{2}  &amp; (X_{1}^{2})^2 &amp; ...  &amp; (X_{n}^{2})^2 &amp; ... &amp; (X_{1}^{2})^k  &amp; ... &amp; (X_{n}^{2})^k\\
         ... &amp; ... &amp; ... &amp; ... &amp; ... &amp; ...  &amp;  ... &amp; ... &amp; ... &amp; ... &amp; ...\\
         X_{0}^{m} &amp;   X_{1}^{m} &amp; ...  &amp;   X_{n}^{m} &amp; (X_{1}^{m})^2 &amp; ...  &amp; (X_{n}^{m})^2 &amp; ... &amp; (X_{1}^{m})^k  &amp; ... &amp; (X_{n}^{m})^k
     \end{bmatrix}\]</span></p>
<p>Hay que considerar que por la vectorización de nuestro modelo, <span class="math inline">\(X_0\)</span> = 1. Por poner un ejemplo el siguiente modelo lineal:</p>
<p><span class="math display">\[\label{eqn:linear_regression_mod1}
\hat{Y}  = \beta _1 x_1 + \beta _2 x_2 + \beta _0\]</span></p>
<p>Con <span class="math inline">\(k=3\)</span> sería de la siguiente forma:</p>
<p><span class="math display">\[\label{eqn:linear_regression_mod2}
\hat{Y}  = \beta _1 x_1 + \beta _2 x_2 + \beta _3 (x_1)^2 + \beta _4 (x_2)^2 + \beta _5 (x_1)^3 + \beta _6 (x_2)^3 +\beta _0\]</span></p>
<p>Nuestro modelo quedaría descrito de la siguiente forma: <span class="math display">\[\label{eqn:linear_regression_vec_mod3}
\hat{Y}  = h(X) \beta\]</span></p>
<p>Y todos los métodos para obtener los parámetros del modelo descritos en el tema de regresión lineal pueden ser aplicados reemplazando <span class="math inline">\(X\)</span> por <span class="math inline">\(h(X)\)</span>.</p>
<p><strong>Modelado de estacionalidad</strong></p>
<p>Mediante la generación de características derivadas de nuestras variables independientes es posible modelar diferentes patrones presentes en los datos, un ejemplo de ello es modelar estacionalidad, si una variable de entrada <span class="math inline">\(x\)</span> presenta este patrón la estacionalidad puede modelarse de la siguiente manera:</p>
<p><span class="math inline">\(w_1*sin(2\pi x/ periodo) + w_2*cos(2\pi x/ periodo)\)</span></p>
<div class="center">
<p>(1,0)<span>420</span></p>
</div>
<p><strong>Ejercicio de programación:</strong></p>
<p>Ejercicio para fortalecer los conocimientos adquiridos:</p>
<ol>
<li><p>En un lenguaje de programación matemático como Octave, Julia o Matlab resolver un problema de regresión polinomial.</p></li>
<li><p>En cualquier lenguaje de programación utilizar alguna librería como scikit-learn para resolver un problema de regresión polinomial.</p></li>
</ol>
<p>A continuación se presenta un link a las soluciones en caso de que el lector lo requiera:</p>
<p><img src="pandocConversionMedia/Pictures/github/libro-ia.png" style="width:5cm" alt="image" /></p>
<p><a href="https://github.com/amr205/Introduccion-a-la-IA---Libro">https://github.com/amr205/Introduccion-a-la-IA---Libro</a></p>
<strong>Regresión mediante K-Nearest Neighbors</span> <span id="subsection:knn" label="subsection:knn">[subsection:knn]</strong>
<p>El algoritmo de K-Nearest Neighbors (K-Vecinos más cercanos) es una técnica no paramétrica <a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> que puede ser utilizada para resolver tareas de regresión y clasificación <span class="citation" data-cites="knn_intro"></span>, en este tema se explorará su uso en el área de regresión.</p>
<p><strong>Suposiciones del algoritmo</strong></p>
<p>Dado a que es un algoritmo de aprendizaje no paramétrico no se realizan fuertes suposiciones sobre la forma que tiene la curva de regresión, de manera intuitiva se puede entender que este algoritmo asume que el valor de la variable dependiente <span class="math inline">\(Y\)</span> en una instancia toma valores similares a aquellos valores de las <span class="math inline">\(n\)</span> instancias más cercanas de acuerdo a una distancia calculada a partir de las características <span class="math inline">\(X\)</span>.</p>
<p><strong>Funcionamiento del algoritmo de K-NN</strong></p>
<p>Tendremos los siguientes elementos:</p>
<ul>
<li><p>Un set de entrenamiento compuesto de las características <span class="math inline">\(X\)</span> y el vector columna <span class="math inline">\(Y\)</span> que contiene la variable dependiente que queremos predecir asociado a cada instancia en <span class="math inline">\(X\)</span>.</p></li>
<li><p>Una nueva instancia <span class="math inline">\(b\)</span> a clasificar.</p></li>
<li><p>El hiperparámetro <span class="math inline">\(k\)</span> que determina el número de vecinos a seleccionar.</p></li>
</ul>
<p>El algoritmo es el siguiente:</p>
<ol>
<li><p>Calcular la distancia entre la nueva instancia <span class="math inline">\(b\)</span> y cada una de las instancias en <span class="math inline">\(X\)</span>.</p></li>
<li><p>Seleccionar los <span class="math inline">\(k\)</span> elementos presentes en <span class="math inline">\(X\)</span> más cercanos a <span class="math inline">\(b\)</span>.</p></li>
<li><p>Devolver un resultado basado en el valor presente en <span class="math inline">\(Y\)</span> de los <span class="math inline">\(k\)</span> elementos más cercanos.</p></li>
</ol>
<p>Es un algoritmo bastante simple, vamos a explorar cada uno de estos pasos de manera más detallada para que después de leer este tema el lector sea capaz de realizar la implementación del algoritmo.</p>
<p><u>1. Calcular la distancia entre <span class="math inline">\(b\)</span> y las demás instancias en <span class="math inline">\(X\)</span></u></p>
<p>Existen diferentes funciones para calcular la distancia entre vectores con valores continuos, algunas de las más comunes son las siguientes:</p>
<p>Distancia euclidiana o euclídea <span class="math display">\[\label{eqn:distancia_euclidiana}
d(x_i,y_i) = \sqrt{\sum_{i=1}^{k}\left (  x_i - y_i \right )^{2}}\]</span></p>
<p>Distancia Manhattan <span class="math display">\[\label{eqn:distancia_manhattan}
d(x_i,y_i) = \sum_{i=1}^{k}  \left | x_i - y_i  \right |\]</span></p>
<p>Distancia Minkowski <span class="math display">\[\label{eqn:distancia_Minkowski}
d(x_i,y_i) = \left ( \sum_{i=1}^{k}  \left ( \left | x_i - y_i  \right | \right )^q \right )^{1/q}\]</span></p>
<p>Para vectores con datos categóricos se tiene que usar la distancia Hamming, la distancia Hamming entre dos vectores es igual al número de posiciones donde los elementos correspondientes en los vectores son diferentes.</p>
<p>Distancia Hamming <span class="math display">\[\label{eqn:distancia_Hamming}
d(x_i,y_i) = \sum_{i=1}^{k} h(x_i,y_i)\]</span> <span class="math display">\[h(x_i,y_i)= 
\begin{dcases}
    0,&amp; \text{si } x_i = y_i\\
    1,&amp; \text{si } x_i \neq  y_i
\end{dcases}\]</span></p>
<p><u>2. Seleccionar los <span class="math inline">\(k\)</span> elementos presentes en <span class="math inline">\(X\)</span> más cercanos a <span class="math inline">\(b\)</span>.</u></p>
<p>Para esto se puede hacer uso de una cola de prioridad de <span class="math inline">\(k\)</span> elementos, añadiendo cada elemento al calcular la distancia. Otra opción es primero calcular todas las distancias y posteriormente ordenarla para seleccionar los primeros <span class="math inline">\(k\)</span> elementos.</p>
<p><u>3. Devolver un resultado basado en el valor presente en <span class="math inline">\(Y\)</span> de los <span class="math inline">\(k\)</span> elementos más cercanos.</u></p>
<p>Hay diferentes opciones para calcular el valor que se va a devolver:</p>
<ul>
<li><p><strong>Promedio:</strong> Simplemente se regresa el promedio de los valores en <span class="math inline">\(Y\)</span> de los <span class="math inline">\(k\)</span> elementos más cercanos. <span class="math display">\[\hat{Y}_b = \frac{1}{k} \sum_{i=1}^{k} Y_{NNi}\]</span> Donde <span class="math inline">\(Y_{NNi}\)</span> corresponde al valor de Y del vecino más cercano <span class="math inline">\(i\)</span>.<br />
</p></li>
<li><p><strong>Vecinos más cercanos con distancia ponderada (weighted knn):</strong> El valor devuelto se calcula tomando en cuenta la distancia los vecinos más cercanos a <span class="math inline">\(b\)</span>, mientras más cercano sea, su valor en <span class="math inline">\(Y\)</span> tendrá mayor contribución al valor devuelto.</p>
<p>La fórmula general para calcular el valor sería la siguiente:</p>
<p><span class="math display">\[\hat{Y}_b=\frac{\sum_{i=1}^{k} C_{bNNi}*Y_{NNi}}{\sum_{i=1}^{k} C_{bNNi}}\]</span> Donde <span class="math inline">\(Y_{NNi}\)</span> corresponde al valor de Y del vecino más cercano <span class="math inline">\(i\)</span>.<br />
Donde <span class="math inline">\(C_{bNNi}\)</span> corresponde al valor de la contribución que el vecino más cercano <span class="math inline">\(i\)</span> aportará al calculo del valor que se quiere predecir de <span class="math inline">\(b\)</span>.<br />
Para calcular el valor de <span class="math inline">\(C_{bNNi}\)</span> se utilizan diversas funciones (también llamadas kernels) que toman en cuenta la distancia entre el vecino más cercano <span class="math inline">\(i\)</span> y la instancia <span class="math inline">\(b\)</span> para determinar el nivel de contribución. Algunas de estas funciones son las siguientes (<span class="math inline">\(\lambda\)</span> es un hiper-parámetro utilizado para determinar que tan rápido decae la contribución respecto a la distancia):<br />
Distancia ponderada simple: <span class="math display">\[C_{bNNi}=\frac{1}{d(X_b,X_{NNi})^2}\]</span></p>
<p>Kernel gaussiano: <span class="math display">\[C_{bNNi}=exp( -d(X_b,X_{NNi})^2 / \lambda)\]</span></p>
<p>Kernel uniforme: <span class="math display">\[C_{bNNi} = 
\begin{dcases}
    0,&amp; \text{si } |d(X_b,X_{NNi})| &gt; \lambda\\
    1/2,&amp; \text{si } |d(X_b,X_{NNi})| \leq  \lambda
\end{dcases}\]</span></p>
<p>Kernel triangular: <span class="math display">\[C_{bNNi} = 
\begin{dcases}
    0,&amp; \text{si } |d(X_b,X_{NNi})| &gt; \lambda\\
    (\lambda - |d(X_b,X_{NNi})|) ,&amp; \text{si } |d(X_b,X_{NNi})| \leq  \lambda
\end{dcases}\]</span></p>
<p>Kernel Epanechnikov: <span class="math display">\[C_{bNNi} = 
\begin{dcases}
    0,&amp; \text{si } |d(X_b,X_{NNi})| &gt; \lambda\\
    \frac{3}{4}(\lambda^2 - d(X_b,X_{NNi})^2) ,&amp; \text{si } |d(X_b,X_{NNi})| \leq  \lambda
\end{dcases}\]</span></p>
<figure>
<img src="pandocConversionMedia/ia/kernels.png" id="fig:kernels_knn" style="width:9.5cm" alt="Diferentes kernels con \lambda= 1 por Brian Amberg licencia CC BY-SA 3.0" /><figcaption aria-hidden="true">Diferentes kernels con <span class="math inline">\(\lambda= 1\)</span> por Brian Amberg licencia CC BY-SA 3.0</figcaption>
</figure></li>
</ul>
<p><strong>Ejemplo de solución de un problema</strong></p>
<p>Se busca predecir el precio de una casa con 4 recámaras, 2 baños y 5 años de antigüedad, se disponen de los siguientes datos:</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">4</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">224,000</td>
</tr>
<tr class="even">
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">113,000</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">144,000</td>
</tr>
<tr class="even">
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">212,000</td>
</tr>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">92,000</td>
</tr>
<tr class="even">
<td style="text-align: left;">5</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">260,000</td>
</tr>
<tr class="odd">
<td style="text-align: left;">5</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">300,000</td>
</tr>
<tr class="even">
<td style="text-align: left;">3</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">175,000</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">224,000</td>
</tr>
<tr class="even">
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">194,000</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">178,000</td>
</tr>
</tbody>
</table>
<p>Se aplicará el algoritmo de KNN con <span class="math inline">\(k=5\)</span>.<br />
El primer paso es calcular la distancia, para este ejemplo se usará la distancia euclidiana:</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">4</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">224,000</td>
<td style="text-align: left;">3.1623</td>
</tr>
<tr class="even">
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">113,000</td>
<td style="text-align: left;">4.4721</td>
</tr>
<tr class="odd">
<td style="text-align: left;">2</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">144,000</td>
<td style="text-align: left;">2.4495</td>
</tr>
<tr class="even">
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">212,000</td>
<td style="text-align: left;">1.0000</td>
</tr>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">3</td>
<td style="text-align: left;">92,000</td>
<td style="text-align: left;">3.7417</td>
</tr>
<tr class="even">
<td style="text-align: left;">5</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">260,000</td>
<td style="text-align: left;">1.4142</td>
</tr>
<tr class="odd">
<td style="text-align: left;">5</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">300,000</td>
<td style="text-align: left;">1.4142</td>
</tr>
<tr class="even">
<td style="text-align: left;">3</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">175,000</td>
<td style="text-align: left;">3.7417</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">6</td>
<td style="text-align: left;">224,000</td>
<td style="text-align: left;">1.4142</td>
</tr>
<tr class="even">
<td style="text-align: left;">2</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">8</td>
<td style="text-align: left;">194,000</td>
<td style="text-align: left;">3.6056</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3</td>
<td style="text-align: left;">4</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">178,000</td>
<td style="text-align: left;">3.7417</td>
</tr>
</tbody>
</table>
<p>Debido a que <span class="math inline">\(k=2\)</span> se seleccionarán los dos vecinos más cercanos, en este caso se seleccionaron los vecinos 4 y 6.</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">3</td>
<td style="text-align: left;">2</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">212,000</td>
<td style="text-align: left;">1.0000</td>
</tr>
<tr class="even">
<td style="text-align: left;">5</td>
<td style="text-align: left;">1</td>
<td style="text-align: left;">5</td>
<td style="text-align: left;">260,000</td>
<td style="text-align: left;">1.4142</td>
</tr>
</tbody>
</table>
<p>En este caso se devolverá el promedio de los precios, dando como resultado: 236,000.</p>
<div class="center">
<p>(1,0)<span>420</span></p>
</div>
<p><strong>Ejercicio de programación:</strong></p>
<ol>
<li><p>En un lenguaje de programación matemático como Octave, Julia o Matlab resolver un problema de regresión mediante knn.</p></li>
<li><p>En cualquier lenguaje de programación utilizar alguna librería como scikit-learn para resolver un problema de regresión mediante knn.</p></li>
</ol>
<p>A continuación se presenta un link a las soluciones en caso de que el lector lo requiera:</p>
<p><img src="pandocConversionMedia/Pictures/github/libro-ia.png" style="width:5cm" alt="image" /></p>
<p><a href="https://github.com/amr205/Introduccion-a-la-IA---Libro">https://github.com/amr205/Introduccion-a-la-IA---Libro</a></p>
<strong>Kernel Regression</strong>
<p>Kernel Regression es otra técnica para regresión no parámetrica muy similar a vecinos más cercanos con distancia ponderada, la principal diferencia es que no se eligen un <span class="math inline">\(k\)</span> número de vecinos sino todos aquellos en los cuales <span class="math inline">\(|d(v,b)|\leq \lambda\)</span>, donde <span class="math inline">\(b\)</span> es la instancia que queremos predecir, <span class="math inline">\(v\)</span> es una instancia cualquiera y <span class="math inline">\(\lambda\)</span> es un hiperparámetro que limita la distancia máxima a considerar para el algoritmo.</p>
<p><strong>Suposiciones del algoritmo</strong></p>
<p>No hace fuertes suposiciones acerca de la curva de regresión, es muy similar al algoritmo de aprendizaje de KNN, sin embargo aqui se consideran los vecinos que se encuentren a menos de cierta distancia.</p>
<p><strong>Funcionamiento del algoritmo Kernel Regression</strong></p>
<p>Tendremos los siguientes elementos:</p>
<ul>
<li><p>Un set de entrenamiento compuesto de las características <span class="math inline">\(X\)</span> y el vector columna <span class="math inline">\(Y\)</span> que contiene la variable dependiente que queremos predecir asociado a cada instancia en <span class="math inline">\(X\)</span>.</p></li>
<li><p>Una nueva instancia <span class="math inline">\(b\)</span> a clasificar.</p></li>
<li><p>El hiperparámetro <span class="math inline">\(\lambda\)</span> que determina la distancia máxima que debe tener un vecino cualquiera <span class="math inline">\(v\)</span> respecto a <span class="math inline">\(b\)</span> para ser considerado.</p></li>
</ul>
<p>El algoritmo es el siguiente:</p>
<ol>
<li><p>Calcular la distancia entre la nueva instancia <span class="math inline">\(b\)</span> y cada una de las instancias en <span class="math inline">\(X\)</span>.</p></li>
<li><p>Seleccionar los elementos <span class="math inline">\(V\)</span> presentes en <span class="math inline">\(X\)</span> dado que <span class="math inline">\(|d(v,b)|\leq \lambda\)</span>.</p></li>
<li><p>Devolver un resultado basado en el valor presente en <span class="math inline">\(Y\)</span> de los elementos presentes en <span class="math inline">\(V\)</span>.</p></li>
</ol>
<p><u>1. Calcular la distancia entre la nueva instancia <span class="math inline">\(b\)</span> y cada una de las instancias en <span class="math inline">\(X\)</span>.</u></p>
<p>Se pueden utilizar cualquiera de las funciones para calcular distancias descritas en el tema anterior ( <a href="#subsection:knn" data-reference-type="ref" data-reference="subsection:knn">[subsection:knn]</a>).</p>
<p><u>2 y 3. Seleccionar los elementos <span class="math inline">\(V\)</span> y devolver un resultado basado en su valor presente en <span class="math inline">\(Y\)</span></u></p>
<p>Se podría aplicar la siguiente fórmula: <span class="math display">\[\hat{Y}_b=\frac{\sum_{i=1}^{n} C_{bNNi}*Y_{NNi}}{\sum_{i=1}^{n} C_{bNNi}}\]</span> Donde <span class="math inline">\(Y_{NNi}\)</span> corresponde al valor de Y de la instancia <span class="math inline">\(i\)</span>.<br />
Donde <span class="math inline">\(C_{bNNi}\)</span> corresponde al valor de la contribución que la instancia <span class="math inline">\(i\)</span> aportará al calculo del valor que se quiere predecir de <span class="math inline">\(b\)</span>.<br />
Donde <span class="math inline">\(n\)</span> corresponde al número de instancias en <span class="math inline">\(X\)</span>.</p>
<p>Esto puede hacerse de esta manera si los kernels devuelven 0 cuando <span class="math inline">\(|d(X_i,b)| &gt; \lambda\)</span>. Para aquellos kernels que no lo hagan puede agregarse una condición (en este libro los kernels que no tienen la condición ya implementada son el kernel gaussiano y distancia ponderada simple).</p>
<p><strong>Elección de kernel y <span class="math inline">\(\lambda\)</span></strong></p>
<p>Más adelante en este libro se explorarán técnicas para la selección de hiperparámetros, por ahora considero útil que el lector observe los efectos del uso de diferentes kernels con diferentes valores de <span class="math inline">\(\lambda\)</span>.</p>
<figure>
<img src="pandocConversionMedia/ia/kr_lambda.png" id="fig:kernel_regression_epanechikov" style="width:15cm" alt="Kernel regression con kernel Epanechnikov y diferentes valores de lambda, azul-señal, verde-predicción, imagen tomada de Fox, Emily y Guestrin, Carlos (2015). Machine Learning: Regression [MOOC]. Coursera. https://www.coursera.org/learn/ml-regression/" /><figcaption aria-hidden="true">Kernel regression con kernel Epanechnikov y diferentes valores de lambda, azul-señal, verde-predicción, imagen tomada de Fox, Emily y Guestrin, Carlos (2015). Machine Learning: Regression [MOOC]. Coursera. <a href="https://www.coursera.org/learn/ml-regression/">https://www.coursera.org/learn/ml-regression/</a></figcaption>
</figure>
<figure>
<img src="pandocConversionMedia/ia/kr_kernel.png" id="fig:kernel_regression_diff_kernels" style="width:14cm" alt="Kernel regression con diferentes kernels, izquierda-uniforme, derecha-Epanechnikov, imagen tomada de Fox, Emily y Guestrin, Carlos (2015). Machine Learning: Regression [MOOC]. Coursera. https://www.coursera.org/learn/ml-regression/" /><figcaption aria-hidden="true">Kernel regression con diferentes kernels, izquierda-uniforme, derecha-Epanechnikov, imagen tomada de Fox, Emily y Guestrin, Carlos (2015). Machine Learning: Regression [MOOC]. Coursera. <a href="https://www.coursera.org/learn/ml-regression/">https://www.coursera.org/learn/ml-regression/</a></figcaption>
</figure>
<div class="center">
<p>(1,0)<span>420</span></p>
</div>
<p><strong>Ejercicio de programación:</strong></p>
<p>En un lenguaje de programación matemático como Octave, Julia o Matlab resolver un problema de regresión mediante kernel regression.</p>
<p>A continuación se presenta un link a las soluciones en caso de que el lector lo requiera:</p>
<p><img src="pandocConversionMedia/Pictures/github/libro-ia.png" style="width:3cm" alt="image" /></p>
<p><a href="https://github.com/amr205/Introduccion-a-la-IA---Libro">https://github.com/amr205/Introduccion-a-la-IA---Libro</a></p>
<strong>Clasificación</strong>
<strong>Tipos de clasificación</strong>
<p>Existen diferentes tipos de tareas de clasificación y cada algoritmo puede tratar con una o varias de estas tareas, es importante conocer las distintas tareas de clasificación para ser capaces de identificar el algoritmo adecuado para solucionar nuestro problema.</p>
<p><strong>Clasificación binaria</strong></p>
<p>Este tipo de tarea de clasificación contiene solo dos clases, y cada instancia puede pertenecer solo a una de estas dos clases, por ejemplo si entrenáramos un modelo para reconocer osos tendríamos dos clases: “oso” y “no oso”.</p>
<figure>
<img src="pandocConversionMedia/ia/clasificacion_binaria.png" id="fig:clasificacion_binaria" style="width:14cm" alt="Ejemplo de clasificación binaria con frutas" /><figcaption aria-hidden="true">Ejemplo de clasificación binaria con frutas</figcaption>
</figure>
<p><strong>Clasificación multi-clase</strong></p>
<p>Este tipo de tarea de clasificación puede tener n-clases, sin embargo cada instancia solo puede pertenecer a una de estas n-clases, por ejemplo si entrenáramos un modelo para clasificar frutas tendríamos algunas de las siguientes clases: { “manzana”, “pera”, “naranja”, “platano”, etc } pero una instancia no puede ser manzana y pera al mismo tiempo.</p>
<figure>
<img src="pandocConversionMedia/ia/clasificacion_multiclase.png" id="fig:clasificacion_multiclase" style="width:14cm" alt="Ejemplo de clasificación multi-clase con frutas" /><figcaption aria-hidden="true">Ejemplo de clasificación multi-clase con frutas</figcaption>
</figure>
<p><strong>Clasificación multi-etiqueta</strong></p>
<p>Este tipo de tarea de clasificación puede tener n-clases, y cada instancia tiene asociada una o más clases, por ejemplo si tuviéramos que identificar las frutas presentes en una imagen, algunas tendrían peras y manzanas, otras quizás solo manzanas, etc.</p>
<figure>
<img src="pandocConversionMedia/ia/clasificacion_multietiqueta.png" id="fig:clasificacion_multietiqueta" style="width:13.5cm" alt="Ejemplo de clasificación multi-etiqueta con frutas" /><figcaption aria-hidden="true">Ejemplo de clasificación multi-etiqueta con frutas</figcaption>
</figure>
<p><strong>Clasificación con datos no balanceados</strong></p>
<p>En este tipo de tarea las instancias en cada clases no están distribuidas de manera equitativa, por ejemplo en sistemas de detección de anomalías y sistemas de detección de fraude se tienen muchos ejemplos de situaciones e instancias “normales” y solo unas cuantas “anormales”. Este tipo de tarea suele ser tratada con algoritmos distintos o variaciones de los algoritmos originales, ya que si por ejemplo tenemos 990 instancias con comportamiento normal y solo 10 con comportamiento anormal si nuestro clasificador siempre dice que todo esta bien tendríamos un valor de exactitud del 99% lo cual en otras circunstancias sería algo muy bueno, sin embargo en la clasificación con datos no balanceados este valor tan alto de exactitud no significa que nuestro modelo tenga un buen desempeño o generalice adecuadamente.</p>
<strong>Regresión logística</strong>
<p>La regresión logística simple soluciona problemas de clasificación binaria, este modelo nos sirve para predecir la probabilidad de que una instancia pertenezca a una clase o no.</p>
<p><strong>Suposiciones del algoritmo</strong></p>
<p>Este algoritmo de aprendizaje hace la suposición de que hay una relación lineal entre los atributos <span class="math inline">\(X\)</span> de las instancias y el logaritmo natural de la razón de posibilidades <a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>.</p>
<p><strong>Deducción del modelo (opcional)</strong></p>
<p>Esta sección del tema esta marcada como opcional debido a que no es necesaria entenderla para poder aplicar el algoritmo y saber como realiza la clasificación, sin embargo considero que es muy interesante como a partir de la suposición presentada anteriormente se construye el modelo.</p>
<p><u>¿Por qué no hacemos una suposición más simple?</u></p>
<p>¿Por qué no suponer una relación lineal entre las características <span class="math inline">\(X\)</span> y la probabilidad <span class="math inline">\(p\)</span> de que una instancia pertenezca a una clase?, esto podría parecer la solución más obvia, sin embargo nos encontramos con el problema de que si tenemos clasificados nuestras instancias la probabilidad de que pertenezcan es 100% (pertenece a la clase) o 0% (no pertenece), y si tratamos de ajustar un modelo que realice esta suposición (este modelo sería el mismo que el de regresión lineal) veríamos el siguiente resultado.</p>
<figure>
<img src="pandocConversionMedia/ia/regresionlineal_probs.png" id="fig:regresionlineal_probs" style="width:10cm" alt="Modelo de regresión lineal donde la variable dependiente Y es la probabilidad p de que una instancia pertenezca a una clase. Figura tomada de Regresión logística simple y múltiple por Joaquín Amat Rodrigo, disponible en https://www.cienciadedatos.net/documentos/27_regresion_logistica_simple_y_multiple.html" /><figcaption aria-hidden="true">Modelo de regresión lineal donde la variable dependiente <span class="math inline">\(Y\)</span> es la probabilidad <span class="math inline">\(p\)</span> de que una instancia pertenezca a una clase. Figura tomada de Regresión logística simple y múltiple por Joaquín Amat Rodrigo, disponible en <a href="https://www.cienciadedatos.net/documentos/27_regresion_logistica_simple_y_multiple.html">https://www.cienciadedatos.net/documentos/27_regresion_logistica_simple_y_multiple.html</a></figcaption>
</figure>
<p>Si observamos la figura <a href="#fig:regresionlineal_probs" data-reference-type="ref" data-reference="fig:regresionlineal_probs">2.14</a> podemos darnos cuenta de que el modelo no generaliza nada bien y ni siquiera se ajusta a los datos de entrenamiento, se presenta el problema de underfitting.</p>
<p><u>¿Por qué la suposición tiene sentido?</u></p>
<p>En vez de tratar de predecir directamente la probabilidad de que una instancia pertenezca a una clase mediante los atributos <span class="math inline">\(X\)</span>, tratamos de predecir en los diferentes puntos cuantas veces las instancias en una zona pertenecen a una clase en relación con las que no. De manera visual podemos observar como esperamos un aumento continuo y gradual en la razón de posibilidades debido a que en los valores de 1000 a 2000 en el balance de la figura <a href="#fig:regresionlineal_probs" data-reference-type="ref" data-reference="fig:regresionlineal_probs">2.14</a> hay instancias en ambas clases.</p>
<p><u>Deducción del modelo</u></p>
<p>Como se menciono al inicio del tema, el modelo no regresa como salida la razón de posibilidades sino la probabilidad de que una instancia pertenezca o no a una clase, por lo cuál a partir de la suposición ya descrita se va a deducir el modelo.</p>
<p>La suposición planteada se puede describir mediante la siguiente ecuación:</p>
<p><span class="math display">\[ln (odds) = \beta_0 + \beta_1 x_1 + ... + \beta_n x_n
\label{eqn:suposicion_inicial}\]</span></p>
<p>La razón de probabilidad (odds) está definida por la fórmula:</p>
<p><span class="math display">\[odds = \frac{p}{1-p}
\label{eqn:odds}\]</span></p>
<p>Por ello al sustituir la ecuación <a href="#eqn:odds" data-reference-type="ref" data-reference="eqn:odds">[eqn:odds]</a> en <a href="#eqn:suposicion_inicial" data-reference-type="ref" data-reference="eqn:suposicion_inicial">[eqn:suposicion_inicial]</a> tenemos lo siguiente:</p>
<p><span class="math display">\[ln ( \frac{p}{1-p}) = \beta_0 + \beta_1 x_1 + ... + \beta_n x_n
\label{eqn:suposicion_inicial_mod}\]</span></p>
<p>Para deshacernos del logaritmo natural del lado izquierdo de la ecuación vamos a exponenciar ambos lados:</p>
<p><span class="math display">\[\frac{p}{1-p} = e^{\beta_0 + \beta_1 x_1 + ... + \beta_n x_n}
\label{eqn:suposicion_inicial_mod2}\]</span></p>
<p>Ahora vamos a despejar <span class="math inline">\(p\)</span>:</p>
<p><span class="math display">\[p = e^{\beta_0 + \beta_1 x_1 + ... + \beta_n x_n} * (1-p)
\label{eqn:suposicion_inicial_mod3}\]</span></p>
<p><span class="math display">\[p = e^{\beta_0 + \beta_1 x_1 + ... + \beta_n x_n} - p  * e^{\beta_0 + \beta_1 x_1 + ... + \beta_n x_n}
\label{eqn:suposicion_inicial_mod4}\]</span></p>
<p><span class="math display">\[1 = \frac{e^{\beta_0 + \beta_1 x_1 + ... + \beta_n x_n}}{p} - e^{\beta_0 + \beta_1 x_1 + ... + \beta_n x_n}
\label{eqn:suposicion_inicial_mod5}\]</span></p>
<p><span class="math display">\[p = \frac{e^{\beta_0 + \beta_1 x_1 + ... + \beta_n x_n}}{e^{\beta_0 + \beta_1 x_1 + ... + \beta_n x_n}+1} 
\label{eqn:suposicion_inicial_mod6}\]</span></p>
<p><span class="math display">\[p = \frac{1}{1+e^{-(\beta_0 + \beta_1 x_1 + ... + \beta_n x_n})} 
\label{eqn:suposicion_inicial_final}\]</span></p>
<p>Esta última ecuación es la función sigmoide, y como podemos ver en la figura <a href="#fig:sigmoid" data-reference-type="ref" data-reference="fig:sigmoid">2.15</a> la curva de regresión se ve mucho más adecuada para realizar la predicción de la probabilidad de que una instancia pertenezca a una clase o no. De manera formal es la probabilidad de que la instancia <span class="math inline">\(i\)</span> pertenezca a la clase (<span class="math inline">\(y=1\)</span>) dado que posee los atributos <span class="math inline">\(X\)</span> y los parámetros <span class="math inline">\(\beta\)</span>. Esto es descrito en la siguiente fórmula de una manera más formal:</p>
<p><span class="math display">\[P(y^{(i)}=1 | X^{(i)};\beta) = \frac{1}{1+e^{-(\beta_0 + \beta_1 x^{(i)}_1 + ... + \beta_n x^{(i)}_n})} 
\label{eqn:suposicion_inicial_formalprob}\]</span></p>
<p>Para describir nuestro modelo, en partes posteriores del tema lo haremos de la siguiente forma:</p>
<p><span class="math display">\[h_\beta(X^{(i)}) = \frac{1}{1+e^{-(\beta_0 + \beta_1 x_1 + ... + \beta_n x_n})} 
\label{eqn:modelo_rl}\]</span></p>
<figure>
<img src="pandocConversionMedia/ia/logistic function.png" id="fig:sigmoid" style="width:8.3cm" alt="Función sigmoidea estándar" /><figcaption aria-hidden="true">Función sigmoidea estándar</figcaption>
</figure>
<p><u>Función de coste del modelo</u></p>
<p>Dado nuestro modelo la probabilidad de que una instancia <span class="math inline">\(i\)</span> pertenezca a la clase (<span class="math inline">\(y=1\)</span>) es <span class="math inline">\(h_\beta(X^{(i)})\)</span> y la probabilidad de que no pertenezca (<span class="math inline">\(y=0\)</span>) es <span class="math inline">\(1-h_\beta(X^{(i)})\)</span>, esto puede ser resumido en la siguiente ecuación:</p>
<p><span class="math display">\[P(y^{(i)}) = h_\beta(X^{(i)}) ^ {y^{(i)}} + (1-h_\beta(X^{(i)})) ^ {(1- y^{(i)})}
\label{eqn:probabilidadyrl}\]</span></p>
<p>Esta sería la función de verosimilitud de una instancia <span class="math inline">\(i\)</span> que nos dice la probabilidad de que la instancia <span class="math inline">\(i\)</span> con los atributos <span class="math inline">\(X^{(i)}\)</span> ocurra dado el valor de <span class="math inline">\(y^{(i)}\)</span>, para calcular la verosimilitud de todo el conjunto de entrenamiento se utiliza la siguiente fórmula:</p>
<p><span class="math display">\[P(X;\beta | Y) = \prod_{i=1}^{n} h_\beta(X^{(i)}) ^ {y^{(i)}} + (1-h_\beta(X^{(i)})) ^ {(1- y^{(i)})}
\label{eqn:rl_verosimilituddataset}\]</span></p>
<p>Si quisieramos obtener el valor de los parámetros tendríamos que optimizar esta función <a href="#eqn:rl_verosimilituddataset" data-reference-type="ref" data-reference="eqn:rl_verosimilituddataset">[eqn:rl_verosimilituddataset]</a>, sin embargo debido a que involucra multiplicación obtener su derivada o gradiente sería complejo, por eso obtendremos el logaritmo natural de la verosimilitud (Esto no nos afecta debido a que la función sigue siendo creciente tras aplicar el logaritmo):</p>
<p><span class="math display">\[L(\beta) = ln(P(X;\beta  | Y)) = \sum_{i=1}^{n} y^{(i)}*log(h_\beta(X^{(i)}) ) + (1-y^{(i)})*log(1-h_\beta(X^{(i)}) )
\label{eqn:rl_verosimilituddataset_log}\]</span></p>
<p>Sin embargo como se planea utilizar el descenso del gradiente tendremos que buscar minimizar una función para ello simplemente multiplicaremos por <span class="math inline">\(-1\)</span> la fórmula anterior y para simplificar la derivación dividiremos sobre <span class="math inline">\(n\)</span></p>
<p><span class="math display">\[J(\beta) -\frac{1}{n} \sum_{i=1}^{n} y^{(i)}*log(h_\beta(X^{(i)}) ) + (1-y^{(i)})*log(1-h_\beta(X^{(i)}) )
\label{eqn:rl_funcioncoste}\]</span></p>
<p><strong>Descripción del modelo</strong></p>
<p>Como se dedujo anteriormente, el modelo tiene la siguiente forma:</p>
<p><span class="math display">\[h_\beta(X^{(i)}) = \frac{1}{1+e^{-(\beta_0 + \beta_1 x_1 + ... + \beta_n x_n})} 
\label{eqn:suposicion_inicial_final2}\]</span></p>
<p>Para simplificar el entrenamiento modelo, añadiremos <span class="math inline">\(x_0\)</span> que en todas las instancias tendrá un valor de 1. <span class="math display">\[h_\beta(X^{(i)}) = \frac{1}{1+e^{-(\beta_0 x_0 + \beta_1 x_1 + ... + \beta_n x_n})} 
\label{eqn:suposicion_inicial_final3}\]</span></p>
<p>Este modelo como salida nos da la probabilidad <span class="math inline">\(h(\beta)\)</span> de que una instancia pertenezca o no a una clase dados sus atributos <span class="math inline">\(X\)</span>. Para realizar la tarea de clasificación podemos fijar un valor limite, si la probabilidad es mayor al limite determinado pertenece a la clase, si es menor no pertenece, este valor limite suele ser 0.5.</p>
<p>Cuando una instancia pertenece a la clase nuestro modelo debe regresar 1, en caso contrario debe regresar 0 por lo cuál la siguiente fórmula muestra lo descrito anteriormente.</p>
<p><span class="math display">\[\label{eqn:prob_reg_logistica}
    \hat{y} = 
\begin{dcases}
    1,&amp; \text{si } h_\beta(X^{(i)}) &gt; 0.5 \\
    0,&amp; \text{En caso contrario}
\end{dcases}\]</span></p>
<p><strong>Entrenamiento del modelo</strong></p>
<p>Si se utilizará el error cuadrático medio como función de costo la función de error resultante sería no convexa por lo cuál no se podría asegurar llegar a un mínimo global mediante descenso del gradiente. Es por eso que usaremos la siguiente función de perdida (recordemos que la función de pérdida considera una sola instancia):</p>
<p><span class="math display">\[p( \beta ) = 
\begin{dcases}
    -log(h_\beta(X^{(i)}),&amp; \text{si } y = 1\\
    -log(1-h_\beta(X^{(i)}),&amp; \text{En caso contrario } (y=0)
\end{dcases} 
\label{eqn:costo_reg_logistica}\]</span></p>
<p>Donde <span class="math inline">\(y\)</span> es la clase actual de la instancia (1 si pertenece, 0 si no).<br />
Esta ecuación puede ser escrita también de la siguiente forma: <span class="math display">\[p( \beta ) = - y*log(h_\beta(X^{(i)}) - (1-y)*log(1-h_\beta(X^{(i)})
\label{eqn:costo_reg_logistica2}\]</span></p>
<p>La actualización de los parametros mediante el descenso del gradiente con una sola instancia de entrenamiento se hace de la siguiente manera(el cálculo de esta derivada queda fuera del alcance de este libro, un buen vídeo donde se explora este cálculo es <a href="https://www.youtube.com/watch?v=z_xiwjEdAC4">https://www.youtube.com/watch?v=z_xiwjEdAC4</a>): <span class="math display">\[\label{eqn:logistic_regression_gradient_descent}
\beta_i = \beta_i - \alpha * (h_\beta(X^{(i)}-y)*x_i\]</span></p>
<p>Ahora veamos la función de coste que considera todas las instancias del set de entrenamiento, la función es la siguiente: <span class="math display">\[J(\beta) -\frac{1}{n} \sum_{i=1}^{n} y^{(i)}*log(h_\beta(X^{(i)}) ) + (1-y^{(i)})*log(1-h_\beta(X^{(i)}) )
\label{eqn:logistic_regression_fgradient_descent}\]</span> Por lo cual la actualización de los pesos se da de la forma: <span class="math display">\[\label{eqn:logistic_regression_gradient_descent2}
\beta = \beta - \alpha * \frac{1}{N} X&#39; (h_\beta(X)-Y)\]</span></p>
<p>Esta fórmula es muy parecida a la mostrada en regresión lineal, si reemplazamos <span class="math inline">\(h_\beta(X)\)</span> por <span class="math inline">\(\hat{Y}\)</span> son iguales, lo cual en un principio puede parecer extraño debido a que se esta utilizando una función de coste completamente diferente, sin embargo hay que tomar en cuenta que en ambas ecuaciones la forma de calcular <span class="math inline">\(h_\beta(X)\)</span> y <span class="math inline">\(\hat{Y}\)</span> es totalmente distinta, si se tiene esta intriga o inquietud yo recomiendo ver los vídeos de Andrew Ng donde se calcula este gradiente, todos están disponibles de manera gratuita en la plataforma de Youtube.</p>
<p><strong>Ejercicio de programación:</strong></p>
<p>Ejercicio para fortalecer los conocimientos adquiridos:</p>
<ol>
<li><p>En un lenguaje de programación matemático como Octave, Julia o Matlab resolver un problema de clasificación usando regresión logística.</p></li>
<li><p>En cualquier lenguaje de programación utilizar alguna librería como scikit-learn para resolver un problema de clasificación usando regresión logística.</p></li>
</ol>
<strong>K - nearest neighbors (Clasificación)</span> <span id="subsection:knn_csn" label="subsection:knn_csn">[subsection:knn_csn]</strong>
<p>En este libro ya se exploro el uso de K-Nearest Neighbors (K-Vecinos más cercanos) para regresión en el tema <a href="#subsection:knn" data-reference-type="ref" data-reference="subsection:knn">[subsection:knn]</a>, en este tema se explorará su uso en el área de clasificación, dado su funcionamiento este algoritmo puede resolver problemas de clasificación multi-clase.</p>
<p><strong>Suposiciones del algoritmo</strong></p>
<p>Dado a que es un algoritmo de aprendizaje no paramétrico no se realizan fuertes suposiciones sobre la forma que tiene la curva de regresión, de manera intuitiva se puede entender que este algoritmo asume que la instancia pertenece a la misma clase <span class="math inline">\(Y\)</span> que la mayoría de las <span class="math inline">\(n\)</span> instancias más cercanas de acuerdo a una distancia calculada a partir de las características <span class="math inline">\(X\)</span>.</p>
<p><strong>Funcionamiento del algoritmo de K-NN</strong></p>
<p>Tendremos los siguientes elementos:</p>
<ul>
<li><p>Un set de entrenamiento compuesto de las características <span class="math inline">\(X\)</span> y el vector columna <span class="math inline">\(Y\)</span> que contiene la clase asociada a cada instancia en <span class="math inline">\(X\)</span>.</p></li>
<li><p>Una nueva instancia <span class="math inline">\(b\)</span> a clasificar.</p></li>
<li><p>El hiperparámetro <span class="math inline">\(k\)</span> que determina el número de vecinos a seleccionar.</p></li>
</ul>
<p>El algoritmo es el siguiente:</p>
<ol>
<li><p>Calcular la distancia entre la nueva instancia <span class="math inline">\(b\)</span> y cada una de las instancias en <span class="math inline">\(X\)</span>.</p></li>
<li><p>Seleccionar los <span class="math inline">\(k\)</span> elementos presentes en <span class="math inline">\(X\)</span> más cercanos a <span class="math inline">\(b\)</span>.</p></li>
<li><p>Clasificar la nueva instancia de acuerdo a la clases <span class="math inline">\(Y\)</span> de los vecinos más cercanos.</p></li>
</ol>
<p>Este algoritmo es bastante sencillo y los primeros dos pasos fueron explorados a detalle en el tema <a href="#subsection:knn" data-reference-type="ref" data-reference="subsection:knn">[subsection:knn]</a>, por ello solo se explorará el último paso.</p>
<p><u>3. Clasificar la nueva instancia de acuerdo a la clases <span class="math inline">\(Y\)</span> de los vecinos más cercanos.</u></p>
<p>Esto es bastante sencillo, simplemente se cuenta el número de vecinos que pertenecen a cada clase y se elige la clase con mayor número de votos.</p>
<div class="center">
<p>(1,0)<span>420</span></p>
</div>
<p><strong>Ejercicio de programación:</strong></p>
<ol>
<li><p>En un lenguaje de programación matemático como Octave, Julia o Matlab resolver un problema de clasificación mediante knn.</p></li>
<li><p>En cualquier lenguaje de programación utilizar alguna librería como scikit-learn para resolver un problema de clasificación mediante knn.</p></li>
</ol>
<strong>Clasificador bayesiano ingenuo (Naive Bayes classifier)</strong>
<p>Un clasificador bayesiano ingenuo es un clasificador probabilistico que se basa en el teorema de bayes (Este teorema será explicado más adelante dentro de este tema). Se le llama ingenuo debido a que supone independencia <a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> entre las variables de las instancias, esto suele no ser cierto en los problemas reales sin embargo el desempeño del clasificador suele ser bastante bueno aún asumiendo esto.</p>
<p><strong>Descripción del clasificador</strong></p>
<p>Como lo indica el nombre se basa en el teorema de bayes, el teorema dice lo siguiente <span class="citation" data-cites="bayes1958essay"></span>:</p>
<p>“Sea <span class="math inline">\(\{A_{1},A_{2},...,A_{i},...,A_{n}\}\)</span> un conjunto de sucesos mutuamente excluyentes y exhaustivos, y tales que la probabilidad de cada uno de ellos es distinta de cero (0). Sea <span class="math inline">\(B\)</span> un suceso cualquiera del que se conocen las probabilidades condicionales <span class="math inline">\(P(B|A_{i})\)</span>. Entonces, la probabilidad <span class="math inline">\(P(A_{i}|B)\)</span> viene dada por la expresión: ” <span class="math display">\[P(A_{i}|B) = \frac{P(B|A_{i}) P(A_{i})}{P(B)}
\label{eqn:bayes_theorem}\]</span></p>
<p>Donde:</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(P(A_{i})\)</span> son las probabilidades a priori</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(P(B|A_{i})\)</span> es la probabilidad de <span class="math inline">\(B\)</span> en la hipotesis <span class="math inline">\(A_{i}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(P(A_{i}|B)\)</span> son las probabilidades a posteriori</td>
</tr>
</tbody>
</table>
<p>Los sucesos <span class="math inline">\(\{A_{1},A_{2},...,A_{i},...,A_{n}\}\)</span> son aquellas clases a las cuales pueden pertenecer las instancias, estos sucesos son mutuamente excluyentes (Una instancia no puede pertenecer a dos clases al mismo tiempo) y exhaustivos (El conjunto A representa todas las clases posibles a las cuales pueden pertenecer las instancias, la union de las probabilidades de los sucesos es 1).</p>
<p>A continuación se reescribe el teorema de bayes para expresar la probabilidad de que una instancia con los atributos <span class="math inline">\(\{F_{1},F_{2},...,F_{i},...,F_{n}\}\)</span> (Variables independientes) pertenezca a la clase <span class="math inline">\(C\)</span> (Variable dependiente).</p>
<p><span class="math display">\[P(C|F_{1},F_{2},...,F_{i},...,F_{n}) = \frac{P(F_{1},F_{2},...,F_{i},...,F_{n}|C) P(C)}{P(F_{1},F_{2},...,F_{i},...,F_{n})}
\label{eqn:clasificadorBayesiano1}\]</span></p>
<p>En la practica solo se usa el numerador, ya que se compara la probabilidad para cada clase y <span class="math inline">\(P(F_{1},F_{2},...,F_{i},...,F_{n})\)</span> es constante para todas las clases, por lo cual el clasificador puede ser escrito de la siguiente manera:</p>
<p><span class="math display">\[P(C|F_{1},F_{2},...,F_{i},...,F_{n}) = P(F_{1},F_{2},...,F_{i},...,F_{n}|C) P(C)
\label{eqn:clasificadorBayesiano2}\]</span></p>
<p>La definición de probabilidad condicional es la siguiente: <span class="math display">\[P(A \mid B) = \frac{P(A \cap B)}{P(B)}.
\label{eqn:probabilidadCondicional}\]</span></p>
<p>Aplicando la anterior definición sobre la fórmula <a href="#eqn:clasificadorBayesiano2" data-reference-type="ref" data-reference="eqn:clasificadorBayesiano2">[eqn:clasificadorBayesiano2]</a> obtenemos lo siguiente: <span class="math display">\[P(C|F_{1},F_{2},...,F_{i},...,F_{n}) = P(C) \ P(F_1\vert C) \ P(F_2\vert C, F_1) \ P(F_3\vert C, F_1, F_2) \ P(F_4,\dots,F_n\vert C, F_1, F_2, F_3)
\label{eqn:clasificadorBayesiano3}\]</span></p>
<p>Y dado a que se asume independencia entre los atributos de la instancia (<span class="math inline">\(P(F_{i}\vert C,F_{j})=P(F_{i}\vert C)\)</span>), la fórmula final del clasificador es la siguiente:</p>
<p><span class="math display">\[P(C|F_{1},F_{2},...,F_{i},...,F_{n}) = P(C) \prod_{i=1}^n P(F_i \vert C)
\label{eqn:clasificadorBayesianoFinal}\]</span></p>
<p>Calcular las probabilidades a priori (<span class="math inline">\(P(C)\)</span>) es bastante simple, para conocer la probabilidad a priori de que una instancia pertenezca a la clase <span class="math inline">\(C\)</span> basta con dividir el número de instancias que pertenecen en la clase <span class="math inline">\(C\)</span> en nuestro set de entrenamiento al número total de instancias dentro del mismo set de datos. Obtener <span class="math inline">\(P(F_i \vert C)\)</span> depende del tipo de atributos que tengamos.</p>
<p><strong>Ejemplo con atributos categóricos u ordinales</strong></p>
<p>Ahora trataremos con un problema de juguete, en el cual tenemos que determinar si un elemento es una Manzana, Naranja o Sandía basado en sus características (Color, Tamaño, Textura). Los valores que puede tomar cada atributo son los siguientes:</p>
<p>Color: {Rojo, Naranja, Verde}<br />
Tamaño: {Pequeño, Mediano, Grande}<br />
Textura: {Rugosa, Lisa}</p>
<p>Para este ejemplo usaremos un set de entrenamiento muy pequeño (10 instancias) es importante tomar en cuenta que lo ideal sería contar con un mayor número de instancias.</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"><strong>Instancia</strong></th>
<th style="text-align: center;"><strong>Color</strong></th>
<th style="text-align: center;"><strong>Tamaño</strong></th>
<th style="text-align: center;"><strong>Textura</strong></th>
<th style="text-align: center;"><strong>Clase</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">Rojo</td>
<td style="text-align: left;">Pequeño</td>
<td style="text-align: left;">Lisa</td>
<td style="text-align: left;">Manzana</td>
</tr>
<tr class="even">
<td style="text-align: left;">2</td>
<td style="text-align: left;">Naranja</td>
<td style="text-align: left;">Mediano</td>
<td style="text-align: left;">Rugosa</td>
<td style="text-align: left;">Naranja</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3</td>
<td style="text-align: left;">Verde</td>
<td style="text-align: left;">Grande</td>
<td style="text-align: left;">Lisa</td>
<td style="text-align: left;">Sandía</td>
</tr>
<tr class="even">
<td style="text-align: left;">4</td>
<td style="text-align: left;">Rojo</td>
<td style="text-align: left;">Pequeño</td>
<td style="text-align: left;">Lisa</td>
<td style="text-align: left;">Manzana</td>
</tr>
<tr class="odd">
<td style="text-align: left;">5</td>
<td style="text-align: left;">Naranja</td>
<td style="text-align: left;">Pequeño</td>
<td style="text-align: left;">Rugosa</td>
<td style="text-align: left;">Naranja</td>
</tr>
<tr class="even">
<td style="text-align: left;">6</td>
<td style="text-align: left;">Verde</td>
<td style="text-align: left;">Pequeño</td>
<td style="text-align: left;">Rugosa</td>
<td style="text-align: left;">Naranja</td>
</tr>
<tr class="odd">
<td style="text-align: left;">7</td>
<td style="text-align: left;">Verde</td>
<td style="text-align: left;">Grande</td>
<td style="text-align: left;">Lisa</td>
<td style="text-align: left;">Sandía</td>
</tr>
<tr class="even">
<td style="text-align: left;">8</td>
<td style="text-align: left;">Naranja</td>
<td style="text-align: left;">Pequeño</td>
<td style="text-align: left;">Rugosa</td>
<td style="text-align: left;">Manzana</td>
</tr>
<tr class="odd">
<td style="text-align: left;">9</td>
<td style="text-align: left;">Naranja</td>
<td style="text-align: left;">Pequeño</td>
<td style="text-align: left;">Lisa</td>
<td style="text-align: left;">Naranja</td>
</tr>
<tr class="even">
<td style="text-align: left;">10</td>
<td style="text-align: left;">Rojo</td>
<td style="text-align: left;">Mediano</td>
<td style="text-align: left;">Lisa</td>
<td style="text-align: left;">Manzana</td>
</tr>
</tbody>
</table>
<p>El primer paso sería obtener las probabilidades a priori de cada una de las clases (Manzana, Sandía y Naranja), para ello hay que contar el número de elementos pertenecientes a cada clase y dividirlo sobre el número total de instancias.</p>
<p><span class="math display">\[P(C=Manzana) = \frac{4}{10}
\label{eqn:prioriManzana}\]</span></p>
<p><span class="math display">\[P(C=Naranja) = \frac{4}{10}
\label{eqn:prioriNaranja}\]</span></p>
<p><span class="math display">\[P(C=Sandia) = \frac{2}{10}
\label{eqn:prioriSandia}\]</span></p>
<p>Posteriormente hay que obtener las probabilidades de que se de un evento determinado dado que la instancia pertenece a una clase. Aquí se calcularan algunos eventos relacionados con la clase Sandía y el atributo tamaño. De igual manera se cuentan los elementos que cumplan con el evento y se divide entre el número de elementos pertenecientes a la clase.</p>
<p><span class="math display">\[P(\text{Tamaño}=\text{Pequeño} | C=Sandia) = \frac{0}{2}
\label{eqn:tamPeqSandia}\]</span></p>
<p><span class="math display">\[P(\text{Tamaño}=\text{Mediano} | C=Sandia) = \frac{0}{2}
\label{eqn:tamMedSandia}\]</span></p>
<p><span class="math display">\[P(\text{Tamaño}=\text{Grande} | C=Sandia) = \frac{2}{2}
\label{eqn:tamGraSandia}\]</span></p>
<p>Se puede notar en las probabilidades anteriores que cuando el tamaño es Mediano o Pequeño la probabilidad es 0, por lo cual el resto de las características dejan de ser relevantes al momento de realizar la clasificación (esto debido a que las probabilidades se multiplican), esto suele ser evitado sumando un elemento a cada una de los valores posibles (sumando 1 en el numerador y N en el denominador, N es el número de valores posibles que puede tomar el atributo), por lo cual las fórmulas anteriores tomarían los siguientes valores:</p>
<p><span class="math display">\[P(\text{Tamaño}=\text{Pequeño} | C=Sandia) = \frac{0+1}{2+3} = \frac{1}{5}
\label{eqn:tamPeqSandia2}\]</span></p>
<p><span class="math display">\[P(\text{Tamaño}=\text{Mediano} | C=Sandia) = \frac{0+1}{2+3} = \frac{1}{5}
\label{eqn:tamMedSandia2}\]</span></p>
<p><span class="math display">\[P(\text{Tamaño}=\text{Grande} | C=Sandia) = \frac{2+1}{2+3} = \frac{3}{5}
\label{eqn:tamGraSandia2}\]</span></p>
<p>En este ejemplo de juguete los valores de las probabilidades se ven fuertemente alterados, esto no suele ser tan relevante en problemas reales donde se cuenta con muchas instancias en nuestro set de entrenamiento.</p>
<p>Ahora que ya vimos como realizar el calculo de las probabilidades vamos a ver como clasificaríamos una determinada instancia, supongamos que la instancia tiene color rojo, es mediana, y es lisa.</p>
<p>Dado el conjunto de atributos A = {<span class="math inline">\(Color = Rojo, \text{Tamaño} = Mediano, Textura=Lisa\)</span>}, podemos calcular su pertenencia a una clase C con la siguiente fórmula:</p>
<p><span class="math display">\[P(C|A) = P(C)*P(\text{Color}=\text{Rojo} | C)*P(\text{Tamaño}=\text{Mediano} | C)*P(\text{Textura}=\text{Lisa} | C)
\label{eqn:clasificadorEjemplo}\]</span></p>
<p>Si C = Manzana:</p>
<p><span class="math display">\[P(C=Manzana|A) = \frac{4}{10}*\frac{4}{7}*\frac{2}{7}*\frac{4}{6} = 0.04353741496
\label{eqn:clasificadorEjemplo1}\]</span></p>
<p>Si C = Naranja:</p>
<p><span class="math display">\[P(C=Naranja|A) = \frac{4}{10}*\frac{1}{7}*\frac{2}{7}*\frac{2}{6} = 0.0054421768707483
\label{eqn:clasificadorEjemplo2}\]</span></p>
<p>Si C = Sandia:</p>
<p><span class="math display">\[P(C=Sandia|A) = \frac{2}{10}*\frac{1}{5}*\frac{1}{5}*\frac{3}{4} = 0.006
\label{eqn:clasificadorEjemplo3}\]</span></p>
<p>Como podemos ver este ejemplo sería clasificado como una manzana.<br />
<strong>Ejemplo con atributos númericos</strong></p>
<p>Ahora veremos como se tendría que tratar el problema si tuviéramos valores numéricos continuos, en este caso asumiremos que para cada instancia de nuestro conjunto de datos de entrenamiento tenemos su color promedio (dado por 3 valores, rojo R, verde G y azul B) y la etiqueta de la clase a la que pertenece.</p>
<p>Las probabilidades a priori se calculan de la misma manera que en el ejemplo anterior.</p>
<p>Para calcular la probabilidad de que se de un evento determinado dado a que la instancia pertenece a una clase tendremos que asumir que los valores que toma una variable en cada clase pertenecen a una distribución. Por poner un ejemplo, masomenos se debería ver de la siguiente manera la distribución de la variable R (concentración del canal rojo) en cada una de las clases.</p>
<figure>
<img src="pandocConversionMedia/ia/r_channel_dist.png" id="fig:distributionchannelr" style="width:10cm" alt="Distribución del canal rojo en el color medido en las naranjas, sandías y manzanas" /><figcaption aria-hidden="true">Distribución del canal rojo en el color medido en las naranjas, sandías y manzanas</figcaption>
</figure>
<p>El primer paso consiste en obtener estás distribuciones de las variables numéricas para cada una de las clases, generalmente se usa la distribución normal, para tener la función de densidad de probabilidad de esta distribución tendremos que conocer el valor promedio de la variable <span class="math inline">\(\mu\)</span> y la desviación estándar <span class="math inline">\(\sigma\)</span>.</p>
<p><span class="math display">\[f(x) = \frac{1}{\sigma\sqrt{2\pi}} 
  \exp\left( -\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^{\!2}\,\right)\]</span></p>
<p>En general para conocer la probabilidad de que un valor <span class="math inline">\(x_i\)</span> pertenezca a la clase <span class="math inline">\(y\)</span> usaremos la siguiente fórmula:</p>
<p><span class="math display">\[P(x_i | y) = \frac{1}{ \sqrt{ 2 \pi \sigma_{y}^{2} } } 
  \exp\left( -\frac{1}{2}\left(\frac{x_i -\mu_{y}}{\sigma_{y}^{2}}\right)^{\!2}\,\right)\]</span></p>
<p>Y dado a que se asume independencia entre los atributos de la instancia (<span class="math inline">\(P(F_{i}\vert C,F_{j})=P(F_{i}\vert C)\)</span>), podemos usar la siguiente fórmula:</p>
<p><span class="math display">\[P(C|F_{1},F_{2},...,F_{i},...,F_{n}) = P(C) \prod_{i=1}^n P(F_i \vert C)
\label{eqn:clasificadorBayesianoFinal2}\]</span></p>
<p><strong>Ejercicio de programación:</strong></p>
<p>Ejercicio para fortalecer los conocimientos adquiridos:</p>
<ol>
<li><p>En un lenguaje de programación matemático como Octave, Julia o Matlab resolver un problema de clasificación usando un clasificador bayesiano ingenuo.</p></li>
<li><p>En cualquier lenguaje de programación utilizar alguna librería como scikit-learn para resolver un problema de clasificación usando un clasificador bayesiano ingenuo.</p></li>
</ol>
<p>A continuación se presenta un link a las soluciones en caso de que el lector lo requiera:</p>
<p><img src="pandocConversionMedia/Pictures/github/libro-ia.png" style="width:6cm" alt="image" /></p>
<p><a href="https://github.com/amr205/Introduccion-a-la-IA---Libro">https://github.com/amr205/Introduccion-a-la-IA---Libro</a></p>
<strong>Árbol de decisión (Decision Tree)</strong>
<p>Un árbol de decisión es una técnica de aprendizaje automático que puede ser utilizada para resolver problemas de clasificación o regresión, en este libro revisaremos su uso en la tarea de clasificación.</p>
<p><strong>Suposiciones del algoritmo</strong></p>
<p>Un clasificador de árbol de decisión es uno de los posibles acercamientos para la toma de decisiones de múltiples etapas. La idea principal consiste en dividir una decisión compleja en la unión de varias decisiones más simples. <span class="citation" data-cites="dtc_survey"></span></p>
<p><strong>Descripción del modelo</strong></p>
<p>En los arboles de decisión, cada nodo interno representa una decisión y cada hoja representa la clase a la cual se asignaría si se sigue esa ruta durante la clasificación.</p>
<figure>
<img src="pandocConversionMedia/ia/decisiontree.png" id="fig:decisiontree" style="width:6.5cm" alt="Ejemplo de árbol de decisión" /><figcaption aria-hidden="true">Ejemplo de árbol de decisión</figcaption>
</figure>
<p>Podemos ver en las siguientes figuras <a href="#fig:decisiontree_e1" data-reference-type="ref" data-reference="fig:decisiontree_e1">2.18</a>,<a href="#fig:decisiontree_e2" data-reference-type="ref" data-reference="fig:decisiontree_e2">2.19</a> y <a href="#fig:decisiontree_e3" data-reference-type="ref" data-reference="fig:decisiontree_e3">2.20</a> cómo cada decisión va separando los datos dentro del siguiente ejemplo donde clasificamos instancias con características <span class="math inline">\(x_0\)</span> y <span class="math inline">\(x_1\)</span>.</p>
<figure>
<img src="pandocConversionMedia/ia/dt_1.png" id="fig:decisiontree_e1" style="width:10cm" alt="Ejemplo del primer nivel del árbol de decisión, los puntos azules pertenecen a la clase A y los puntos rojos a la clase B" /><figcaption aria-hidden="true">Ejemplo del primer nivel del árbol de decisión, los puntos azules pertenecen a la clase A y los puntos rojos a la clase B</figcaption>
</figure>
<figure>
<img src="pandocConversionMedia/ia/dt_2.png" id="fig:decisiontree_e2" style="width:10cm" alt="Ejemplo del segundo nivel del árbol de decisión, los puntos azules pertenecen a la clase A y los puntos rojos a la clase B" /><figcaption aria-hidden="true">Ejemplo del segundo nivel del árbol de decisión, los puntos azules pertenecen a la clase A y los puntos rojos a la clase B</figcaption>
</figure>
<figure>
<img src="pandocConversionMedia/ia/dt_3.png" id="fig:decisiontree_e3" style="width:10cm" alt="Ejemplo del tercer nivel del árbol de decisión, los puntos azules pertenecen a la clase A y los puntos rojos a la clase B" /><figcaption aria-hidden="true">Ejemplo del tercer nivel del árbol de decisión, los puntos azules pertenecen a la clase A y los puntos rojos a la clase B</figcaption>
</figure>
<p><strong>Construcción de un árbol de decisión</strong></p>
<p>El diseño de un árbol de decisión consiste principalmente de los siguientes puntos <span class="citation" data-cites="dtc_survey"></span>:</p>
<ol>
<li><p>La elección de la estructura del árbol.</p></li>
<li><p>La elección del subconjunto de características a usar en cada nodo interno.</p></li>
<li><p>La elección de la regla o estrategia de decisión a usar en cada nodo interno.</p></li>
</ol>
<p>El algoritmo para la construcción del árbol dependerá de las decisiones que tomemos, un conjunto de decisiones comunes para el diseño del árbol son las siguientes <span class="citation" data-cites="dtc_survey"></span>:</p>
<ul>
<li><p>Construir un árbol binario.</p></li>
<li><p>Utilizar una sola característica en cada nodo interno</p></li>
<li><p>Construir el árbol de abajo a arriba tratando de minimizar el porcentaje de error.</p></li>
</ul>
<p>Dentro de los algoritmos existentes destaca el algoritmo CART (Classification and Regression Trees) que permite generar los árboles de decisión, a continuación se describe de manera general el algoritmo, un buen video que explica este proceso de manera gráfica es el siguiente: <a href="https://www.youtube.com/watch?v=kqaLlte6P6o&amp;t=6s&amp;ab_channel=codificandobits">https://www.youtube.com/watch?v=kqaLlte6P6o&amp;t=6s&amp;ab_channel=codificandobits</a></p>
<p>El algoritmo CART va construyendo el árbol de decisión de arriba hacia abajo, dividiendo el espacio de entrada de forma recursiva con cada decisión, el pseudocódigo presentado a continuación pretende proveer al lector de una base para entender el funcionamiento de estos algoritmos.</p>
<div class="algorithm">

</div>
<p>Para elegir la condición óptima tendremos que recorrer los diferentes atributos con sus posibles valores para evaluarlos usando el conjunto de datos de entrenamiento que han llegado a ese nodo, elegiremos aquella condición que minimice algún valor de impureza o error. Dentro de los valores de impureza usados comunmente se encuentran los siguientes:</p>
<ul>
<li><p><strong>Impureza Gini</strong>: <span class="math display">\[Gini = 1 - \sum_{i=1}^{k}(p_i)^{2}\]</span></p></li>
<li><p><strong>Entropy</strong>: <span class="math display">\[Entropy = - \sum_{i=1}^{k}(p_i)log_2(p_i)\]</span></p></li>
</ul>
<p>Donde <span class="math inline">\(p_i\)</span> es la probabilidad de que una instancia pertenezca a la clase <span class="math inline">\(i\)</span> y <span class="math inline">\(k\)</span> es el número de clases presentes en nuestro conjunto de datos.</p>
<div class="algorithm">

</div>
<p><strong>Ventajas de los árboles de decisión</strong></p>
<ul>
<li><p>El proceso de clasificación o regresión es fácil de entender y explicar. (A diferencia de otros algoritmos de aprendizaje supervisado es fácil determinar las razones por las cuales un modelo clasifico una instancia en una clase)</p></li>
<li><p>Puede usar características continuas o categóricas.</p></li>
<li><p>Mediante un árbol interno podemos identificar las características más relevantes.</p></li>
<li><p>Implícitamente el árbol de decisión realiza selección de características (lo cuál nos permite observar las características más importantes de nuestro conjunto de datos)</p></li>
</ul>
<p><strong>Desventajas de los árboles de decisión</strong></p>
<ul>
<li><p>La construcción de un árbol de decisión puede ser computacionalmente costoso (incrementa de manera lineal con el número de datos y el número de características).</p></li>
<li><p>No son tan adecuado para la tarea de regresión de variables continuas.</p></li>
<li><p>Este algoritmo no puede asegurar un óptimo global.</p></li>
</ul>
<p>En este libro no se aborda tan a detalle el proceso de construcción de un árbol, en el repositorio de github del libro se podrá encontrar la implementación en el lenguaje octave para la construcción de un árbol de decisión binario para características categóricas.</p>
<p><strong>Ejercicio de programación:</strong></p>
<p>Ejercicio para fortalecer los conocimientos adquiridos:</p>
<ol>
<li><p>En un lenguaje de programación matemático como Octave, Julia o Matlab resolver un problema de clasificación usando un árbol de decisión.</p></li>
<li><p>En cualquier lenguaje de programación utilizar alguna librería como scikit-learn para resolver un problema de clasificación usando un árbol de decisión.</p></li>
</ol>
<p><img src="pandocConversionMedia/Pictures/github/libro-ia.png" style="width:5cm" alt="image" /></p>
<p><a href="https://github.com/amr205/Introduccion-a-la-IA---Libro">https://github.com/amr205/Introduccion-a-la-IA---Libro</a></p>
<strong>Máquinas de vectores de soporte (SVM)</strong>
<p>Una máquina de vectores de soporte es una tecnica de aprendizaje automático que puede utilizarse para resolver problems de clasificación, a diferencia de otros algoritmos las SVM buscan encontrar el hiperplano que separe los elementos maximizando el margen entre los elementos.</p>
<figure>
<img src="pandocConversionMedia/ia/svm_margin_example.png" id="fig:svm_example_margin" style="width:10cm" alt="En el lado izquierdo se muestran posibles hiperplanos que separan los datos, en el lado derecho se muestra el hiperplano que maximiza el margen entre los datos" /><figcaption aria-hidden="true">En el lado izquierdo se muestran posibles hiperplanos que separan los datos, en el lado derecho se muestra el hiperplano que maximiza el margen entre los datos</figcaption>
</figure>
<p><strong>Suposiciones del algoritmo</strong></p>
<p>Este algoritmo se basa en la idea de que dado un conjunto de datos linealmente separables es posible encontrar el hiperplano que minimiza el margen entre el hiperplano y las instancias más cercanas (a estas instancias se les llama vectores de soporte).</p>
<p>La manera en la cual se formula el modelo a partir de esta hipotesis y el proceso de optimización se sale del alcance de este libro debido a los requisitos para la deducción y descripción formal del módelo. Se motiva al lector que este interesado en el proceso que revise los siguientes contenidos.</p>
<ul>
<li><p><a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Lista de reproducción sobre algebra lineal</a></p></li>
<li><p><a href="https://www.youtube.com/watch?v=_PwhiWxHK8o">Video donde se explica cómo se llega al módelo de SVM</a></p></li>
<li><p><a href="https://www.syncfusion.com/succinctly-free-ebooks/support-vector-machines-succinctly">Libro donde se explora a mayor detalle este algoritmo</a></p></li>
</ul>
<p><strong>Descripción y evolución del modelo</strong></p>
<p>El algoritmo básico de SVM (Hard margin) desarrollado en 1963 requiere que los datos sean linealmente separables y el modelo resultante es el siguiente <span class="citation" data-cites="boswell2002introduction"></span>:</p>
<p><span class="math display">\[\label{eqn:svm_basic}
f(X) = sign(W \cdot  X + b)\]</span></p>
<figure>
<img src="pandocConversionMedia/ia/svm_hard_vs_soft.png" style="width:10cm" alt="Ejemplo de SVM Hard Margin (izquierda), SVM Soft Margin (derecha)" /><figcaption aria-hidden="true">Ejemplo de SVM Hard Margin (izquierda), SVM Soft Margin (derecha)</figcaption>
</figure>
<p>Es posible considerar un hiperparámetro durante el entrenamiento del algoritmo que busque un balance entre el margen y asegurarse de que todos los elementos sean clasificados correctamente. A esta variación del SVM se le conoce como Soft Margin y fue desarrollado en 1993.</p>
<figure>
<img src="pandocConversionMedia/ia/svm_kernel_trick.png" id="fig:svm_kernel_trick" style="width:12cm" alt="Ejemplo de SVM usando el kernel \phi(a, b) = (a, b, a2 + b2). By Shiyu Ji - Own work, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=60458994" /><figcaption aria-hidden="true">Ejemplo de SVM usando el kernel <span class="math inline">\(\phi(a, b) = (a, b, a2 + b2)\)</span>. By Shiyu Ji - Own work, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=60458994</figcaption>
</figure>
<p>Una ventaja de las máquinas de vectores de soporte es la posibilidad de clasificar conjuntos de datos no linealmente separables utilizando una técnica llamada Kernel trick, esta técnica consiste en aplicar una función <span class="math inline">\(\phi\)</span> a cada instancia para llevarlas a un mayor espacio dimensional <span class="citation" data-cites="boswell2002introduction"></span>.</p>
<p>Por esto el modelo final resulta de la siguiente manera: <span class="math display">\[\label{eqn:svm_basic}
f(X) = sign(W \cdot  \phi(X) + b)\]</span></p>
<p><strong>Usos de las máquinas de vectores de soporte</strong></p>
<p>Las máquinas de soporte de vectores han tenido exito en diversas áreas como clasificación de texto o imágenes. Dada su flexibilidad usando el truco de kernel es posible aplicarlo en una amplia variedad de problemas. Debido a que se busca un buen hiperplano que maximize el margen estos modelos suelen generalizar adecuadamente.</p>
<p><strong>Ejercicio de programación:</strong></p>
<p>Ejercicio para fortalecer los conocimientos adquiridos:</p>
<ol>
<li><p>En cualquier lenguaje de programación utilizar alguna librería como scikit-learn para resolver un problema de clasificación usando un árbol de decisión.</p></li>
</ol>
<p><img src="pandocConversionMedia/Pictures/github/libro-ia.png" style="width:5cm" alt="image" /></p>
<p><a href="https://github.com/amr205/Introduccion-a-la-IA---Libro">https://github.com/amr205/Introduccion-a-la-IA---Libro</a></p>
<strong>Overfitting y underfitting</strong>
<p>Cuando se entrenan diferentes modelos para desempeñar las tareas de clasificación o regresión es probable que nos encontremos con problemas de overfitting o underfitting.</p>
<p><strong>Overfitting</strong></p>
<p>El problema de overfitting se presenta cuando el modelo se ha ajustado demasiado bien a los datos con los cuales fue entrenado (Aprendiendo incluso el ruido presente en nuestros datos de entrenamiento), por lo cual su capacidad de generalización <a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> es bastante mala.</p>
<p><strong>Ruido vs Señal</strong></p>
<p>La señal es la función o patrón "verdadera" que pretendemos extraer de nuestros datos. El ruido presente en los datos se puede dar por errores durante la medición, aleatoriedad presente en los datos o valores atípicos (Outliers) <a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a>.</p>
<figure>
<img src="pandocConversionMedia/ia/overfitting.png" id="fig:overfitting" style="width:13cm" alt="Dos modelos con los mismos datos de entrada. (Izquierda) Modelo con overfitting, (Derecha) Modelo ajustado correctamente." /><figcaption aria-hidden="true">Dos modelos con los mismos datos de entrada. (Izquierda) Modelo con overfitting, (Derecha) Modelo ajustado correctamente.</figcaption>
</figure>
<p><strong>Underfitting</strong></p>
<p>Este es el problema contrario al overfitting, se da cuando nuestro modelo no es lo suficientemente expresivo para representar la relación entre los datos de entrada X y los datos de salida Y. En este caso nuestro modelo no se desempeña bien ni siquiera en nuestro set de entrenamiento.</p>
<figure>
<img src="pandocConversionMedia/ia/underfitting.png" id="fig:underfitting" style="width:13cm" alt="Dos modelos con los mismos datos de entrada. (Izquierda) Modelo con underfitting, (Derecha) Modelo ajustado correctamente." /><figcaption aria-hidden="true">Dos modelos con los mismos datos de entrada. (Izquierda) Modelo con underfitting, (Derecha) Modelo ajustado correctamente.</figcaption>
</figure>
<p><strong>¿Cómo detectar el overfitting o el underfitting?</strong></p>
<p>Posteriormente en la parte TODO de este libro se tratan formas más avanzadas de detectar el overfitting o underfitting, por ahora basta con evaluar nuestros modelos (tema que se explorará más adelante en este capítulo) en el set de entrenamiento y el set de prueba.</p>
<p>De manera general si nuestro desempeño en el set de entrenamiento es mucho mejor que nuestro desempeño en el set de prueba nuestro modelo tiene una alta probabilidad de sufrir overfitting.</p>
<p>En cambio si nuestro desempeño en el set de entrenamiento y el set de prueba es bajo es probable que nuestro modelo sufra de underfitting.</p>
<p><strong>¿Cómo combatir el overfitting?</strong></p>
<p>A continuación se describen de manera general algunas maneras de prevenir el overfitting en nuestro modelo, algunos de estos temas serán tratados con más profundidad más adelante en el libro:</p>
<ul>
<li><p><strong>Recolectar más datos:</strong> Usar más datos para el entrenamiento suele ayudar para mejorar la capacidad de generalización de nuestro modelo, sin embargo esto suele ser bastante costoso por lo cual se recomienda primero probar con otras maneras de combatir el overfitting.</p></li>
<li><p><strong>Remover características o atributos en nuestros datos:</strong> Si nuestro modelo tiene acceso a datos que no son relevantes para el problema es más fácil que nuestro modelo presente overfitting. Se puede hacer manualmente o utilizar algoritmos diseñados precisamente para realizar esta tarea.</p>
<p>Por ejemplo supongamos que tenemos que predecir que fruta estamos analizando en base a una serie de características (color, altura, anchura, peso y hora del análisis), en este caso la última característica no es relevante, si la persona encargada siempre analizará las manzanas en la noche, un modelo con overfitting "pensaría" que una fruta analizada en la mañana no puede ser una manzana.</p></li>
<li><p><strong>Early stopping:</strong> Cuando se entrene el modelo con algoritmos de aprendizaje iterativos es posible medir el desempeño en cada iteración, por ende podría detenerse el proceso de aprendizaje cuando nuestro modelo deje de generalizar exitosamente y empiece a presentar overfitting.</p>
<p>Esta técnica no suele recomendarse debido a que durante el entrenamiento se suele buscar minimizar o maximizar una función, si se usa early stopping esto deja de ser verdadero por lo cual es recomendable utilizar otras técnicas.</p></li>
<li><p><strong>Regularización:</strong> Estas técnicas fuerzan a nuestro modelo a ser más simple reduciendo el problema de overfitting en modelos complejos. La regularización es una de las maneras más recomendadas para combatir este problema.</p></li>
</ul>
<p>Los modelos más complejos suelen tener predisposición al overfitting, y los modelos más simples al underfitting.</p>
<p>Algunos modelos y algoritmos de aprendizaje tienen sus propios parámetros, mediante el uso de un set de validación se pueden ajustar estos parámetros para evitar el overfitting o el underfitting.</p>
<strong>Técnicas de regularización</strong>
<strong>Regularización L2 (Ridge penalisation)</strong>
<p>Los modelos con overfitting suelen tener valores muy altos en sus parámetros, por lo cual al penalizar valores muy altos en los mismos se puede regularizar el modelo.</p>
<p>La fórmula correspondiente a una función de coste J con regularización L2 es la siguiente:</p>
<p><span class="math display">\[J(X,Y,\theta) = cf(X,Y,\theta) + \lambda \sum_{j=1}^{n} {\theta_{j}}^{2}\]</span></p>
<p>Donde:</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">X son los atributos de nuestro set de entrenamiento</td>
</tr>
<tr class="even">
<td style="text-align: left;">Y son las etiquetas o variable a predecir de nuestro set de entrenamiento</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\theta\)</span> son los atributos del modelo</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(cf(X,Y,\theta)\)</span> es la función de coste o error sin regularizar de nuestro modelo</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\lambda\)</span> es un parámetro que controla el nivel de regularización aplicado al modelo</td>
</tr>
</tbody>
</table>
<p>La regularización de tipo L2 tiende a disminuir el valor de los parámetros del modelo sin llegar a fijar algunos en 0, en la figura <a href="#fig:l2_regularization" data-reference-type="ref" data-reference="fig:l2_regularization">2.25</a> se presenta un modelo de regresión polinomial de grado 9, aplicando distintos valores en <span class="math inline">\(\lambda\)</span> se puede apreciar el efecto resultante.</p>
<figure>
<img src="pandocConversionMedia/ia/l2_regularization.png" id="fig:l2_regularization" style="width:12cm" alt="Ejemplo de una regresión polinomial de grado 9 con regularización L2, en cada figura se puede observar el valor de \lambda." /><figcaption aria-hidden="true">Ejemplo de una regresión polinomial de grado 9 con regularización L2, en cada figura se puede observar el valor de <span class="math inline">\(\lambda\)</span>.</figcaption>
</figure>
<p>Cuando se tienen muchas características, la regularización l2 tiende a funcionar de una manera aproximada a lo que se muestra en la figura.</p>
<figure>
<img src="pandocConversionMedia/ia/l2_weights.png" id="fig:l2_weights" style="width:13cm" alt="Forma general en el cambio de los pesos de un modelo de acuerdo al cambio del valor de \lambda en regularización l2." /><figcaption aria-hidden="true">Forma general en el cambio de los pesos de un modelo de acuerdo al cambio del valor de <span class="math inline">\(\lambda\)</span> en regularización l2.</figcaption>
</figure>
<strong>Regularización L1 (Lasso penalisation)</strong>
<p>La fórmula correspondiente a una función de coste J con regularización L1 es la siguiente:</p>
<p><span class="math display">\[J(X,Y,\theta) = cf(X,Y,\theta) + \lambda \sum_{j=1}^{n} | {\theta_{j}} |\]</span></p>
<p>Donde:</p>
<table>
<tbody>
<tr class="odd">
<td style="text-align: left;">X son los atributos de nuestro set de entrenamiento</td>
</tr>
<tr class="even">
<td style="text-align: left;">Y son las etiquetas o variable a predecir de nuestro set de entrenamiento</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\theta\)</span> son los atributos del modelo</td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(cf(X,Y,\theta)\)</span> es la función de coste o error sin regularizar de nuestro modelo</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\lambda\)</span> es un parámetro que controla el nivel de regularización aplicado al modelo</td>
</tr>
</tbody>
</table>
<p>La principal diferencia con regularización l2 es la manera en la cual disminuyen los pesos, ya que como se muestra en la figura <a href="#fig:l1_weights" data-reference-type="ref" data-reference="fig:l1_weights">2.27</a> al aumentar el valor de <span class="math inline">\(\lambda\)</span> se van fijando en 0, por esta razón este tipo de regularización es usada para el proceso de selección de características, descartando aquellas que sean menos relevantes.</p>
<figure>
<img src="pandocConversionMedia/ia/l1_weights.png" id="fig:l1_weights" style="width:13cm" alt="Forma general en el cambio de los pesos de un modelo de acuerdo al cambio del valor de \lambda en regularización l1." /><figcaption aria-hidden="true">Forma general en el cambio de los pesos de un modelo de acuerdo al cambio del valor de <span class="math inline">\(\lambda\)</span> en regularización l1.</figcaption>
</figure>
<strong>Regularización en regresión lineal</strong>
<p><strong>Ridge Regression</strong></p>
<p>Para implementar regresión lineal con regularización L2 basta con modificar la función de coste de la siguiente manera:</p>
<p><span class="math display">\[\label{eqn:mean_squared_error_modified_l2}
J(\beta)=\frac{1}{2n} \sum_{i=1}^{n}\left (\hat{Y} - Y  \right )^{2} + \lambda \sum_{j=1}^{n} {\beta_{j}}^{2}\]</span></p>
<p>Por lo cual, la actualización de los pesos sería la siguiente:</p>
<p><span class="math display">\[\label{eqn:linear_regression_gradient_descent_l2}
\beta = \beta - \alpha \cdot \frac{1}{n} \left ( X&#39; (\hat{Y}-Y ) + 2 \lambda \beta \right )\]</span></p>
<p><strong>Lasso Regression</strong></p>
<p>Para implementar regresión lineal con regularización L1 tenemos que modificar la función de coste de la siguiente manera:</p>
<p><span class="math display">\[\label{eqn:mean_squared_error_modified_l1}
J(\beta)=\frac{1}{2n} \sum_{i=1}^{n}\left (\hat{Y} - Y  \right )^{2} + \lambda \sum_{j=1}^{n} {|\beta_{j}|}\]</span></p>
<p>En este caso la actualización de los pesos dependerá del valor de <span class="math inline">\(\beta_{j}\)</span></p>
<p><span class="math display">\[\label{eqn:linear_regression_gradient_descent_l1}
    \beta_j= 
\begin{dcases}
    \beta_j - \alpha \cdot \frac{1}{n} \left ( X_j (\hat{Y}-Y ) + \lambda \right ),&amp; \text{si } \beta_j \geq 0\\
    \beta_j - \alpha \cdot \frac{1}{n} \left ( X_j (\hat{Y}-Y ) - \lambda \right ),              &amp; \text{si } \beta_j &lt; 0
\end{dcases}\]</span></p>
<div class="center">
<p>(1,0)<span>420</span></p>
</div>
<p><strong>Overfitting en regresión polinomial</strong></p>
<p>Mientras mayor sea el valor de k, más grande es el riesgo de que nuestro modelo sufra del problema de overfitting, más adelante se explorarán técnicas para escoger hiperparámetros, de momento una solución viable es hacer uso de regularización L2 si se presenta este problema.</p>
<p><u>Overfitting en los árboles de decisión</u></p>
<p>Si nosotros no limitamos el número de nodos o tamaño del árbol podemos terminar con zonas de decisión muy pequeñas que clasifiquen perfectamente nuestro conjunto de datos de entrenamiento pero fallen al generalizar (clasificar datos fuera del dataset de entrenamiento), es por ello que para evitar existen dos acercamientos:</p>
<ol>
<li><p><strong>Pre-poda:</strong> Se suele limitar la profundidad del árbol, otras acciones de pre-poda incluyen limitar el número de nodos, limitar el número minimo de elementos que puede haber en un nodo interno, etc.</p></li>
<li><p><strong>Post-poda:</strong> Se suelen recorrer los nodos evaluando el efecto que tendría su eliminación usando una función de coste y un conjunto de datos de prueba.</p></li>
</ol>
<h2 data-number="4.3" id="aprendizaje-no-supervisado"><span class="header-section-number">4.3</span> Aprendizaje no supervisado</h2>
<strong>Introducción al capítulo</strong>
<p>A diferencia del aprendizaje supervisado en el aprendizaje supervisado no tenemos las etiquetas o salidas <span class="math inline">\(Y\)</span> que queremos obtener, en nuestro conjunto de datos unicamente contamos con los atributos <span class="math inline">\(X\)</span>, todos los modelos de aprendizaje no supervisado tienen esta característica pero pueden tener distintos objetivos, por ejemplo la generación de nuevos datos similares a los datos de entrenamiento, la modificación de los datos, el agrupamiento de los mismos o su compresión.</p>
<p>Los modelos de apredizaje no supervisado pueden clasificarse de acuerdo a la tarea que pueden realizar:</p>
<ul>
<li><p>Clusterización</p></li>
<li><p>Reducción de dimensionalidad</p></li>
<li><p>Detección de anomalias</p></li>
<li><p>Generación de datos</p></li>
<li><p>Otras tareas</p></li>
</ul>
<p>También es posible clasificarlos de acuerdo a si estos modelos se basan en la idea de variables latentes<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a> <span class="math inline">\(Z\)</span>. Estos modelos permiten capturar una estructura subyacente en los datos, generalmente de menor dimensionalidad, esto nos puede permitir comprimir los datos al pasar de los datos <span class="math inline">\(X\)</span> a sus variables latentes <span class="math inline">\(Z\)</span> o generar nuevos datos pasando de las variables latentes <span class="math inline">\(Z\)</span> a datos <span class="math inline">\(X\)</span> <span class="citation" data-cites="prince2023understanding"></span>.</p>
<strong>Clusterización</strong>
<p>La clusterización consiste en asignar etiquetas a instancias de nuestro conjunto de datos no etiquetados.</p>
<p><strong>Tipos de clusterización</strong></p>
<p>Existen diferentes tipos de algoritmos de clusterización a continuación se describen algunos de los más populares <span class="citation" data-cites="Xu2015"></span>:</p>
<ul>
<li><p><strong>Algoritmos basados en particion</strong>: La idea básica de estos algoritmos es ubicar el “centro” de k clusters en nuestros datos.</p></li>
<li><p><strong>Algoritmos basados en densidad</strong>: Este tipo de algoritmos asignan como clusters aquellas areas con alta densidad de instancias.</p></li>
<li><p><strong>Algoritmos basados en distribución</strong>: Estos algoritmos parten de la siguiente idea, aquellas instancias generadas a partir de la misma distribución pertenecen al mismo cluster.</p></li>
<li><p><strong>Algoritmos basados en jerarquía</strong>: Estos algoritmos construyen una relación jerárquica entre las instancias.</p></li>
</ul>
<p>Existen otros tipos de algoritmos como aquellos basados en teoría de fractales, teoría difusa, inteligencia de enjambre, etc.</p>
<figure>
<img src="pandocConversionMedia/ia/k-means clustering.png" id="fig:kmeans_clustering" style="width:7.5cm" alt="Clusterización basada en partición utilizando el algoritmo K-means" /><figcaption aria-hidden="true">Clusterización basada en partición utilizando el algoritmo K-means</figcaption>
</figure>
<figure>
<img src="pandocConversionMedia/ia/dbscan clustering.png" id="fig:dbscan_clustering" style="width:7.5cm" alt="Clusterización basada en densidad utilizando el algoritmo DBSCAN" /><figcaption aria-hidden="true">Clusterización basada en densidad utilizando el algoritmo DBSCAN</figcaption>
</figure>
<figure>
<img src="pandocConversionMedia/ia/gmm clustering.png" id="fig:gmm_clustering" style="width:7.5cm" alt="Clusterización basada en distribución utilizando el algoritmo Gaussian Mixture Models" /><figcaption aria-hidden="true">Clusterización basada en distribución utilizando el algoritmo Gaussian Mixture Models</figcaption>
</figure>
<figure>
<img src="pandocConversionMedia/ia/hierarchical clustering.png" id="fig:hierarchical_clustering" style="width:7.5cm" alt="Clusterización basada en jerarquía" /><figcaption aria-hidden="true">Clusterización basada en jerarquía</figcaption>
</figure>
<strong>K - means</span> <span id="subsection:k_means" label="subsection:k_means">[subsection:k_means]</strong>
<p>Este algoritmo pretende encontrar <span class="math inline">\(K\)</span> centroides, cada ejemplo del conjunto de datos de entrenamiento pertenece a un centroide por lo cual el resultado son <span class="math inline">\(K\)</span> clusters.</p>
<p><strong>Suposiciones del algoritmo</strong></p>
<p>K-means es un algoritmo de aprendizaje no paramétrico por lo cual no realiza fuertes suposiciones sobre la forma de los clusters, de manera intuitiva se puede entender que este algoritmo asume que los elementos pertenecientes a un mismo cluster poseen caracteristicas <span class="math inline">\(X\)</span> similares.</p>
<p><strong>Funcionamiento del algoritmo de K-means</strong></p>
<p>Tendremos los siguientes elementos:</p>
<ul>
<li><p>Un set de entrenamiento compuesto de las características <span class="math inline">\(X\)</span>.</p></li>
<li><p>El hiperparámetro <span class="math inline">\(k\)</span> que determina el número de centroides o clusters.</p></li>
</ul>
<p>El algoritmo es el siguiente:</p>
<ol>
<li><p>Se inicializan <span class="math inline">\(k\)</span> centroides <span class="math inline">\(\mathrm{M}\)</span> dentro del espacio de datos <span class="math inline">\(X\)</span>, se puden elegir por ejemplo de forma aleatoria.</p></li>
<li><p>Cada elemento de <span class="math inline">\(X\)</span> es asignado al cluster <span class="math inline">\(\mu\)</span> más cercano.</p></li>
<li><p>Se actualiza la posición de cada centroide <span class="math inline">\(\mu\)</span> tomando la posición del promedio de los elementos asignados a el.</p></li>
</ol>
<p>Matemáticamente podemos entender que estamos minimizando la distancia de los centroides <span class="math inline">\(\mathrm{M}\)</span> a los elementos en <span class="math inline">\(X\)</span> pertenecientes al set <span class="math inline">\(S\)</span> donde cada <span class="math inline">\(x\)</span> fue asignado al cluster <span class="math inline">\(\mu\)</span>.</p>
<p><span class="math display">\[J(X,Y,\theta) = cf(X,Y,\theta) + \lambda \sum_{j=1}^{n} | {\theta_{j}} |\]</span></p>
<div class="center">
<p>(1,0)<span>420</span></p>
</div>
<p><strong>Ejercicio de programación:</strong></p>
<ol>
<li><p>En un lenguaje de programación matemático como Octave, Julia o Matlab resolver un problema de clusterización mediante k-means.</p></li>
<li><p>En cualquier lenguaje de programación utilizar alguna librería como scikit-learn para resolver un problema de clasificación mediante k-means.</p></li>
</ol>
<h2 class="unnumbered" id="bibliography">Bibliography</h2>
<p>Las referencias se pueden encontrar bien listadas y ordenadas en la versión pdf del libro</p>
 
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>Una tabla de verdad, o tabla de valores de verdades, es una tabla que muestra el valor de verdad de una proposición compuesta, para cada combinación de verdad que se pueda asignar<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>La base de conocimiento es el lugar donde se almacena el conocimiento del experto a manera de hechos y reglas, más adelante cuando se vea el tema de sistemas expertos se verá el rol de este elemento.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3" role="doc-endnote"><p>La indecidibilidad es la propiedad de un sistema de conducir siempre a una respuesta verdadera o falsa, por lo cual no siempre puede demostrar o refutar una sentencia.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4" role="doc-endnote"><p>Un hiperparámetro es una propiedad del algoritmo de aprendizaje, estos valores no son aprendidos a partir del proceso de aprendizaje y tienen que ser determinados por el desarrollador.<a href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5" role="doc-endnote"><p>Un hiperplano es una extensión del concepto del plano, este tiene una dimensión menos que el ambiente en el cual reside, por ejemplo en un espacio tridimensional, el hiperplano correspondiente sería un plano.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6" role="doc-endnote"><p>La regresión no paramétrica comprende un conjunto de técnicas para estimar una curva de regresión sin realizar fuertes suposiciones acerca de la forma de la señal que pretendemos extaer de los datos<a href="#fnref6" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn7" role="doc-endnote"><p>La razón de probabilidades o razón de posibilidades (odds en íngles) indica la razón entre el número de eventos que producen un resultado y los que no lo hacen. Por ejemplo si tenemos 70% de probabilidades de ganar tenemos una razón de probabilidades de <span class="math inline">\(7/3 = 2.33333\)</span><a href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8" role="doc-endnote"><p>Dos sucesos aleatorios son independientes entre sí cuando la probabilidad de cada uno de ellos no está influida porque el otro suceso ocurra o no<a href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9" role="doc-endnote"><p>La generalización es la capacidad de desempeñarse exitosamente las tareas de clasificación o regresión en datos que el modelo no ha observado.<a href="#fnref9" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10" role="doc-endnote"><p>Los valores atípicos (Outliers) son aquellos valores que difieren significativamente del resto de los datos o que no pertenecen al dataset.<a href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11" role="doc-endnote"><p>Las variables latentes o variables ocultas son aquellas que no observamos pero se pueden inferir a partir de otras variables observables<a href="#fnref11" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
